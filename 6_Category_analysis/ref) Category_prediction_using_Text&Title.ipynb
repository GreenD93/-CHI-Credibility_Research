{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = '[Full_TFIDF]Credibility_research_20180906.db' #DB 파일명\n",
    "# db 생성\n",
    "con = sqlite3.connect( db_name )\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select p.Post_id,p.Category,p.Title,p.Text,u.Credibility,group_concat(img.Img_id) as img_count\n",
    "    FROM Post as p\n",
    "    Left JOIN user as u\n",
    "        ON p.User_id = u.User_id\n",
    "    Left JOIN Img as img\n",
    "        ON p.Post_id = img.Post_id\n",
    "    GROUP BY p.Post_id;\n",
    "    '''\n",
    "cur.execute(sql)\n",
    "rows = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = [i[0] for i in cur.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Post_id', 'Category', 'Title', 'Text', 'Credibility', 'img_count']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df['Category'] != \"무작위\"].iloc[:16304]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = test_df[test_df['Credibility'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('text_practice.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['img_count'] = test_df['img_count'].apply(lambda x : 0 if type(x)==type(None) else x)\n",
    "test_df['img_count'] = test_df['img_count'].apply(lambda x : len(x.split(',')) if x != 0 else x)\n",
    "test_df['Text_len'] = test_df['Text'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18개 Category to Numeric labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_df['Category'])\n",
    "le.classes_\n",
    "test_df['Category'] =le.transform(test_df['Category'])\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IT·컴퓨터', '건강·의학', '공연·전시', '교육·학문', '국내여행', '드라마·방송', '등산·낚시·레저',\n",
       "       '만화·애니', '맛집', '사진', '스포츠', '시사·인문·경제', '어학·외국어', '와인·술', '육아·결혼',\n",
       "       '자동차', '차·커피·디저트', '패션·뷰티'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Category = le.classes_\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "test_df = shuffle(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = test_df['Title']\n",
    "Text = test_df['Text']\n",
    "y = test_df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#vectorizer = TfidfVectorizer(analyzer='word', sublinear_tf=True,lowercase=True)\n",
    "vectorizer_Text = TfidfVectorizer(max_features=2000)\n",
    "tfidf_Text = vectorizer_Text.fit_transform(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer_Text,open(\"tfidf_text_.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_load = pickle.load(open(\"tfidf_text.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#vectorizer = TfidfVectorizer(analyzer='word', sublinear_tf=True,lowercase=True)\n",
    "vectorizer_Title = TfidfVectorizer(max_features=1000)\n",
    "tfidf_Title = vectorizer_Title.fit_transform(Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01',\n",
       " '02',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '10',\n",
       " '100',\n",
       " '10월',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '14년',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '18년',\n",
       " '19',\n",
       " '1기',\n",
       " '1위',\n",
       " '1편',\n",
       " '1화',\n",
       " '20',\n",
       " '200mm',\n",
       " '2011',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2015년',\n",
       " '2016',\n",
       " '2016년',\n",
       " '2017',\n",
       " '2017년',\n",
       " '2018',\n",
       " '2018년',\n",
       " '2019',\n",
       " '22',\n",
       " '24',\n",
       " '24시',\n",
       " '24시간',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '2기',\n",
       " '2편',\n",
       " '2화',\n",
       " '30',\n",
       " '365일',\n",
       " '3화',\n",
       " '4분기',\n",
       " '4월',\n",
       " '4차산업혁명',\n",
       " '5월',\n",
       " '5화',\n",
       " '6월',\n",
       " '70',\n",
       " '7월',\n",
       " '8월',\n",
       " 'a100엔터테인먼트',\n",
       " 'abonz',\n",
       " 'all',\n",
       " 'amg',\n",
       " 'and',\n",
       " 'angling',\n",
       " 'aslan',\n",
       " 'at',\n",
       " 'bmw',\n",
       " 'by',\n",
       " 'ckcolor',\n",
       " 'color',\n",
       " 'comodo',\n",
       " 'cos',\n",
       " 'day',\n",
       " 'de',\n",
       " 'detailing',\n",
       " 'dslr',\n",
       " 'ef',\n",
       " 'effects',\n",
       " 'f1',\n",
       " 'feat',\n",
       " 'for',\n",
       " 'gre',\n",
       " 'hyundai',\n",
       " 'ii',\n",
       " 'in',\n",
       " 'is',\n",
       " 'it',\n",
       " 'kbl',\n",
       " 'lg',\n",
       " 'live',\n",
       " 'my',\n",
       " 'new',\n",
       " 'nikon',\n",
       " 'no',\n",
       " 'nx',\n",
       " 'of',\n",
       " 'ost',\n",
       " 'paris',\n",
       " 'part',\n",
       " 'ready',\n",
       " 'sports',\n",
       " 'sports카페에서',\n",
       " 'spring',\n",
       " 'ssl',\n",
       " 'story',\n",
       " 'talk',\n",
       " 'the',\n",
       " 'to',\n",
       " 'today',\n",
       " 'tv',\n",
       " 'up',\n",
       " 'vol',\n",
       " 'vs',\n",
       " 'wash',\n",
       " 'with',\n",
       " 'wk',\n",
       " 'wnba',\n",
       " 'wwe',\n",
       " 'you',\n",
       " '가격',\n",
       " '가격비교',\n",
       " '가격비교사이트',\n",
       " '가격으로',\n",
       " '가는',\n",
       " '가능한',\n",
       " '가득한',\n",
       " '가로수길',\n",
       " '가방',\n",
       " '가볼만',\n",
       " '가볼만한',\n",
       " '가볼만한곳',\n",
       " '가성비',\n",
       " '가세요',\n",
       " '가슴',\n",
       " '가을',\n",
       " '가자',\n",
       " '가장',\n",
       " '가즈아',\n",
       " '가평',\n",
       " '간단',\n",
       " '감상',\n",
       " '강남',\n",
       " '강남서울밝은안과',\n",
       " '강남서울밝은안과에서',\n",
       " '강남역',\n",
       " '강릉',\n",
       " '강원도',\n",
       " '강좌',\n",
       " '강화도',\n",
       " '같은',\n",
       " '같이',\n",
       " '개봉기',\n",
       " '개인전',\n",
       " '갤러리',\n",
       " '갤럭시',\n",
       " '걱정',\n",
       " '건강',\n",
       " '건강을',\n",
       " '건강이야기',\n",
       " '건강한',\n",
       " '건담',\n",
       " '걸그룹',\n",
       " '것은',\n",
       " '게임',\n",
       " '겨울',\n",
       " '견적',\n",
       " '견적을',\n",
       " '결과',\n",
       " '결정',\n",
       " '결혼',\n",
       " '결혼이야기',\n",
       " '결혼준비',\n",
       " '경기',\n",
       " '경기도',\n",
       " '경기를',\n",
       " '경주',\n",
       " '계신가요',\n",
       " '계신다면',\n",
       " '고등과외',\n",
       " '고민',\n",
       " '고민이라면',\n",
       " '고퀄리티',\n",
       " '골프',\n",
       " '곳에서',\n",
       " '곳을',\n",
       " '공간',\n",
       " '공개',\n",
       " '공부',\n",
       " '공부법',\n",
       " '공부하기',\n",
       " '공부하세요',\n",
       " '공부할',\n",
       " '공연',\n",
       " '공유',\n",
       " '공지',\n",
       " '관련주',\n",
       " '관리',\n",
       " '광동',\n",
       " '광주',\n",
       " '교체',\n",
       " '교환',\n",
       " '구리',\n",
       " '구입',\n",
       " '국내',\n",
       " '국어',\n",
       " '귀성형',\n",
       " '귀성형잘하는곳',\n",
       " '귀성형잘하는병원',\n",
       " '그랑',\n",
       " '그랑서울',\n",
       " '그랑서울에서',\n",
       " '그럼',\n",
       " '그리고',\n",
       " '극장판',\n",
       " '근교',\n",
       " '기념',\n",
       " '기록',\n",
       " '기장',\n",
       " '기장치과',\n",
       " '김앤방여성의원',\n",
       " '김앤방여성의원에서',\n",
       " '깔끔한',\n",
       " '꿈을',\n",
       " '나는',\n",
       " '나도',\n",
       " '나들이',\n",
       " '나루토',\n",
       " '나를',\n",
       " '나만의',\n",
       " '나의',\n",
       " '나인윅스',\n",
       " '남자',\n",
       " '남자눈썹문신',\n",
       " '내가',\n",
       " '내신과외',\n",
       " '너무',\n",
       " '네온펀치',\n",
       " '네이버',\n",
       " '네일',\n",
       " '노원필라테스',\n",
       " '노원필라테스에서',\n",
       " '높은',\n",
       " '눈썹',\n",
       " '눈썹문신',\n",
       " '뉴스',\n",
       " '뉴욕',\n",
       " '늑연골',\n",
       " '늘어진',\n",
       " '늘어진뱃살',\n",
       " '니콘',\n",
       " '다녀왔어요',\n",
       " '다른',\n",
       " '다시',\n",
       " '다양하고',\n",
       " '다양한',\n",
       " '다이어트',\n",
       " '다이어트를',\n",
       " '다이캐스트',\n",
       " '담은',\n",
       " '대게',\n",
       " '대구',\n",
       " '대박',\n",
       " '대안학교',\n",
       " '대전',\n",
       " '대전맛집',\n",
       " '대전시청맛집',\n",
       " '대학로',\n",
       " '대한',\n",
       " '대한민국',\n",
       " '대해',\n",
       " '대해서',\n",
       " '더브로우',\n",
       " '더브로우를',\n",
       " '더브로우에서',\n",
       " '더새로이',\n",
       " '더새로이성형외과',\n",
       " '더새로이성형외과에서',\n",
       " '더새로이에서',\n",
       " '데이',\n",
       " '데이트',\n",
       " '데일리룩',\n",
       " '도와드리는',\n",
       " '도와드립니다',\n",
       " '도움을',\n",
       " '돌출귀성형',\n",
       " '동시에',\n",
       " '동영상',\n",
       " '되는',\n",
       " '둔산본가',\n",
       " '드디어',\n",
       " '드라마',\n",
       " '드라이브',\n",
       " '드립니다',\n",
       " '드셔보세요',\n",
       " '드시고',\n",
       " '들어보셨나요',\n",
       " '등장',\n",
       " '디자인',\n",
       " '디자인전문회사',\n",
       " '디저트',\n",
       " '디젤',\n",
       " '따라',\n",
       " '때문에',\n",
       " '라이프',\n",
       " '라즈베리',\n",
       " '라켓',\n",
       " '러시아',\n",
       " '러시아대게',\n",
       " '레스토랑',\n",
       " '로맨틱',\n",
       " '로맨틱그랑서울',\n",
       " '로맨틱그랑서울에',\n",
       " '로맨틱그랑서울에서',\n",
       " '로즈데이',\n",
       " '르노',\n",
       " '리뷰',\n",
       " '리스트',\n",
       " '립스틱',\n",
       " '마지막',\n",
       " '만나는',\n",
       " '만나다',\n",
       " '만나보세요',\n",
       " '만난',\n",
       " '만남',\n",
       " '만드는',\n",
       " '만든',\n",
       " '만들기',\n",
       " '만들어',\n",
       " '만화',\n",
       " '많은',\n",
       " '많이',\n",
       " '말고',\n",
       " '맛있게',\n",
       " '맛있는',\n",
       " '맛집',\n",
       " '매거진',\n",
       " '매력적인',\n",
       " '맥짚기',\n",
       " '먹고',\n",
       " '먹으러',\n",
       " '멋진',\n",
       " '메이크업',\n",
       " '메인보드수리',\n",
       " '명륜진사갈비',\n",
       " '모델',\n",
       " '모두',\n",
       " '모든',\n",
       " '모음',\n",
       " '모집',\n",
       " '몬스터폰',\n",
       " '몬스터폰에서',\n",
       " '무료',\n",
       " '무료로',\n",
       " '무료이벤트',\n",
       " '무선',\n",
       " '무한리필',\n",
       " '문의하세요',\n",
       " '문제',\n",
       " '문제집',\n",
       " '뮤지컬',\n",
       " '미국',\n",
       " '미니',\n",
       " '미드',\n",
       " '미소',\n",
       " '미소를',\n",
       " '미스터주스',\n",
       " '미팅',\n",
       " '믿고',\n",
       " '믿을',\n",
       " '바다',\n",
       " '바로',\n",
       " '바이브티비',\n",
       " '바이브티비로',\n",
       " '바이브티비에서',\n",
       " '반영구',\n",
       " '반포',\n",
       " '받고',\n",
       " '받아',\n",
       " '받아보세요',\n",
       " '받으세요',\n",
       " '발산스터디카페',\n",
       " '발표',\n",
       " '방법',\n",
       " '방송',\n",
       " '방송연기학원',\n",
       " '배우',\n",
       " '배울학',\n",
       " '배터리',\n",
       " '백내장',\n",
       " '백내장수술',\n",
       " '백두대간',\n",
       " '뱃살',\n",
       " '베이비스튜디오',\n",
       " '벤츠',\n",
       " '벨로스터',\n",
       " '병원',\n",
       " '보고',\n",
       " '보기',\n",
       " '보내세요',\n",
       " '보는',\n",
       " '보다',\n",
       " '보생옥',\n",
       " '보생옥에서',\n",
       " '보세요',\n",
       " '보양식',\n",
       " '보자',\n",
       " '복부성형',\n",
       " '복부성형으로',\n",
       " '본스타',\n",
       " '본스타에서',\n",
       " '본스타트레이닝센터',\n",
       " '본스타트레이닝센터에서',\n",
       " '본식스냅',\n",
       " '볼보',\n",
       " '부산',\n",
       " '부산치과',\n",
       " '분석',\n",
       " '분위기',\n",
       " '브랜드',\n",
       " '블랙',\n",
       " '비교',\n",
       " '비에이블',\n",
       " '비에이블스터디',\n",
       " '비에이블스터디카페',\n",
       " '비에이블스터디카페창업',\n",
       " '비용',\n",
       " '비키니바디',\n",
       " '빠른',\n",
       " '빵집',\n",
       " '사람들',\n",
       " '사랑의',\n",
       " '사용',\n",
       " '사용기',\n",
       " '사용법',\n",
       " '사용하는',\n",
       " '사이트',\n",
       " '사주카페',\n",
       " '사진',\n",
       " '사진예술의',\n",
       " '사진전',\n",
       " '사키',\n",
       " '살펴보기',\n",
       " '삼겹살',\n",
       " '삼성',\n",
       " '상담받아보세요',\n",
       " '상담하세요',\n",
       " '상반기',\n",
       " '새로',\n",
       " '새로운',\n",
       " '새롭게',\n",
       " '생활',\n",
       " '샤넬',\n",
       " '서면',\n",
       " '서비스',\n",
       " '서울',\n",
       " '서울야경',\n",
       " '선물',\n",
       " '선택',\n",
       " '설악산',\n",
       " '설치',\n",
       " '성공',\n",
       " '성남아이폰수리',\n",
       " '성수동',\n",
       " '성우',\n",
       " '성장기어린이영양제',\n",
       " '성형',\n",
       " '성형외과',\n",
       " '세계',\n",
       " '세미나',\n",
       " '세일',\n",
       " '세차',\n",
       " '센터',\n",
       " '소개',\n",
       " '소개합니다',\n",
       " '소개해',\n",
       " '소개해드립니다',\n",
       " '소개해요',\n",
       " '소니',\n",
       " '소문난',\n",
       " '소소한',\n",
       " '소속',\n",
       " '소식',\n",
       " '소중한',\n",
       " '소화불량에',\n",
       " '속초',\n",
       " '솔로',\n",
       " '솔로대첩',\n",
       " '수능',\n",
       " '수리',\n",
       " '수리서비스',\n",
       " '수면앤다이어트',\n",
       " '수술',\n",
       " '수시컨설팅',\n",
       " '수업',\n",
       " '수원',\n",
       " '수지수학학원',\n",
       " '수질환경기사',\n",
       " '수학교육과',\n",
       " '수학문제집',\n",
       " '순위',\n",
       " '쉐보레',\n",
       " '쉽게',\n",
       " '쉽고',\n",
       " '슈퍼바나바로',\n",
       " '스마트밴드',\n",
       " '스마트폰',\n",
       " '스케치',\n",
       " '스타',\n",
       " '스타벅스',\n",
       " '스터디',\n",
       " '스터디카페',\n",
       " '스토리',\n",
       " '스튜디오',\n",
       " '스트레칭',\n",
       " '스트릿패션',\n",
       " '스페셜',\n",
       " '스펙',\n",
       " '스포츠',\n",
       " '스포츠분석',\n",
       " '스포츠중계',\n",
       " '스포츠중계는',\n",
       " '스포츠중계를',\n",
       " '시간',\n",
       " '시리즈',\n",
       " '시스템',\n",
       " '시승기',\n",
       " '시원하게',\n",
       " '시원한',\n",
       " '시작',\n",
       " '시작하세요',\n",
       " '시작하자',\n",
       " '시즌',\n",
       " '시청',\n",
       " '시청률',\n",
       " '시청하세요',\n",
       " '식당',\n",
       " '신사동',\n",
       " '신작',\n",
       " '신차드림',\n",
       " '신차드림에서',\n",
       " '신촌',\n",
       " '신촌ybm',\n",
       " '신촌스터디카페',\n",
       " '실기',\n",
       " '실시간',\n",
       " '실시간으로',\n",
       " '싱글',\n",
       " '싶다면',\n",
       " '싶은',\n",
       " '아기',\n",
       " '아나레슨',\n",
       " '아나레슨에서',\n",
       " '아나운서',\n",
       " '아나운서아카데미',\n",
       " '아나운서학원',\n",
       " '아닌',\n",
       " '아름다운',\n",
       " '아름다움을',\n",
       " '아반떼',\n",
       " '아시나요',\n",
       " '아이',\n",
       " '아이들',\n",
       " '아이들과',\n",
       " '아이디어',\n",
       " '아이스',\n",
       " '아이와',\n",
       " '아이키크는방법',\n",
       " '아이템',\n",
       " '아이폰',\n",
       " '아이폰8',\n",
       " '아이폰8플러스',\n",
       " '아이폰x',\n",
       " '아이폰배터리교체',\n",
       " '아이폰배터리할인',\n",
       " '아이폰배터리할인과',\n",
       " '아이폰수리',\n",
       " '아이폰액정수리',\n",
       " '아직도',\n",
       " '아침',\n",
       " '아침맑음한의원',\n",
       " '아침맑음한의원에서',\n",
       " '아토피',\n",
       " '아티초크',\n",
       " '안내',\n",
       " '안산점',\n",
       " '안산중고차',\n",
       " '안양',\n",
       " '안양연기학원',\n",
       " '안전한',\n",
       " '않는',\n",
       " '않은',\n",
       " '알고',\n",
       " '알려드려요',\n",
       " '알려드립니다',\n",
       " '알아보고',\n",
       " '알아보기',\n",
       " '알아보세요',\n",
       " '알아보아요',\n",
       " '알아보자',\n",
       " '알아볼까요',\n",
       " '알아봐요',\n",
       " '압구정',\n",
       " '애니',\n",
       " '애니메이션',\n",
       " '애니추천',\n",
       " '야경',\n",
       " '야구친구',\n",
       " '야생화',\n",
       " '어느',\n",
       " '어느멋진날',\n",
       " '어디',\n",
       " '어디로',\n",
       " '어디서',\n",
       " '어때',\n",
       " '어때요',\n",
       " '어떠세요',\n",
       " '어떤',\n",
       " '어떻게',\n",
       " '어린이',\n",
       " '어본즈',\n",
       " '언제',\n",
       " '업체',\n",
       " '없는',\n",
       " '없다',\n",
       " '없이',\n",
       " '에서',\n",
       " '에이치비',\n",
       " '에이치비성형외과',\n",
       " '에이치비성형외과가',\n",
       " '에이치비성형외과에서',\n",
       " '엑셀',\n",
       " '엠필라테스에서',\n",
       " '여기',\n",
       " '여기서',\n",
       " '여기에서',\n",
       " '여드름',\n",
       " '여드름한의원',\n",
       " '여러분과',\n",
       " '여름',\n",
       " '여름방학',\n",
       " '여름에',\n",
       " '여름을',\n",
       " '여름철',\n",
       " '여름휴가',\n",
       " '여수',\n",
       " '여의도',\n",
       " '여자',\n",
       " '여천맛집',\n",
       " '여행',\n",
       " '역사',\n",
       " '역시',\n",
       " '연극',\n",
       " '연극영화입시학원',\n",
       " '연기',\n",
       " '연기학원',\n",
       " '연꽃',\n",
       " '연암주식투자',\n",
       " '연출',\n",
       " '연희단거리패',\n",
       " '영국',\n",
       " '영덕',\n",
       " '영상',\n",
       " '영양제',\n",
       " '영어',\n",
       " '영어공부',\n",
       " '영어로',\n",
       " '영어를',\n",
       " '영어표현',\n",
       " '영화',\n",
       " '예고',\n",
       " '예쁜',\n",
       " '예상도',\n",
       " '오늘',\n",
       " '오늘의',\n",
       " '오모티비',\n",
       " '오모티비에서',\n",
       " '오세요',\n",
       " '오픈',\n",
       " '오픈한',\n",
       " '오후',\n",
       " '온라인',\n",
       " '올여름',\n",
       " '와우브로우',\n",
       " '와우브로우에서',\n",
       " '와우코믹스',\n",
       " '와인',\n",
       " '완성',\n",
       " '왕수학',\n",
       " '요즘',\n",
       " '용인',\n",
       " '우리',\n",
       " '우리아이',\n",
       " '우승',\n",
       " '운동',\n",
       " '운영하는',\n",
       " '울산',\n",
       " '원피스',\n",
       " '원한다면',\n",
       " '월드컵',\n",
       " '웨딩박람회',\n",
       " '웨딩앤',\n",
       " '위담',\n",
       " '위캔다이어트',\n",
       " '위한',\n",
       " '위해',\n",
       " '위험물산업기사',\n",
       " '윌성형외과',\n",
       " '윌성형외과에서',\n",
       " '윌슨',\n",
       " '유명한',\n",
       " '유명한곳',\n",
       " '유튜브',\n",
       " '으로',\n",
       " '이렇게',\n",
       " '이번',\n",
       " '이벤트',\n",
       " '이벤트를',\n",
       " '이야기',\n",
       " '이영은아나운서',\n",
       " '이용하세요',\n",
       " '이용한',\n",
       " '이용해보세요',\n",
       " '이유',\n",
       " '이제',\n",
       " '이제는',\n",
       " '이젠',\n",
       " '이지수능교육',\n",
       " '인강',\n",
       " '인도',\n",
       " '인천',\n",
       " '인터넷',\n",
       " '인터뷰',\n",
       " '인테리어',\n",
       " '인한',\n",
       " '일드',\n",
       " '일몰',\n",
       " '일본',\n",
       " '일본어',\n",
       " '일산',\n",
       " '일산점',\n",
       " '일상',\n",
       " '일정',\n",
       " '일출',\n",
       " '임진강장어',\n",
       " '임플란트',\n",
       " '임플란트잘하는곳',\n",
       " '입꼬리',\n",
       " '입꼬리성형',\n",
       " '입꼬리성형수술',\n",
       " '입꼬리성형수술로',\n",
       " '입꼬리수술',\n",
       " '입꼬리수술잘하는곳',\n",
       " '입니다',\n",
       " '입시연기학원',\n",
       " '입체도감',\n",
       " '있나요',\n",
       " '있는',\n",
       " '있다',\n",
       " '있다면',\n",
       " '있습니다',\n",
       " '있어요',\n",
       " '있을까',\n",
       " '자격증',\n",
       " '자동차',\n",
       " '자동차리스',\n",
       " '자료',\n",
       " '자면서',\n",
       " '자소서의',\n",
       " '자신감',\n",
       " '자신감을',\n",
       " '자연스러운',\n",
       " '자전거',\n",
       " '작은',\n",
       " '잘하는',\n",
       " '잘하는곳',\n",
       " '잠실',\n",
       " '장기렌트',\n",
       " '장기렌트카',\n",
       " '장어',\n",
       " '재미있는',\n",
       " '재밌는',\n",
       " '저렴하게',\n",
       " '저렴한',\n",
       " '전망',\n",
       " '전문',\n",
       " '전문점',\n",
       " '전시',\n",
       " '전주',\n",
       " '전통',\n",
       " '정기배송으로',\n",
       " '정리',\n",
       " '정말',\n",
       " '정보',\n",
       " '제10회',\n",
       " '제7회',\n",
       " '제8회',\n",
       " '제9회',\n",
       " '제네시스',\n",
       " '제대로',\n",
       " '제로스마트카',\n",
       " '제주',\n",
       " '제주도',\n",
       " '제품',\n",
       " '젠요가',\n",
       " '젠요가에서',\n",
       " '좋아요',\n",
       " '좋은',\n",
       " '주는',\n",
       " '주말',\n",
       " '주문은',\n",
       " '주식',\n",
       " '준비',\n",
       " '준비하세요',\n",
       " '줄기세포가슴지방이식',\n",
       " '줄기세포가슴지방이식으로',\n",
       " '중계',\n",
       " '중계를',\n",
       " '중고차',\n",
       " '중고폰',\n",
       " '중고폰매입',\n",
       " '중고폰매입도',\n",
       " '중고폰매입은',\n",
       " '중국',\n",
       " '즐거운',\n",
       " '즐겨보세요',\n",
       " '즐기는',\n",
       " '즐기자',\n",
       " '즐길',\n",
       " '지금',\n",
       " '직장인',\n",
       " '직장인미팅',\n",
       " '직접',\n",
       " '진산서당',\n",
       " '진짜',\n",
       " '집에서',\n",
       " '창업',\n",
       " '찾고',\n",
       " '찾는',\n",
       " '찾는다면',\n",
       " '찾아',\n",
       " '찾으세요',\n",
       " '찾으시나요',\n",
       " '찾으신다면',\n",
       " '처진뱃살',\n",
       " '처진살',\n",
       " '천안',\n",
       " '청남대',\n",
       " '청담동',\n",
       " '청담여신성형외과',\n",
       " '청담여신성형외과에서',\n",
       " '청담여신성형외과의',\n",
       " '체계적인',\n",
       " '체크',\n",
       " '체형교정',\n",
       " '체형성형',\n",
       " '체형성형전문',\n",
       " '초대합니다',\n",
       " '초등수학문제집',\n",
       " '초등수학문제집추천',\n",
       " '초등학교',\n",
       " '촬영',\n",
       " '최고',\n",
       " '최고의',\n",
       " '최저가',\n",
       " '최초',\n",
       " '추천',\n",
       " '추천드려요',\n",
       " '추천합니다',\n",
       " '추천해요',\n",
       " '축구',\n",
       " '축산항',\n",
       " '춘천',\n",
       " '출산후',\n",
       " '출시',\n",
       " '치료',\n",
       " '카눈에서',\n",
       " '카메라',\n",
       " '카페',\n",
       " '캐논',\n",
       " '커피',\n",
       " '컬러',\n",
       " '컬렉션',\n",
       " '코디',\n",
       " '코성형',\n",
       " '코스',\n",
       " '코스티비',\n",
       " '코스티비에서',\n",
       " '코재수술',\n",
       " '쾌적한',\n",
       " '쿠션',\n",
       " '클럽',\n",
       " '키성장영양제',\n",
       " '키앤지',\n",
       " '키워보세요',\n",
       " '탐방',\n",
       " '테니스',\n",
       " '테스트',\n",
       " '토끼입니까',\n",
       " '토익',\n",
       " '통영',\n",
       " '통해',\n",
       " '통해서',\n",
       " '투어',\n",
       " '트렌드',\n",
       " '특별한',\n",
       " '틴트',\n",
       " '파이',\n",
       " '파이썬',\n",
       " '파티',\n",
       " '패션',\n",
       " '편안한',\n",
       " '편하게',\n",
       " '포르쉐',\n",
       " '포인트',\n",
       " '포켓몬스터',\n",
       " '포토샵',\n",
       " '풍경',\n",
       " '풍경들',\n",
       " '프랑스',\n",
       " '프로',\n",
       " '프로야구',\n",
       " '프로젝트',\n",
       " '프리미엄',\n",
       " '프리뷰',\n",
       " '프리존',\n",
       " '플러스',\n",
       " '피규어',\n",
       " '피는',\n",
       " '피부',\n",
       " '피아노',\n",
       " '필기',\n",
       " '필름사진',\n",
       " '필리핀',\n",
       " '필요한',\n",
       " '하고',\n",
       " '하기',\n",
       " '하나',\n",
       " '하는',\n",
       " '하루',\n",
       " '하면',\n",
       " '하세요',\n",
       " '하이브리드',\n",
       " '하자',\n",
       " '학원',\n",
       " '한국',\n",
       " '한국어교원자격증',\n",
       " '한국정보인증',\n",
       " '한글',\n",
       " '한남동',\n",
       " '한번',\n",
       " '한번에',\n",
       " '한우',\n",
       " '할까',\n",
       " '할로윈',\n",
       " '할로윈데이',\n",
       " '함께',\n",
       " '함께하는',\n",
       " '함께하세요',\n",
       " '함께한',\n",
       " '함락',\n",
       " '합격',\n",
       " '합니다',\n",
       " '합리적인',\n",
       " '핫한',\n",
       " '해결',\n",
       " '해결하세요',\n",
       " '해독주스',\n",
       " '해보세요',\n",
       " '해야',\n",
       " '해외',\n",
       " '해외선물',\n",
       " '해외야구중계',\n",
       " '해요',\n",
       " '해운대',\n",
       " '해주는',\n",
       " '핵티비',\n",
       " '핵티비로',\n",
       " '행사',\n",
       " '현대',\n",
       " '현충원본가',\n",
       " '형제발레리노',\n",
       " '혜택',\n",
       " '호텔',\n",
       " '혼다',\n",
       " '홍대',\n",
       " '홍천',\n",
       " '홍천펜션',\n",
       " '홍콩',\n",
       " '화담숲참숯화로',\n",
       " '화장품',\n",
       " '확인하세요',\n",
       " '황금새우나라',\n",
       " '횟집',\n",
       " '효과',\n",
       " '후기',\n",
       " '휴가']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_Title.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer_Title,open(\"tfidf_title_.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_load = pickle.load(open(\"tfidf_title_.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_load.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_len = test_df['Text_len'].reset_index(drop=True)\n",
    "Img_cnt = test_df['img_count'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_result = pd.DataFrame(tfidf_Text.toarray())\n",
    "Title_result = pd.DataFrame(tfidf_Title.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([Text_result,Title_result],axis=1)\n",
    "y = y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x , y , test_size=0.1 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13621, 3000), (13621,), (1514, 3000), (1514,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=42, solver='sag',\n",
       "          tol=0.0001, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "logreg = linear_model.LogisticRegression(C=2.0,random_state=42,solver='sag',multi_class='multinomial',warm_start=True)\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117569352708058"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# model_save\n",
    "model_name = 'Category_model.pkl'\n",
    "pickle.dump(logreg, open(model_name, 'wb'))\n",
    "# model_load\n",
    "logreg = pickle.load(open(model_name, 'rb'))\n",
    "accuracy_score(logreg.predict(x_test), y_test)\n",
    "import pickle\n",
    "logreg = pickle.load(open(model_name, 'rb'))\n",
    "accuracy_score(logreg.predict(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85869565, 0.86466165, 0.81318681, 0.83739837, 0.57142857,\n",
       "       0.79365079, 0.30434783, 0.76363636, 0.92857143, 0.84393064,\n",
       "       0.69333333, 0.609375  , 0.66666667, 0.61538462, 0.59259259,\n",
       "       0.82608696, 0.87323944, 0.93142857])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(logreg.predict(x_test), y_test,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.86      0.82        92\n",
      "          1       0.86      0.86      0.86       133\n",
      "          2       0.83      0.81      0.82        91\n",
      "          3       0.90      0.84      0.87       123\n",
      "          4       0.72      0.57      0.64        63\n",
      "          5       0.91      0.79      0.85        63\n",
      "          6       0.64      0.30      0.41        23\n",
      "          7       0.82      0.76      0.79        55\n",
      "          8       0.84      0.93      0.88       154\n",
      "          9       0.67      0.84      0.74       173\n",
      "         10       0.68      0.69      0.69        75\n",
      "         11       0.66      0.61      0.63        64\n",
      "         12       0.86      0.67      0.75        27\n",
      "         13       0.89      0.62      0.73        13\n",
      "         14       0.84      0.59      0.70        27\n",
      "         15       0.94      0.83      0.88        92\n",
      "         16       0.94      0.87      0.91        71\n",
      "         17       0.86      0.93      0.89       175\n",
      "\n",
      "avg / total       0.82      0.81      0.81      1514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, logreg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실제 맛집 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class textclass:\n",
    "    def Extract_structure_and_tag(User_id, Post_id):\n",
    "        url = \"http://blog.naver.com/PostView.nhn?blogId=\" + User_id + \"&logNo=\" + Post_id + \"&redirect=Dlog&widgetTypeCall=true\"\n",
    "        r = requests.get(url)\n",
    "        bs = BeautifulSoup(re.sub('&nbsp;', ' ', r.text).encode(\"utf-8\"), \"html.parser\")\n",
    "        # structure\n",
    "        structure = bs.find(\"div\", {\"id\": \"postViewArea\"})\n",
    "        if structure == None:\n",
    "            structure = bs.find(\"div\", {\"class\", \"se_component_wrap sect_dsc __se_component_area\"})\n",
    "\n",
    "        structure_p_img_tag = structure.find_all(['p', 'img'])\n",
    "        structure_dict = {'structure': structure, 'structure_p_img_tag': structure_p_img_tag}\n",
    "        # structure_p_img_tag : p,img tag만 extract\n",
    "        # structure : 모든 tag 가져오기\n",
    "        return structure_dict\n",
    "\n",
    "    # Extract_structure_and_tag 함수의 'structure_p_img_tag' 값을 가져와야함.\n",
    "\n",
    "    def HTML_preprocessing(structure_p_img_tag):\n",
    "        # only tag & text extract\n",
    "        tag_list = []\n",
    "        text_list = []\n",
    "        for i in structure_p_img_tag:\n",
    "            # p_tag만 불러오기\n",
    "            if \"<p\" in (str(i)):\n",
    "                tag_list.append('<p>')\n",
    "                # img만 있을 때\n",
    "\n",
    "                if '<img' in str(i):\n",
    "                    for j in i:\n",
    "                        try:\n",
    "                            if len(j.text) > 1:\n",
    "                                tag_list.append('<br>')\n",
    "                                text_list.append(j.text)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                # img가 아닌 경우 span tag가 더 있을 때\n",
    "                elif '<span' in str(i):\n",
    "                    for j in i:\n",
    "                        if '<br' in str(j):\n",
    "                            text_list.append(j.text)\n",
    "                            # br_tag가 2개 이상 있을 때\n",
    "\n",
    "                            if len(j.findAll('br')) > 2:\n",
    "                                for _ in range(0, len(j.findAll('br'))):\n",
    "                                    tag_list.append('<br>')\n",
    "\n",
    "                            # br_tag가 1개 있을 때\n",
    "                            else:\n",
    "                                tag_list.append('<br>')\n",
    "\n",
    "                        # span은 있지만 br tag가 없을 때\n",
    "                        else:\n",
    "                            try:\n",
    "                                text_list.append(j.text)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                # 그냥 p_tag만 있을 때 br_tag 추가\n",
    "                else:\n",
    "                    # 글이 있을 때\n",
    "                    if len(i.text) > 1:\n",
    "                        text_list.append(i.text)\n",
    "\n",
    "                    # 글 없이 br tag만 있을 때\n",
    "                    else:\n",
    "                        tag_list.append('<br>')\n",
    "                        text_list.append(i.text)\n",
    "\n",
    "                # P_tag 끝맽음\n",
    "                tag_list.append('</p>')\n",
    "\n",
    "            else:\n",
    "                tag_list.append('<img>')\n",
    "\n",
    "        text_list = list(map(remove_odd, text_list))\n",
    "        filter_text = list(filter(lambda x: len(x) > 1, text_list))\n",
    "\n",
    "        Text = \" \".join(list(filter(lambda x: len(x) > 1, map(lambda x: x.strip(), text_list))))\n",
    "        Text = re.sub('\\n', '', Text)\n",
    "        Text = re.sub('\\t', '', Text)\n",
    "        Space_text = \" \".join(Spacing_text(filter_text))\n",
    "        Count_space_mistake = len(Space_text) - len(Text)\n",
    "\n",
    "        # only tag\n",
    "        Structure_only_tag = \"|\".join(tag_list)\n",
    "        Structure_only_tag_df = pd.DataFrame({'text': [Structure_only_tag]})\n",
    "        array_temp = Structure_only_tag_df['text'].apply(\n",
    "            lambda x: \" img \".join(list(map(lambda x: 'text' if len(x) > 3 else '', x.split('<img>')))).strip().replace(\n",
    "                '  ', ' ')).values\n",
    "        refined_structure = ''.join(array_temp)\n",
    "\n",
    "        HTML_preprocessing = {'Text': Text, 'refined_structure': refined_structure,\n",
    "                              'Count_space_mistake': Count_space_mistake}\n",
    "\n",
    "        return HTML_preprocessing\n",
    "\n",
    "    def sentimental_analysis(text):\n",
    "        pos_word_list = []\n",
    "        neg_word_list = []\n",
    "        \n",
    "        pos_ratio = 0.000000001\n",
    "        neg_ratio = 0.000000001\n",
    "        subjectivity = 0.000000001\n",
    "        polarity = 0.000000001\n",
    "        senti_diffs_per_ref = 0.000000001\n",
    "\n",
    "        if text == '':\n",
    "            sentiment_dict = {'pos_ratio': pos_ratio, 'neg_ratio': neg_ratio, 'subjectivity': subjectivity,\n",
    "                              'polarity': polarity, 'senti_diffs_per_ref': senti_diffs_per_ref}\n",
    "            return sentiment_dict, pos_word_list, neg_word_list\n",
    "        else:\n",
    "            pos = 0\n",
    "            neg = 0\n",
    "            text = text.split(' ')\n",
    "            n = len(text)\n",
    "            for i in text:\n",
    "                i = remove_odd(i)\n",
    "                pre = kkma.pos(i)\n",
    "                test = ';'.join(['/'.join(i) for i in pre])\n",
    "                if test in word_list:\n",
    "                    if label[word_list.index(test)] == 'POS':\n",
    "                        pos += 1\n",
    "                        pos_word_list.append(test)\n",
    "                    elif label[word_list.index(test)] == 'NEG':\n",
    "                        neg += 1\n",
    "                        neg_word_list.append(test)\n",
    "            try:\n",
    "                pos_ratio = pos / n\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                neg_ratio = neg / n\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                subjectivity = (neg + pos) / n\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                polarity = (neg - pos) / (neg + pos)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                senti_diffs_per_ref = (pos - neg) / n\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            sentiment_dict = {'pos_ratio': pos_ratio, 'neg_ratio': neg_ratio, 'subjectivity': subjectivity,\n",
    "                              'polarity': polarity, 'senti_diffs_per_ref': senti_diffs_per_ref}\n",
    "            return sentiment_dict, pos_word_list, neg_word_list\n",
    "\n",
    "    def check_First_second(Text):\n",
    "        first_person = ['나/NP', '저/NP', '내/NP', '제/NP', '저희/NP', '우리/NP']\n",
    "        second_person = ['너/NP', '자네/NP', '당신/NP', '그대/NP', '그쪽/NP', '너희/NP', '자기/NP']\n",
    "        First = 0\n",
    "        Second = 0\n",
    "        if Text == '':\n",
    "            check_First_second_dict = {'First': First, 'Second': Second}\n",
    "            return check_First_second_dict\n",
    "        else:\n",
    "            text = kkma.pos(Text)\n",
    "            for i in text:\n",
    "                temp = \"/\".join(i)\n",
    "                if temp in first_person:\n",
    "                    First += len(temp.split('/')[0])\n",
    "                if temp in second_person:\n",
    "                    Second += len(temp.split('/')[0])\n",
    "            check_First_second_dict = {'First_ratio': First/len(Text), 'Second_ratio': Second/len(Text)}\n",
    "            return check_First_second_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spacing_text(text_list):\n",
    "    spacing_list = []\n",
    "    for i in text_list:\n",
    "        if len(i) < 197:\n",
    "            spacing_list.append(spacing(i))\n",
    "        else:\n",
    "            iteration = int(len(i) / 197)\n",
    "            mod = len(i) % 197\n",
    "            start = 0\n",
    "            end = 197\n",
    "            check = 0\n",
    "            while True:\n",
    "                # 시행횟수 < 몫\n",
    "                if check < iteration:\n",
    "                    spacing_list.append(spacing(i[start:end]))\n",
    "                    start += 197\n",
    "                    end += 197\n",
    "                    check += 1\n",
    "                else:\n",
    "                    # 마지막 횟수 + 나머지 더 slice\n",
    "                    spacing_list.append(spacing(i[iteration * 197:(iteration * 197) + mod]))\n",
    "                    break\n",
    "    return spacing_list\n",
    "\n",
    "def remove_odd(x):\n",
    "    x = re.sub(\"nbsp\", \" \", x)\n",
    "    x = re.sub(\"\\xa0\", \"\", x)\n",
    "    x = re.sub(\"\\u200b\", \"\", x)\n",
    "    x = re.sub(\"\\n\", \"\", x)\n",
    "    x = re.sub(\"\\t\", \"\", x)\n",
    "    x = re.sub('   ', ' ', x)\n",
    "    return x\n",
    "\n",
    "def tfidf_vectorizer(Text):\n",
    "    try:\n",
    "        return v_load.transform([Text]).toarray().flatten()\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex1 https://blog.naver.com/you-n-mi?Redirect=Log&logNo=221352751222\n",
    "# ex2 https://blog.naver.com/sky_sea11?Redirect=Log&logNo=221216249472\n",
    "# ex3 https://blog.naver.com/jhforever48/221154182850\n",
    "# ex4 https://blog.naver.com/soundbross?Redirect=Log&logNo=221403690848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_id = ['you-n-mi','sky_sea11','jhforever48','soundbross','senti54','0105114a']\n",
    "Post_id = ['221352751222','221216249472','221154182850','221403690848','221401308842','221269157353']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yonggeol/miniconda3/envs/py/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from pykospacing import spacing\n",
    "import pandas as pd\n",
    "from konlpy.tag import Kkma\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "title_list = []\n",
    "for User_id,Post_id in list(zip(User_id, Post_id)):\n",
    "    url = \"http://blog.naver.com/PostView.nhn?blogId=\" + User_id + \"&logNo=\" + Post_id + \"&redirect=Dlog&widgetTypeCall=true\"\n",
    "    mobile_url = \"http://m.blog.naver.com/PostView.nhn?blogId=\"+ User_id\n",
    "    opening_url = 'http://blog.naver.com/profile/intro.nhn?blogId='+ User_id\n",
    "    structure = textclass.Extract_structure_and_tag(User_id,Post_id)\n",
    "    all_tag = structure['structure']\n",
    "    p_img_tag = structure['structure_p_img_tag']\n",
    "    HTML_preprocessing = textclass.HTML_preprocessing(p_img_tag)\n",
    "    text = HTML_preprocessing['Text']\n",
    "    text_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://blog.naver.com/PostView.nhn?blogId=\" + User_id + \"&logNo=\" + Post_id + \"&redirect=Dlog&widgetTypeCall=true\"\n",
    "r = requests.get(url)\n",
    "bs = BeautifulSoup(re.sub('&nbsp;', ' ', r.text).encode(\"utf-8\"), \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = bs.find(\"h3\", {\"class\": \"se_textarea\"})\n",
    "\n",
    "# 스마트에디터3 타이틀 제거 임시 적용 (클래스가 다름)\n",
    "if (title == None):\n",
    "    title = post.find(\"span\", {\"class\": \"pcol1 itemSubjectBoldfont\"})\n",
    "if (title != None):\n",
    "    title = title.text.strip()\n",
    "else:\n",
    "    title = \"TITLE ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfidf_model로 교체\n",
    "text_vec = vectorizer_Text.transform([text])\n",
    "title_vec = vectorizer_Title.transform([title])\n",
    "text_vec = pd.DataFrame(text_vec.toarray())\n",
    "title_vec = pd.DataFrame(title_vec.toarray())\n",
    "x = pd.concat([text_vec,title_vec],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction class\n",
    "Category[logreg.predict(x)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_id = 'newpark314'\n",
    "Post_id = '221387605004'\n",
    "\n",
    "url = \"http://blog.naver.com/PostView.nhn?blogId=\" + User_id + \"&logNo=\" + Post_id + \"&redirect=Dlog&widgetTypeCall=true\"\n",
    "mobile_url = \"http://m.blog.naver.com/PostView.nhn?blogId=\"+ User_id\n",
    "opening_url = 'http://blog.naver.com/profile/intro.nhn?blogId='+ User_id\n",
    "structure = textclass.Extract_structure_and_tag(User_id,Post_id)\n",
    "all_tag = structure['structure']\n",
    "p_img_tag = structure['structure_p_img_tag']\n",
    "HTML_preprocessing = textclass.HTML_preprocessing(p_img_tag)\n",
    "text = HTML_preprocessing['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_Text = pickle.load(open('tfidf_text.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15135x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 972880 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_Text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
