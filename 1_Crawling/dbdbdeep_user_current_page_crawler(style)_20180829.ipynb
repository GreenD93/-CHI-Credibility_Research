{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AjouHCI\\Miniconda3\\envs\\study\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import urllib\n",
    "import requests\n",
    "import shutil \n",
    "from selenium import webdriver\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pykospacing import spacing\n",
    "import pandas as pd\n",
    "import copy\n",
    "import string, random ## generate random str package\n",
    "from collections import OrderedDict ## repetition removal package\n",
    "from collections import Counter\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hangul(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글과 띄어쓰기를 제외한 모든 글자\n",
    "    # hangul = re.compile('[^ \\u3131-\\u3163\\uac00-\\ud7a3]+')  # 위와 동일\n",
    "    result = hangul.sub('', text) # 한글과 띄어쓰기를 제외한 모든 부분을 제거\n",
    "    return str(result)\n",
    "\n",
    "def find_categories():\n",
    "    test = driver.find_elements_by_css_selector(\"body > div.lyr_category_lst1 > ul > li:nth-child(1) > ul > li > a\")\n",
    "    Categories = []\n",
    "    for i in test:\n",
    "        Categories.append(i.text.split(\"\\n\")[:2])\n",
    "    Count_Categories = len(Categories)\n",
    "    return Categories, Count_Categories\n",
    "\n",
    "def find_post_id():\n",
    "    post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "    r = re.compile('logNo=.*')\n",
    "    string = r.findall(post.get_attribute('ng-href'))\n",
    "    return re.sub(\"logNo=\",'',\"\".join(string))\n",
    "\n",
    "def random_id():\n",
    "    passkey= '' # an empty str key\n",
    "    for x in range(10): # length of the random passkeys\n",
    "\n",
    "        if random.choice([1,2]) == 1:\n",
    "            passkey += passkey.join(random.choice(string.ascii_letters)) # upper & lower cased letter\n",
    "        else:\n",
    "            passkey += passkey.join(random.choice(string.digits)) # numbers\n",
    "    return passkey\n",
    "\n",
    "def Spacing_text(text_list):\n",
    "    spacing_list = []\n",
    "    for i in text_list:\n",
    "        if len(i) < 197:\n",
    "            spacing_list.append(spacing(i))\n",
    "        else:\n",
    "            iteration = int(len(i) / 197)\n",
    "            mod = len(i) % 197\n",
    "            start = 0\n",
    "            end = 197\n",
    "            check = 0\n",
    "            while True:\n",
    "                # 시행횟수 < 몫\n",
    "                if check < iteration:\n",
    "                    spacing_list.append(spacing(i[start:end]))\n",
    "                    start+=197\n",
    "                    end+=197\n",
    "                    check +=1\n",
    "                else:\n",
    "                    # 마지막 횟수 + 나머지 더 slice \n",
    "                    spacing_list.append(spacing(i[iteration*197:(iteration*197)+mod]))\n",
    "                    break\n",
    "    return spacing_list\n",
    "\n",
    "def remove_odd(x):\n",
    "    x = re.sub(\"&nbsp\",\" \",x)\n",
    "    x = re.sub(\"nbsp\",\" \",x)\n",
    "    x = re.sub(\"\\xa0\",\"\",x)\n",
    "    x = re.sub(\"\\u200b\",\"\",x)\n",
    "    x = re.sub(\"\\n\",\"\",x)\n",
    "    x = re.sub(\"\\t\",\"\",x)\n",
    "    x = re.sub(\"\\r\",\"\",x)\n",
    "    x = re.sub('   ',' ',x)\n",
    "    return x.strip()\n",
    "\n",
    "def find_rgb(value):\n",
    "    p = re.compile('rgb.*\\)')\n",
    "    rgb = p.findall(value)\n",
    "    rgb = str(rgb[0])\n",
    "    return rgb\n",
    "\n",
    "def numeric_value(string):\n",
    "    number = re.sub('[^0-9]', '', string) \n",
    "    return(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comment():\n",
    "    def Get_Comment_Text():\n",
    "        # Comment\n",
    "        comment_list = []\n",
    "        comments = driver.find_elements_by_class_name('u_cbox_text_wrap')\n",
    "        for comment in comments:\n",
    "            comment_list.append(comment.text)\n",
    "        return comment_list\n",
    "    \n",
    "    def Get_Comment_Time():\n",
    "        comment_times = driver.find_elements_by_class_name('u_cbox_date')\n",
    "        comment_time = []\n",
    "        for time in comment_times:\n",
    "            comment_time.append(time.text)\n",
    "        return comment_time\n",
    "    \n",
    "    def Get_Comment_ID(post_no):\n",
    "        comments_href = driver.find_elements_by_class_name('u_cbox_nick')\n",
    "        comment_user_list = []\n",
    "        for i in range(0,len(comments_href)):\n",
    "            comments_href[i].click()\n",
    "            window_before = driver.window_handles[0]\n",
    "            window_after = driver.window_handles[1]\n",
    "            driver.switch_to_window(window_after)\n",
    "            driver.implicitly_wait(10)\n",
    "            comment_user_list.append(driver.current_url)\n",
    "            driver.close()\n",
    "            driver.switch_to_window(window_before)\n",
    "        # comment단 사람 Id 추출\n",
    "        comment_user_id = []\n",
    "\n",
    "        for url in comment_user_list:\n",
    "\n",
    "            if '?' in url: \n",
    "                comment_user_id.append(re.sub(\"https://blog.naver.com/\",\"\",url).split(\"?\")[0])\n",
    "\n",
    "            elif 'blog.me' in url:\n",
    "                url_temp = re.sub(\"https://\",\"\",url).split(\".\")\n",
    "                comment_user_id.append(url_temp[0])\n",
    "\n",
    "            else:\n",
    "                url_temp = re.sub(\"https://blog.naver.com/\",\"\",url).split(\"/\")\n",
    "                comment_user_id.append(url_temp[0])\n",
    "        return comment_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Post_Id_Get_1():\n",
    "    foot_info = driver.find_element_by_class_name('wrap_postcomment').get_attribute('innerHTML')\n",
    "    p = re.compile('id=\"area_sympathy.*\" ')\n",
    "    post_id_string = p.findall(foot_info)\n",
    "    if post_id_string == []:\n",
    "        p = re.compile('id=\"Comi.*\" ')\n",
    "        post_id_string = p.findall(foot_info)\n",
    "    remove_quotes = re.sub('\"','',str(post_id_string[0]))\n",
    "    post_no = \"\".join(list(filter(str.isdigit,remove_quotes)))\n",
    "    return post_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Post_Id_Get_2():\n",
    "    #게시글 번호 따오기\n",
    "\n",
    "    foot_info = driver.find_element_by_id('postViewArea').get_attribute('innerHTML')\n",
    "    p = re.compile('postViewArea.*\"')\n",
    "    post_id_string = \"\".join(p.findall(foot_info))\n",
    "\n",
    "    post_id_string = re.sub('postViewArea','',post_id_string)\n",
    "    post_id_string = re.sub('\"','',post_id_string)\n",
    "    return post_id_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Opening_Date_Get(user_id,driver):\n",
    "    opening_url = 'http://blog.naver.com/profile/intro.nhn?blogId='+ user_id\n",
    "    #driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "    driver.get(opening_url)\n",
    "    driver.implicitly_wait(10)\n",
    "    try:\n",
    "        driver.find_element_by_id('category2').click()\n",
    "        driver.implicitly_wait(10)\n",
    "        years = driver.find_elements_by_css_selector('#post-area > div:nth-child(4) > table:nth-child(2) > tbody > tr > td > table > tbody > tr > td > table > tbody > tr:nth-child(3) > td:nth-child(2)')\n",
    "        for year in years:\n",
    "            if len(year.text) > 4:\n",
    "                blog_opening_date = year.text\n",
    "        driver.close()\n",
    "        return blog_opening_date\n",
    "    \n",
    "    except:\n",
    "        driver.close()\n",
    "        return 'hide'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comment_Sympath_Count():\n",
    "    p = re.compile('[0-9]')\n",
    "    sympathy_count = 'hide'\n",
    "    comment_count = 'hide'\n",
    "    footer_list = driver.find_elements_by_class_name('wrap_postcomment')[0].text.split('\\n')\n",
    "    if footer_list == ['']:\n",
    "        return sympathy_count, comment_count\n",
    "    else:\n",
    "        for foot in footer_list:\n",
    "            if '공감' in foot:\n",
    "                sympathy_count = \"\".join(p.findall(foot))\n",
    "                if sympathy_count == '':\n",
    "                    sympathy_count = 0\n",
    "            if '댓글' in foot:\n",
    "                comment_count = \"\".join(p.findall(foot))\n",
    "                if comment_count == '':\n",
    "                    comment_count = 0\n",
    "        return sympathy_count, comment_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comment():\n",
    "    def Get_Comment_Text():\n",
    "        # Comment\n",
    "        comment_list = []\n",
    "        comments = driver.find_elements_by_class_name('u_cbox_text_wrap')\n",
    "        for comment in comments:\n",
    "            comment_list.append(remove_odd(comment.text))\n",
    "        return comment_list\n",
    "    \n",
    "    def Get_Comment_Time():\n",
    "        comment_times = driver.find_elements_by_class_name('u_cbox_date')\n",
    "        comment_time = []\n",
    "        for time in comment_times:\n",
    "            comment_time.append(time.text)\n",
    "        return comment_time\n",
    "    \n",
    "#     def Get_Comment_ID(post_no):\n",
    "#         comments_href = driver.find_elements_by_class_name('u_cbox_nick')\n",
    "#         comment_user_list = []\n",
    "#         for i in range(0,len(comments_href)):\n",
    "#             comments_href[i].click()\n",
    "#             window_before = driver.window_handles[0]\n",
    "#             window_after = driver.window_handles[1]\n",
    "#             driver.switch_to_window(window_after)\n",
    "#             driver.implicitly_wait(10)\n",
    "#             comment_user_list.append(driver.current_url)\n",
    "#             driver.close()\n",
    "#             driver.switch_to_window(window_before)\n",
    "#         # comment단 사람 Id 추출\n",
    "#         comment_user_id = []\n",
    "\n",
    "#         for url in comment_user_list:\n",
    "\n",
    "#             if '?' in url: \n",
    "#                 comment_user_id.append(re.sub(\"https://blog.naver.com/\",\"\",url).split(\"?\")[0])\n",
    "\n",
    "#             elif 'blog.me' in url:\n",
    "#                 url_temp = re.sub(\"https://\",\"\",url).split(\".\")\n",
    "#                 comment_user_id.append(url_temp[0])\n",
    "\n",
    "#             else:\n",
    "#                 url_temp = re.sub(\"https://blog.naver.com/\",\"\",url).split(\"/\")\n",
    "#                 comment_user_id.append(url_temp[0])\n",
    "#         return comment_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sympathy_Comment_Id_Get(post_no):\n",
    "    try:\n",
    "        footer_list = driver.find_elements_by_class_name('wrap_postcomment')[0].text.split('\\n')\n",
    "        sympathy_user_id = 'hide'\n",
    "        comment_user_id = 'hide'\n",
    "        comment_list = 'hide'\n",
    "        comment_time = 'hide'\n",
    "\n",
    "        if footer_list ==['']:\n",
    "            sympathy_user_id = 'hide'\n",
    "            comment_user_id = 'hide'\n",
    "            comment_list = 'hide'\n",
    "            comment_time = 'hide'\n",
    "            return sympathy_user_id, comment_user_id , comment_list, comment_time\n",
    "\n",
    "        # 공감이 있는지, 댓글이 있는지 없는지 check 해주어야함.\n",
    "\n",
    "        for number ,foot in enumerate(footer_list):\n",
    "\n",
    "            if '공감' in foot:\n",
    "                sympathy_user_id = []\n",
    "                driver.find_elements_by_class_name('bu_arr')[number].click()\n",
    "                # 공감한 사람 ID 찾기\n",
    "                driver.implicitly_wait(3)\n",
    "                sympathy_url = driver.find_element_by_id('sympathyFrm'+str(post_no)).get_attribute('src')\n",
    "                driver.find_elements_by_class_name('bu_arr')[number].click()\n",
    "\n",
    "                # 공감한 블로거 화면으로 전환\n",
    "                driver.get(sympathy_url)\n",
    "                driver.implicitly_wait(10)\n",
    "                users_href = driver.find_elements_by_css_selector('#post-area > ul > li > div > div.bloger > span.area_text.pcol2 > strong > span > a')\n",
    "                sympath_user_list = []\n",
    "                for user in users_href:\n",
    "                    sympath_user_list.append(user.get_attribute('href'))\n",
    "                driver.back()\n",
    "\n",
    "                # 공감한 블로거 아이디 추출\n",
    "                for url in sympath_user_list:\n",
    "                    if 'DomainDispatcher' in url:\n",
    "                        p = re.compile('id=.*&ty')\n",
    "                        string = p.findall(url)\n",
    "                        string = re.sub('id=','',string[0])\n",
    "                        string = re.sub('&ty','',string)\n",
    "                    else:\n",
    "                        url_temp = re.sub(\"http://blog.naver.com/\",\"\",url).split(\"/\")\n",
    "                        sympathy_user_id.append(url_temp[0])\n",
    "\n",
    "            elif '댓글' in foot:\n",
    "                comment_user_id = []\n",
    "                # 댓글쓴 사람 ID들 찾기\n",
    "\n",
    "                driver.find_elements_by_class_name('bu_arr')[number].click()\n",
    "                comment_list = Comment.Get_Comment_Text()\n",
    "                comment_time = Comment.Get_Comment_Time()\n",
    "\n",
    "                comments_href = driver.find_elements_by_class_name('u_cbox_nick')\n",
    "                comment_user_list = []\n",
    "                for i in range(0,len(comments_href)):\n",
    "                    comments_href[i].click()\n",
    "                    window_before = driver.window_handles[0]\n",
    "                    window_after = driver.window_handles[1]\n",
    "                    driver.switch_to_window(window_after)\n",
    "                    driver.implicitly_wait(10)\n",
    "                    comment_user_list.append(driver.current_url)\n",
    "                    driver.close()\n",
    "                    driver.switch_to_window(window_before)\n",
    "\n",
    "                # comment단 사람 Id 추출\n",
    "                for url in comment_user_list:\n",
    "\n",
    "                    if '?' in url: \n",
    "                        comment_user_id.append(re.sub(\"https://blog.naver.com/\",\"\",url).split(\"?\")[0])\n",
    "\n",
    "                    elif 'blog.me' in url:\n",
    "                        url_temp = re.sub(\"https://\",\"\",url).split(\".\")\n",
    "                        comment_user_id.append(url_temp[0])\n",
    "\n",
    "                    else:\n",
    "                        url_temp = re.sub(\"https://blog.naver.com/\",\"\",url).split(\"/\")\n",
    "                        comment_user_id.append(url_temp[-1])\n",
    "            if comment_user_id == [] or comment_user_id == ['']:\n",
    "                comment_list = []\n",
    "                comment_time = []\n",
    "            if sympathy_user_id == [] or sympathy_user_id == ['']:\n",
    "                sympathy_user_id = []\n",
    "\n",
    "        return sympathy_user_id, comment_user_id , comment_list, comment_time\n",
    "    \n",
    "    except:\n",
    "        sympathy_user_id = []\n",
    "        comment_user_id = []\n",
    "        comment_list = []\n",
    "        comment_time = []\n",
    "        \n",
    "        \n",
    "        return sympathy_user_id, comment_user_id , comment_list, comment_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_user_id(url):\n",
    "    \n",
    "    if '?' in url: \n",
    "        User_id =re.sub(\"https://blog.naver.com/\",\"\",url).split(\"?\")[0]\n",
    "\n",
    "    elif 'blog.me' in url:\n",
    "        url_temp = re.sub(\"https://\",\"\",url).split(\".\")\n",
    "        temp_Post_id = url\n",
    "        User_id = url_temp[0]\n",
    "\n",
    "    else:\n",
    "        url_temp = re.sub(\"https://blog.naver.com/\",\"\",url).split(\"/\")\n",
    "        User_id = url_temp[0]\n",
    "        \n",
    "    return User_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_csv 작성\n",
    "csv_name = 'dbdbdeep_page_user_table.csv'\n",
    "col_name = \"\\t\".join([\"User_id\",\"Blog_name\",\"Blog_nickname\",\"Blog_info_text\",\"Count_neighbors\",\"Count_visitors\",\"Categories\",\"Count_categories\",\"Total_post\",\"Credibility\",\"Source\",\"Blog_mobile_profile_img\",\"Blog_mobile_cover_img\",'Opening_date'])\n",
    "\n",
    "if not os.path.exists(csv_name):\n",
    "    with open(csv_name, 'w') as f:\n",
    "        f.write(col_name+'\\n')\n",
    "        \n",
    "# post_csv 작성\n",
    "post_csv_name = 'dbdbdeep_page_post_table.csv'\n",
    "post_col_name = \"\\t\".join([\"Post_id\",\"User_id\",\"Category\",\"Title\",\"Date\",\"Structure\",\"Structure_tag\",\"Text\",\"Space_text\",\"Count_space_mistake\",\"Map_exist\",\"Media_count\",\"Heart_count\",\"Sticker_count\",\"Comment_count\"])\n",
    "if not os.path.exists(post_csv_name):\n",
    "    with open(post_csv_name, 'w') as f:\n",
    "        f.write(post_col_name +'\\n')\n",
    "\n",
    "# img_csv 작성\n",
    "img_csv_name = 'dbdbdeep_page_img_table.csv'\n",
    "img_col_name = \"\\t\".join([\"Img_id\",\"Post_id\"])\n",
    "if not os.path.exists(img_csv_name):\n",
    "    with open(img_csv_name, 'w') as f:\n",
    "        f.write(img_col_name +'\\n')\n",
    "\n",
    "# tag_csv 작성\n",
    "tag_csv_name = 'dbdbdeep_page_tag_table.csv'\n",
    "tag_col_name = \"\\t\".join([\"Post_id\",\"Post_tag\"])\n",
    "if not os.path.exists(tag_csv_name):\n",
    "    with open(tag_csv_name, 'w') as f:\n",
    "        f.write(tag_col_name +'\\n')\n",
    "\n",
    "# Sympathy_csv 작성\n",
    "Sympathy_csv_name = 'dbdbdeep_page_Sympathy_table.csv'\n",
    "Sympathy_col_name = \"\\t\".join([\"Post_id\",\"Sympath_id\"])\n",
    "if not os.path.exists(Sympathy_csv_name):\n",
    "    with open(Sympathy_csv_name, 'w') as f:\n",
    "        f.write(Sympathy_col_name +'\\n')\n",
    "        \n",
    "# Comment_csv 작성\n",
    "Comment_csv_name = 'dbdbdeep_page_Comment_table.csv'\n",
    "Comment_col_name = \"\\t\".join([\"Post_id\",\"Comment_id\",\"Comment_Text\",\"Comment_Time\"])\n",
    "if not os.path.exists(Comment_csv_name):\n",
    "    with open(Comment_csv_name, 'w') as f:\n",
    "        f.write(Comment_col_name +'\\n')\n",
    "        \n",
    "# Post_Style_csv 작성\n",
    "Post_Style_csv_name = 'dbdbdeep_page_Post_style_table.csv'\n",
    "Post_col_name = \"\\t\".join(['Post_id','Align','basic_font','basic_font_size','b_strong_word_list','b_strong_word_len','b_tag_len','color_rgb_list','color_rgb_word_list','color_rgb_word_len','color_tag_len'])\n",
    "if not os.path.exists(Post_Style_csv_name):\n",
    "    with open(Post_Style_csv_name, 'w') as f:\n",
    "        f.write(Post_col_name +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 path설정\n",
    "dbdbdeep_folder = \"C:\\\\Users\\\\AjouHCI\\\\Desktop\\\\Data\\\\dbdbdeep_random\" \n",
    "Base_path = 'C:\\\\workspace\\\\Credibility_Research'\n",
    "Chrome_path = 'C:\\\\workspace\\\\Credibility_Research\\\\Exe_file\\\\chromedriver.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dbdbdeep_user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbdbdeep_user = pd.read_csv('dbdbdeep_post_table.csv',encoding='utf-8',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbdbdeep_user_id = dbdbdeep_user['User_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbdbdeep_user_id = dbdbdeep_user_id.get_values().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우정 1500: ~\n",
    "# 내꺼 ~1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 75/75 [10:19:57<00:00, 495.96s/it]\n"
     ]
    }
   ],
   "source": [
    "move_path = dbdbdeep_folder\n",
    "\n",
    "for User_id in tqdm(dbdbdeep_user_id):\n",
    "    ## 무작위 User_folder 만들기\n",
    "    Category_path_random = dbdbdeep_folder\n",
    "    os.chdir(Category_path_random)\n",
    "\n",
    "    if not os.path.exists(User_id):\n",
    "        os.makedirs(User_id)\n",
    "\n",
    "    os.chdir(Base_path)\n",
    "\n",
    "    before_Title = ''   \n",
    "    for page in range(2,12):\n",
    "        try:\n",
    "            Category = '무작위'\n",
    "            url = \"http://blog.naver.com/PostList.nhn?blogId=\" + User_id + \"&currentPage=\" + str(page)\n",
    "            r = requests.get(url)\n",
    "            bs = BeautifulSoup(re.sub('&nbsp;',' ',r.text).encode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "            Post_id = User_id + '_' + str(page)\n",
    "\n",
    "            #title\n",
    "            Title = bs.find(\"h3\", {\"class\": \"se_textarea\"})\n",
    "            if (Title == None):\n",
    "                Title = bs.find(\"span\", {\"class\": \"pcol1 itemSubjectBoldfont\"})\n",
    "            if (Title != None):\n",
    "                Title = Title.text.strip()\n",
    "            else:\n",
    "                Title = \"TITLE ERROR\"\n",
    "\n",
    "\n",
    "            if before_Title == Title:\n",
    "                break\n",
    "            else:\n",
    "                before_Title = Title \n",
    "\n",
    "\n",
    "            #date\n",
    "            # Append_value\n",
    "            Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2 fil5\"})\n",
    "\n",
    "            if Date == None:\n",
    "                Date = bs.find(\"p\",{\"class\":\"date fil5 pcol2 _postAddDate\"})\n",
    "            if Date == None:\n",
    "                Date = bs.find(\"span\",{\"class\":\"se_publishDate pcol2\"})\n",
    "\n",
    "            Date_text = re.sub(\"\\n\",\"\",Date.text)\n",
    "            Date = re.sub(\"\\t\",\"\",Date_text)\n",
    "\n",
    "            #Tag, Content_structure, Text\n",
    "\n",
    "            # structure\n",
    "            structure = bs.find(\"div\", {\"id\": \"postViewArea\"})\n",
    "            if structure == None:\n",
    "                structure = bs.find(\"div\",{\"class\",\"se_component_wrap sect_dsc __se_component_area\"})\n",
    "            structure_tag = structure.find_all(['p','img'])\n",
    "\n",
    "            # Align\n",
    "            split_structure =  remove_odd(str(structure)).split('>')\n",
    "            center= 0\n",
    "            left = 0\n",
    "            right = 0\n",
    "            justify = 0\n",
    "            for item in split_structure:\n",
    "                if 'align' or 'ALIGN' in str(item):\n",
    "                    if 'center' in str(item):\n",
    "                        center +=1\n",
    "                    if 'left' in str(item):\n",
    "                        left += 1\n",
    "                    if 'right' in str(item):\n",
    "                        right +=1\n",
    "                    if 'justify' in str(item):\n",
    "                        justify +=1\n",
    "            Align = [left, center, right, justify]\n",
    "\n",
    "            # Font Style\n",
    "            fonts = ['나눔고딕','NanumBarungothic','NanumGothic','NanumMyengjo',\n",
    "            '나눔바른고딕','나눔명조','sans-serif','nanumbarungothic','nanumgothic','nanummyeongjo','돋움','돋움체','굴림','굴림체','바탕','바탕체','궁서','Arial','Tahoma','Times New Roman','Verdana','Couier New']\n",
    "\n",
    "            font_list = []\n",
    "            for item in split_structure:\n",
    "                for font in fonts:\n",
    "                    if font in item:\n",
    "                        font_list.append(font)\n",
    "            cnt = Counter(font_list)\n",
    "            basic_font = cnt.most_common(1)\n",
    "            if basic_font == []:\n",
    "                basic_font = 'default'\n",
    "\n",
    "\n",
    "            ## Font_size\n",
    "            font_size_list = []\n",
    "            for item in split_structure:\n",
    "                if 'font' in item:\n",
    "                    p = re.compile('font-size:.*pt;')\n",
    "                    font_size = p.findall(str(item))\n",
    "                    string = \"\".join(font_size)\n",
    "                    size = numeric_value(string)\n",
    "                    if len(size) < 3 and 0 < len(size):\n",
    "                        font_size_list.append(numeric_value(string))\n",
    "            cnt = Counter(font_size_list)\n",
    "            basic_font_size = cnt.most_common(1)\n",
    "            if basic_font_size == []:\n",
    "                basic_font_size = 'default'\n",
    "\n",
    "            # B,strong_tag \n",
    "            b_strong_tag = structure.find_all(['b','strong'])\n",
    "            ## word는 무조건 remove_odd 하기!!!\n",
    "\n",
    "            b_strong_word_list = []\n",
    "            b_strong_word_len = 0\n",
    "\n",
    "            for item in b_strong_tag:\n",
    "                if len(item.text) > 1 and len(item.text) < 22:\n",
    "                    b_strong_word_list.append(remove_odd(item.text))\n",
    "                    b_strong_word_len += len(remove_odd(item.text))\n",
    "            b_tag_len = len(b_strong_word_list)\n",
    "\n",
    "            ## Color_tag\n",
    "            color_tag =  structure.find_all('span')\n",
    "\n",
    "            ## word는 무조건 remove_odd 하기!!!\n",
    "            color_rgb_list = []\n",
    "            color_rgb_word_list = []\n",
    "            color_rgb_word_len = 0\n",
    "            for item in color_tag:\n",
    "                if 'rgb' in str(item):\n",
    "                    if len(item.text)>1 and len(item.text) < 25:\n",
    "                        color_rgb_list.append(find_rgb(str(item)))\n",
    "                        color_rgb_word_list.append(remove_odd(item.text))\n",
    "                        color_rgb_word_len += len(remove_odd(item.text))      \n",
    "            color_tag_len = len(color_rgb_word_list)\n",
    "\n",
    "            save_content_list = [Post_id,Align,basic_font,basic_font_size,b_strong_word_list,b_strong_word_len,b_tag_len,color_rgb_list,color_rgb_word_list,color_rgb_word_len,color_tag_len]\n",
    "            save_content = \"\\t\".join(list(map(str,save_content_list)))\n",
    "\n",
    "            with open(Post_Style_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_content+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "            structure_tag = structure.find_all(['p','img'])\n",
    "            # only tag & texf extract\n",
    "            tag_list = []\n",
    "            structure_list = []\n",
    "            text_list = []\n",
    "\n",
    "            for i in structure_tag:\n",
    "                # p_tag만 불러오기\n",
    "                if \"<p\" in (str(i)):\n",
    "                    tag_list.append('<p>')\n",
    "                    structure_list.append('<p>')\n",
    "                    # img만 있을 때\n",
    "\n",
    "                    if '<img' in str(i):\n",
    "                        for j in i:\n",
    "                            try:\n",
    "                                if len(j.text)>1:\n",
    "                                    tag_list.append('<br>')\n",
    "                                    structure_list.append('<br>')\n",
    "                                    structure_list.append(j.text)\n",
    "                                    text_list.append(j.text)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                    # img가 아닌 경우 span tag가 더 있을 때\n",
    "                    elif '<span' in str(i):\n",
    "                        for j in i:\n",
    "                            if '<br' in str(j):\n",
    "                                structure_list.append(j.text)\n",
    "                                text_list.append(j.text)\n",
    "                                # br_tag가 2개 이상 있을 때\n",
    "\n",
    "                                if len(j.findAll('br'))>2:\n",
    "                                    for _ in range(0,len(j.findAll('br'))):\n",
    "                                        tag_list.append('<br>')\n",
    "                                        structure_list.append('<br>')\n",
    "\n",
    "                                # br_tag가 1개 있을 때\n",
    "                                else:\n",
    "                                    tag_list.append('<br>')\n",
    "                                    structure_list.append('<br>')\n",
    "\n",
    "                            # span은 있지만 br tag가 없을 때       \n",
    "                            else:\n",
    "                                try:\n",
    "                                    structure_list.append(j.text)\n",
    "                                    text_list.append(j.text)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    # 그냥 p_tag만 있을 때 br_tag 추가\n",
    "                    else:\n",
    "                        # 글이 있을 때\n",
    "                        if len(i.text) > 1:\n",
    "                            structure_list.append(i.text)\n",
    "                            text_list.append(i.text)\n",
    "\n",
    "                        # 글 없이 br tag만 있을 때\n",
    "                        else:\n",
    "                            tag_list.append('<br>')\n",
    "                            structure_list.append(i.text)\n",
    "                            structure_list.append('<br>')\n",
    "                            text_list.append(i.text)\n",
    "\n",
    "                    # P_tag 끝맽음      \n",
    "                    tag_list.append('</p>')\n",
    "                    structure_list.append('</p>')\n",
    "\n",
    "                else:\n",
    "                    tag_list.append('<img>')\n",
    "                    structure_list.append('<img>')\n",
    "\n",
    "\n",
    "            structure_list = list(map(remove_odd,structure_list))\n",
    "            text_list = list(map(remove_odd,text_list))\n",
    "            filter_text = list(filter(lambda x: len(x)>1 ,text_list))\n",
    "\n",
    "            Structure = \"|\".join(list(filter(lambda x: len(x)>1 ,structure_list)))\n",
    "            Structure = remove_odd(Structure)\n",
    "\n",
    "            Text = \" \".join(list(filter(lambda x: len(x)>1 ,map(lambda x : x.strip(),text_list))))\n",
    "            Text = remove_odd(Text)\n",
    "\n",
    "\n",
    "            Space_text = \" \".join(Spacing_text(filter_text))\n",
    "            Space_text = remove_odd(Space_text)\n",
    "\n",
    "            Count_space_mistake = len(Space_text)-len(Text)\n",
    "\n",
    "\n",
    "            # only tag\n",
    "            Structure_tag = \"|\".join(tag_list)\n",
    "            Structure_tag = remove_odd(Structure_tag)\n",
    "\n",
    "\n",
    "            # image download    \n",
    "            imgs = structure.find_all('img')\n",
    "\n",
    "            User_path = os.path.join(move_path,User_id)\n",
    "            os.chdir(User_path)\n",
    "\n",
    "            folder_name = Post_id\n",
    "            if not os.path.exists(folder_name):\n",
    "                os.makedirs(folder_name)\n",
    "\n",
    "\n",
    "            Save_path = os.path.join(User_path,Post_id)\n",
    "\n",
    "\n",
    "            os.chdir(Base_path)\n",
    "\n",
    "            Map_exist = 0\n",
    "            Sticker_count = 0\n",
    "\n",
    "\n",
    "            # Sticker_count로 수정\n",
    "            sticker_img = structure.find_all('a')\n",
    "            for i in sticker_img:\n",
    "                if 'sticker' in str(i):\n",
    "                    Sticker_count += 1\n",
    "\n",
    "            # image download    \n",
    "            imgs = structure.find_all('img')\n",
    "\n",
    "            for img in imgs:\n",
    "\n",
    "\n",
    "                img_name =  User_id + \"_\" + str(uuid.uuid4())[:8] + \".jpg\"\n",
    "\n",
    "                try:\n",
    "                    img_url = re.sub(\"\\u200b\",\"\",str(img['src']))\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(img_url,img_name)\n",
    "                        shutil.move(img_name,Save_path)\n",
    "\n",
    "                    except UnicodeEncodeError:\n",
    "                        try:\n",
    "                            if 'map' not in str(img_url):\n",
    "                                driver = webdriver.Chrome(Chrome_path)\n",
    "                                driver.get(url)\n",
    "                                driver.implicitly_wait(3)\n",
    "                                img = driver.find_element_by_tag_name('img')\n",
    "                                src = re.sub(\"\\u200b\",\"\",str(img.get_attribute('src')))\n",
    "                                urllib.request.urlretrieve(src, Save_path)\n",
    "                                shutil.move(img_name,move_folder)\n",
    "                                driver.close()\n",
    "                            else:\n",
    "                                Map_exist = 1\n",
    "                        except:\n",
    "                            pass\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "\n",
    "\n",
    "                    Img_id = \"dbdbdeep\" + '\\\\' + User_id + '\\\\'+ Post_id +'\\\\' + img_name\n",
    "                    save_img_content = Img_id + \"\\t\" + Post_id\n",
    "\n",
    "                    with open(img_csv_name, 'a', encoding='utf-8') as f:\n",
    "                        f.write(save_img_content + \"\\n\")\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # Post_tag, Media_count\n",
    "            driver = webdriver.Chrome(Chrome_path)\n",
    "            driver.get(url)\n",
    "            driver.implicitly_wait(20)\n",
    "\n",
    "            try:\n",
    "                Post_number = Post_Id_Get_1()\n",
    "            except:\n",
    "                try:\n",
    "                    Post_number = Post_Id_Get_2()\n",
    "                except:\n",
    "                    try:\n",
    "                        Post_number = find_post_id()\n",
    "                    except:\n",
    "                        Post_number = 'not_known'\n",
    "\n",
    "            # Comment, Sympath_table\n",
    "            Sympathy_user_id, Comment_user_id , Comment_list, Comment_time = Sympathy_Comment_Id_Get(Post_number)\n",
    "\n",
    "            if Sympathy_user_id != 'hide' or Sympathy_user_id != []:\n",
    "                for Sympath_id in Sympathy_user_id:\n",
    "                    if Sympath_id == 'h':\n",
    "                        break\n",
    "                    with open(Sympathy_csv_name, 'a', encoding='utf-8') as f:\n",
    "                        f.write(Post_id+'\\t'+Sympath_id + \"\\n\")\n",
    "\n",
    "            if Comment_user_id != 'hide' or Comment_user_id != []:\n",
    "                for i in range(0,len(Comment_user_id)):\n",
    "                    with open(Comment_csv_name, 'a', encoding='utf-8') as f:\n",
    "                        f.write(Post_id+'\\t' + Comment_user_id[i] +'\\t'+ Comment_list[i] +'\\t' + Comment_time[i] + \"\\n\") \n",
    "\n",
    "\n",
    "\n",
    "            #extract comment_count\n",
    "            try:\n",
    "                Heart_count, Comment_count = Comment_Sympath_Count()\n",
    "            except:\n",
    "                Heart_count = 'hide'\n",
    "                Comment_count = 'hide'\n",
    "\n",
    "            Media_count = 0\n",
    "            Media_check = driver.find_elements_by_tag_name('iframe')\n",
    "\n",
    "            for Media in Media_check:\n",
    "                if 'Player' in str(Media.get_attribute('src')):\n",
    "                    Media_count += 1\n",
    "            try:\n",
    "                tag_list = re.sub('\\n','',driver.find_element_by_class_name('wrap_tag').text).strip().split('#')[1:]\n",
    "            except:\n",
    "                tag_list = []\n",
    "\n",
    "            for Post_tag in tag_list:\n",
    "                save_tag = Post_id + \"\\t\" + Post_tag\n",
    "                with open(tag_csv_name, 'a', encoding='utf-8') as f:\n",
    "                    f.write(save_tag + \"\\n\")\n",
    "\n",
    "\n",
    "            # make a save list\n",
    "            save_post = \"\\t\".join(list(map(str,[Post_id,User_id,Category,Title,Date,Structure,Structure_tag,Text,Space_text,Count_space_mistake,Map_exist,Media_count,Heart_count,Sticker_count,Comment_count])))\n",
    "\n",
    "            with open(post_csv_name, 'a', encoding='utf-8') as f:\n",
    "                    f.write(save_post + \"\\n\")\n",
    "            driver.close()\n",
    "        except:\n",
    "            print(User_id,'post_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dbdbdeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbdbdeep_user = pd.read_csv('dbdbdeep_drop_user_list.csv',encoding='utf-8',sep='\\t')\n",
    "dbdbdeep_user_id = dbdbdeep_user['User_id']\n",
    "dbdbdeep_user_id = dbdbdeep_user_id.get_values().tolist()\n",
    "dbdbdeep_user_id = dbdbdeep_user_id[1300:1500]\n",
    "\n",
    "move_path = dbdbdeep_folder\n",
    "\n",
    "for User_id in tqdm(dbdbdeep_user_id):\n",
    "    ## 무작위 User_folder 만들기\n",
    "    Category_path_random = dbdbdeep_folder\n",
    "    os.chdir(Category_path_random)\n",
    "\n",
    "    if not os.path.exists(User_id):\n",
    "        os.makedirs(User_id)\n",
    "\n",
    "    os.chdir(Base_path)\n",
    "\n",
    "    before_Title = ''   \n",
    "    for page in range(2,12):\n",
    "        try:\n",
    "            Category = '무작위'\n",
    "            url = \"http://blog.naver.com/PostList.nhn?blogId=\" + User_id + \"&currentPage=\" + str(page)\n",
    "            r = requests.get(url)\n",
    "            bs = BeautifulSoup(re.sub('&nbsp;',' ',r.text).encode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "            Post_id = User_id + '_' + str(page)\n",
    "\n",
    "            #title\n",
    "            Title = bs.find(\"h3\", {\"class\": \"se_textarea\"})\n",
    "            if (Title == None):\n",
    "                Title = bs.find(\"span\", {\"class\": \"pcol1 itemSubjectBoldfont\"})\n",
    "            if (Title != None):\n",
    "                Title = Title.text.strip()\n",
    "            else:\n",
    "                Title = \"TITLE ERROR\"\n",
    "\n",
    "\n",
    "            if before_Title == Title:\n",
    "                break\n",
    "            else:\n",
    "                before_Title = Title \n",
    "\n",
    "\n",
    "            #date\n",
    "            # Append_value\n",
    "            Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2 fil5\"})\n",
    "\n",
    "            if Date == None:\n",
    "                Date = bs.find(\"p\",{\"class\":\"date fil5 pcol2 _postAddDate\"})\n",
    "            if Date == None:\n",
    "                Date = bs.find(\"span\",{\"class\":\"se_publishDate pcol2\"})\n",
    "\n",
    "            Date_text = re.sub(\"\\n\",\"\",Date.text)\n",
    "            Date = re.sub(\"\\t\",\"\",Date_text)\n",
    "\n",
    "            #Tag, Content_structure, Text\n",
    "\n",
    "            # structure\n",
    "            structure = bs.find(\"div\", {\"id\": \"postViewArea\"})\n",
    "            if structure == None:\n",
    "                structure = bs.find(\"div\",{\"class\",\"se_component_wrap sect_dsc __se_component_area\"})\n",
    "            structure_tag = structure.find_all(['p','img'])\n",
    "\n",
    "            # Align\n",
    "            split_structure =  remove_odd(str(structure)).split('>')\n",
    "            center= 0\n",
    "            left = 0\n",
    "            right = 0\n",
    "            justify = 0\n",
    "            for item in split_structure:\n",
    "                if 'align' or 'ALIGN' in str(item):\n",
    "                    if 'center' in str(item):\n",
    "                        center +=1\n",
    "                    if 'left' in str(item):\n",
    "                        left += 1\n",
    "                    if 'right' in str(item):\n",
    "                        right +=1\n",
    "                    if 'justify' in str(item):\n",
    "                        justify +=1\n",
    "            Align = [left, center, right, justify]\n",
    "\n",
    "            # Font Style\n",
    "            fonts = ['나눔고딕','NanumBarungothic','NanumGothic','NanumMyengjo',\n",
    "            '나눔바른고딕','나눔명조','sans-serif','nanumbarungothic','nanumgothic','nanummyeongjo','돋움','돋움체','굴림','굴림체','바탕','바탕체','궁서','Arial','Tahoma','Times New Roman','Verdana','Couier New']\n",
    "\n",
    "            font_list = []\n",
    "            for item in split_structure:\n",
    "                for font in fonts:\n",
    "                    if font in item:\n",
    "                        font_list.append(font)\n",
    "            cnt = Counter(font_list)\n",
    "            basic_font = cnt.most_common(1)\n",
    "            if basic_font == []:\n",
    "                basic_font = 'default'\n",
    "\n",
    "\n",
    "            ## Font_size\n",
    "            font_size_list = []\n",
    "            for item in split_structure:\n",
    "                if 'font' in item:\n",
    "                    p = re.compile('font-size:.*pt;')\n",
    "                    font_size = p.findall(str(item))\n",
    "                    string = \"\".join(font_size)\n",
    "                    size = numeric_value(string)\n",
    "                    if len(size) < 3 and 0 < len(size):\n",
    "                        font_size_list.append(numeric_value(string))\n",
    "            cnt = Counter(font_size_list)\n",
    "            basic_font_size = cnt.most_common(1)\n",
    "            if basic_font_size == []:\n",
    "                basic_font_size = 'default'\n",
    "\n",
    "            # B,strong_tag \n",
    "            b_strong_tag = structure.find_all(['b','strong'])\n",
    "            ## word는 무조건 remove_odd 하기!!!\n",
    "\n",
    "            b_strong_word_list = []\n",
    "            b_strong_word_len = 0\n",
    "\n",
    "            for item in b_strong_tag:\n",
    "                if len(item.text) > 1 and len(item.text) < 22:\n",
    "                    b_strong_word_list.append(remove_odd(item.text))\n",
    "                    b_strong_word_len += len(remove_odd(item.text))\n",
    "            b_tag_len = len(b_strong_word_list)\n",
    "\n",
    "            ## Color_tag\n",
    "            color_tag =  structure.find_all('span')\n",
    "\n",
    "            ## word는 무조건 remove_odd 하기!!!\n",
    "            color_rgb_list = []\n",
    "            color_rgb_word_list = []\n",
    "            color_rgb_word_len = 0\n",
    "            for item in color_tag:\n",
    "                if 'rgb' in str(item):\n",
    "                    if len(item.text)>1 and len(item.text) < 25:\n",
    "                        color_rgb_list.append(find_rgb(str(item)))\n",
    "                        color_rgb_word_list.append(remove_odd(item.text))\n",
    "                        color_rgb_word_len += len(remove_odd(item.text))      \n",
    "            color_tag_len = len(color_rgb_word_list)\n",
    "\n",
    "            save_content_list = [Post_id,Align,basic_font,basic_font_size,b_strong_word_list,b_strong_word_len,b_tag_len,color_rgb_list,color_rgb_word_list,color_rgb_word_len,color_tag_len]\n",
    "            save_content = \"\\t\".join(list(map(str,save_content_list)))\n",
    "\n",
    "            with open(Post_Style_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_content+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "            structure_tag = structure.find_all(['p','img'])\n",
    "            # only tag & texf extract\n",
    "            tag_list = []\n",
    "            structure_list = []\n",
    "            text_list = []\n",
    "\n",
    "            for i in structure_tag:\n",
    "                # p_tag만 불러오기\n",
    "                if \"<p\" in (str(i)):\n",
    "                    tag_list.append('<p>')\n",
    "                    structure_list.append('<p>')\n",
    "                    # img만 있을 때\n",
    "\n",
    "                    if '<img' in str(i):\n",
    "                        for j in i:\n",
    "                            try:\n",
    "                                if len(j.text)>1:\n",
    "                                    tag_list.append('<br>')\n",
    "                                    structure_list.append('<br>')\n",
    "                                    structure_list.append(j.text)\n",
    "                                    text_list.append(j.text)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                    # img가 아닌 경우 span tag가 더 있을 때\n",
    "                    elif '<span' in str(i):\n",
    "                        for j in i:\n",
    "                            if '<br' in str(j):\n",
    "                                structure_list.append(j.text)\n",
    "                                text_list.append(j.text)\n",
    "                                # br_tag가 2개 이상 있을 때\n",
    "\n",
    "                                if len(j.findAll('br'))>2:\n",
    "                                    for _ in range(0,len(j.findAll('br'))):\n",
    "                                        tag_list.append('<br>')\n",
    "                                        structure_list.append('<br>')\n",
    "\n",
    "                                # br_tag가 1개 있을 때\n",
    "                                else:\n",
    "                                    tag_list.append('<br>')\n",
    "                                    structure_list.append('<br>')\n",
    "\n",
    "                            # span은 있지만 br tag가 없을 때       \n",
    "                            else:\n",
    "                                try:\n",
    "                                    structure_list.append(j.text)\n",
    "                                    text_list.append(j.text)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    # 그냥 p_tag만 있을 때 br_tag 추가\n",
    "                    else:\n",
    "                        # 글이 있을 때\n",
    "                        if len(i.text) > 1:\n",
    "                            structure_list.append(i.text)\n",
    "                            text_list.append(i.text)\n",
    "\n",
    "                        # 글 없이 br tag만 있을 때\n",
    "                        else:\n",
    "                            tag_list.append('<br>')\n",
    "                            structure_list.append(i.text)\n",
    "                            structure_list.append('<br>')\n",
    "                            text_list.append(i.text)\n",
    "\n",
    "                    # P_tag 끝맽음      \n",
    "                    tag_list.append('</p>')\n",
    "                    structure_list.append('</p>')\n",
    "\n",
    "                else:\n",
    "                    tag_list.append('<img>')\n",
    "                    structure_list.append('<img>')\n",
    "\n",
    "\n",
    "            structure_list = list(map(remove_odd,structure_list))\n",
    "            text_list = list(map(remove_odd,text_list))\n",
    "            filter_text = list(filter(lambda x: len(x)>1 ,text_list))\n",
    "\n",
    "            Structure = \"|\".join(list(filter(lambda x: len(x)>1 ,structure_list)))\n",
    "            Structure = remove_odd(Structure)\n",
    "\n",
    "            Text = \" \".join(list(filter(lambda x: len(x)>1 ,map(lambda x : x.strip(),text_list))))\n",
    "            Text = remove_odd(Text)\n",
    "\n",
    "\n",
    "            Space_text = \" \".join(Spacing_text(filter_text))\n",
    "            Space_text = remove_odd(Space_text)\n",
    "\n",
    "            Count_space_mistake = len(Space_text)-len(Text)\n",
    "\n",
    "\n",
    "            # only tag\n",
    "            Structure_tag = \"|\".join(tag_list)\n",
    "            Structure_tag = remove_odd(Structure_tag)\n",
    "\n",
    "\n",
    "            # image download    \n",
    "            imgs = structure.find_all('img')\n",
    "\n",
    "            User_path = os.path.join(move_path,User_id)\n",
    "            os.chdir(User_path)\n",
    "\n",
    "            folder_name = Post_id\n",
    "            if not os.path.exists(folder_name):\n",
    "                os.makedirs(folder_name)\n",
    "\n",
    "\n",
    "            Save_path = os.path.join(User_path,Post_id)\n",
    "\n",
    "\n",
    "            os.chdir(Base_path)\n",
    "\n",
    "            Map_exist = 0\n",
    "            Sticker_count = 0\n",
    "\n",
    "\n",
    "            # Sticker_count로 수정\n",
    "            sticker_img = structure.find_all('a')\n",
    "            for i in sticker_img:\n",
    "                if 'sticker' in str(i):\n",
    "                    Sticker_count += 1\n",
    "\n",
    "            # image download    \n",
    "            imgs = structure.find_all('img')\n",
    "\n",
    "            for img in imgs:\n",
    "\n",
    "\n",
    "                img_name =  User_id + \"_\" + str(uuid.uuid4())[:8] + \".jpg\"\n",
    "\n",
    "                try:\n",
    "                    img_url = re.sub(\"\\u200b\",\"\",str(img['src']))\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(img_url,img_name)\n",
    "                        shutil.move(img_name,Save_path)\n",
    "\n",
    "                    except UnicodeEncodeError:\n",
    "                        try:\n",
    "                            if 'map' not in str(img_url):\n",
    "                                driver = webdriver.Chrome(Chrome_path)\n",
    "                                driver.get(url)\n",
    "                                driver.implicitly_wait(3)\n",
    "                                img = driver.find_element_by_tag_name('img')\n",
    "                                src = re.sub(\"\\u200b\",\"\",str(img.get_attribute('src')))\n",
    "                                urllib.request.urlretrieve(src, Save_path)\n",
    "                                shutil.move(img_name,move_folder)\n",
    "                                driver.close()\n",
    "                            else:\n",
    "                                Map_exist = 1\n",
    "                        except:\n",
    "                            pass\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "\n",
    "\n",
    "                    Img_id = \"dbdbdeep\" + '\\\\' + User_id + '\\\\'+ Post_id +'\\\\' + img_name\n",
    "                    save_img_content = Img_id + \"\\t\" + Post_id\n",
    "\n",
    "                    with open(img_csv_name, 'a', encoding='utf-8') as f:\n",
    "                        f.write(save_img_content + \"\\n\")\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # Post_tag, Media_count\n",
    "            driver = webdriver.Chrome(Chrome_path)\n",
    "            driver.get(url)\n",
    "            driver.implicitly_wait(20)\n",
    "\n",
    "            try:\n",
    "                Post_number = Post_Id_Get_1()\n",
    "            except:\n",
    "                try:\n",
    "                    Post_number = Post_Id_Get_2()\n",
    "                except:\n",
    "                    try:\n",
    "                        Post_number = find_post_id()\n",
    "                    except:\n",
    "                        Post_number = 'not_known'\n",
    "\n",
    "            # Comment, Sympath_table\n",
    "            Sympathy_user_id, Comment_user_id , Comment_list, Comment_time = Sympathy_Comment_Id_Get(Post_number)\n",
    "\n",
    "            if Sympathy_user_id != 'hide' or Sympathy_user_id != []:\n",
    "                for Sympath_id in Sympathy_user_id:\n",
    "                    if Sympath_id == 'h':\n",
    "                        break\n",
    "                    with open(Sympathy_csv_name, 'a', encoding='utf-8') as f:\n",
    "                        f.write(Post_id+'\\t'+Sympath_id + \"\\n\")\n",
    "\n",
    "            if Comment_user_id != 'hide' or Comment_user_id != []:\n",
    "                for i in range(0,len(Comment_user_id)):\n",
    "                    with open(Comment_csv_name, 'a', encoding='utf-8') as f:\n",
    "                        f.write(Post_id+'\\t' + Comment_user_id[i] +'\\t'+ Comment_list[i] +'\\t' + Comment_time[i] + \"\\n\") \n",
    "\n",
    "\n",
    "\n",
    "            #extract comment_count\n",
    "            try:\n",
    "                Heart_count, Comment_count = Comment_Sympath_Count()\n",
    "            except:\n",
    "                Heart_count = 'hide'\n",
    "                Comment_count = 'hide'\n",
    "\n",
    "            Media_count = 0\n",
    "            Media_check = driver.find_elements_by_tag_name('iframe')\n",
    "\n",
    "            for Media in Media_check:\n",
    "                if 'Player' in str(Media.get_attribute('src')):\n",
    "                    Media_count += 1\n",
    "            try:\n",
    "                tag_list = re.sub('\\n','',driver.find_element_by_class_name('wrap_tag').text).strip().split('#')[1:]\n",
    "            except:\n",
    "                tag_list = []\n",
    "\n",
    "            for Post_tag in tag_list:\n",
    "                save_tag = Post_id + \"\\t\" + Post_tag\n",
    "                with open(tag_csv_name, 'a', encoding='utf-8') as f:\n",
    "                    f.write(save_tag + \"\\n\")\n",
    "\n",
    "\n",
    "            # make a save list\n",
    "            save_post = \"\\t\".join(list(map(str,[Post_id,User_id,Category,Title,Date,Structure,Structure_tag,Text,Space_text,Count_space_mistake,Map_exist,Media_count,Heart_count,Sticker_count,Comment_count])))\n",
    "\n",
    "            with open(post_csv_name, 'a', encoding='utf-8') as f:\n",
    "                    f.write(save_post + \"\\n\")\n",
    "            driver.close()\n",
    "        except:\n",
    "            print(User_id,'post_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
