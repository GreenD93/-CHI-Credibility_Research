{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import urllib\n",
    "import requests\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pykospacing import spacing\n",
    "import pandas as pd\n",
    "import copy\n",
    "import string, random ## generate random str package\n",
    "from collections import OrderedDict ## repetition removal package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hangul(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글과 띄어쓰기를 제외한 모든 글자\n",
    "    # hangul = re.compile('[^ \\u3131-\\u3163\\uac00-\\ud7a3]+')  # 위와 동일\n",
    "    result = hangul.sub('', text) # 한글과 띄어쓰기를 제외한 모든 부분을 제거\n",
    "    return str(result)\n",
    "\n",
    "def find_categories():\n",
    "    test = driver.find_elements_by_css_selector(\"body > div.lyr_category_lst1 > ul > li:nth-child(1) > ul > li > a\")\n",
    "    Categories = []\n",
    "    for i in test:\n",
    "        Categories.append(i.text.split(\"\\n\")[:2])\n",
    "    Count_Categories = len(Categories)\n",
    "    return Categories, Count_Categories\n",
    "\n",
    "def find_post_id():\n",
    "    post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "    r = re.compile('logNo=.*')\n",
    "    string = r.findall(post.get_attribute('ng-href'))\n",
    "    return re.sub(\"logNo=\",'',\"\".join(string))\n",
    "\n",
    "def random_id():\n",
    "    passkey='' # an empty str key\n",
    "    for x in range(10): # length of the random passkeys\n",
    "\n",
    "        if random.choice([1,2]) == 1:\n",
    "            passkey += passkey.join(random.choice(string.ascii_letters)) # upper & lower cased letter\n",
    "        else:\n",
    "            passkey += passkey.join(random.choice(string.digits)) # numbers\n",
    "    return passkey\n",
    "\n",
    "def Spacing_text(text_list):\n",
    "    spacing_list = []\n",
    "    for i in text_list:\n",
    "        if len(i) < 197:\n",
    "            spacing_list.append(spacing(i))\n",
    "        else:\n",
    "            iteration = int(len(i) / 197)\n",
    "            mod = len(i) % 197\n",
    "            start = 0\n",
    "            end = 197\n",
    "            check = 0\n",
    "            while True:\n",
    "                # 시행횟수 < 몫\n",
    "                if check < iteration:\n",
    "                    spacing_list.append(spacing(i[start:end]))\n",
    "                    start+=197\n",
    "                    end+=197\n",
    "                    check +=1\n",
    "                else:\n",
    "                    # 마지막 횟수 + 나머지 더 slice \n",
    "                    spacing_list.append(spacing(i[iteration*197:(iteration*197)+mod]))\n",
    "                    break\n",
    "    return spacing_list\n",
    "\n",
    "def remove_odd(x):\n",
    "    x = re.sub(\"nbsp\",\" \",x)\n",
    "    x = re.sub(\"\\xa0\",\"\",x)\n",
    "    x = re.sub(\"\\u200b\",\"\",x)\n",
    "    x = re.sub(\"\\n\",\"\",x)\n",
    "    x = re.sub(\"\\t\",\"\",x)\n",
    "    x = re.sub('   ',' ',x)\n",
    "    return x.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category_list = [\"와인·술\",\"육아·결혼\",\"등산·낚시·레저\",\"드라마·방송\",\"교육·학문\",\"건강·의학\",\"차·커피·디저트\",\\\n",
    "\"국내여행\",\"어학·외국어\",\"만화·애니\",\"IT·컴퓨터\",\"자동차\",\"시사·인문·경제\",\"패션·뷰티\",\"공연·전시\",\"스포츠\",\"맛집\",\"사진\",'무작위']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_csv 작성\n",
    "csv_name = 'dbdbdeep_user_table_2.csv'\n",
    "col_name = \"\\t\".join([\"User_id\",\"Blog_name\",\"Blog_nickname\",\"Blog_info_text\",\"Count_neighbors\",\"Count_visitors\",\"Categories\",\"Count_categories\",\"Total_post\",\"Credibility\",\"Source\",\"Blog_mobile_profile_img\",\"Blog_mobile_cover_img\"])\n",
    "\n",
    "if not os.path.exists(csv_name):\n",
    "    with open(csv_name, 'w') as f:\n",
    "        f.write(col_name+'\\n')\n",
    "        \n",
    "# post_csv 작성\n",
    "post_csv_name = 'dbdbdeep_post_table_2.csv'\n",
    "post_col_name = \"\\t\".join([\"Post_id\",\"User_id\",\"Category\",\"Title\",\"Date\",\"Structure\",\"Structure_tag\",\"Text\",\"Space_text\",\"Count_space_mistake\",\"Map_exist\",\"Media_count\",\"Heart_count\",\"Sticker_count\"])\n",
    "if not os.path.exists(post_csv_name):\n",
    "    with open(post_csv_name, 'w') as f:\n",
    "        f.write(post_col_name +'\\n')\n",
    "\n",
    "# img_csv 작성\n",
    "img_csv_name = 'dbdbdeep_img_table_2.csv'\n",
    "img_col_name = \"\\t\".join([\"Img_id\",\"Post_id\"])\n",
    "if not os.path.exists(img_csv_name):\n",
    "    with open(img_csv_name, 'w') as f:\n",
    "        f.write(img_col_name +'\\n')\n",
    "\n",
    "# tag_csv 작성\n",
    "tag_csv_name = 'dbdbdeep_tag_table_2.csv'\n",
    "tag_col_name = \"\\t\".join([\"Post_id\",\"Post_tag\"])\n",
    "if not os.path.exists(tag_csv_name):\n",
    "    with open(tag_csv_name, 'w') as f:\n",
    "        f.write(tag_col_name +'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path 설정해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Category 폴더 만들기\n",
    "\n",
    "Base_path = os.getcwd()\n",
    "Category_path = \"C:\\\\Users\\\\AjouHCI\\\\Desktop\\\\Archive\\\\dbdbdeep\"\n",
    "os.chdir(Category_path)\n",
    "    \n",
    "for directory in Category_list:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "os.chdir(Base_path)\n",
    "\n",
    "# 기본 path설정\n",
    "dbdbdeep_folder = \"C:\\\\Users\\\\AjouHCI\\\\Desktop\\\\Archive\\\\dbdbdeep\\\\\" \n",
    "Base_path = 'C:\\\\workspace\\\\Credibility_Research'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post_count_number 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post_count_number in tqdm(range(0,post_number)):\n",
    "    print(\"post number:\",post_number)\n",
    "\n",
    "# Extract User_id and Post_id\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Web blog 검색\n",
    "    driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "    driver.get(\"https://search.naver.com/search.naver?where=post&sm=tab_jum\")\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    url_list = []\n",
    "\n",
    "    # Category List 나열\n",
    "\n",
    "    for num,category in enumerate(Category_list):\n",
    "        print(num,'\\t',category)\n",
    "\n",
    "    Category = input(\"Category를 입력하세요: \")\n",
    "    check = 1\n",
    "\n",
    "    while check:\n",
    "        if Category not in Category_list:\n",
    "            Category = input(\"Category를 다시 입력하세요: \")\n",
    "        else:\n",
    "            print(\"Category :\",Category)\n",
    "            check = 0\n",
    "\n",
    "    # click blog in current page and save to list\n",
    "\n",
    "    first_page = 1\n",
    "    check = 1\n",
    "    while check:\n",
    "        if first_page == 1:\n",
    "            first_page = 0\n",
    "            urls = driver.find_elements_by_class_name(\"url\")\n",
    "            for num, url in enumerate(urls):\n",
    "                url.click()   \n",
    "                window_before = driver.window_handles[0]\n",
    "                window_after = driver.window_handles[1]\n",
    "                driver.switch_to_window(window_after)\n",
    "                driver.implicitly_wait(10)\n",
    "                url_list.append(driver.current_url)\n",
    "                driver.close()\n",
    "                driver.switch_to_window(window_before)\n",
    "\n",
    "        # next_button click\n",
    "        try:\n",
    "            driver.find_element_by_class_name(\"next\").click()\n",
    "            driver.implicitly_wait(3)\n",
    "            urls = driver.find_elements_by_class_name(\"url\")\n",
    "\n",
    "            for num, url in enumerate(urls):\n",
    "                url.click()\n",
    "                window_before = driver.window_handles[0]\n",
    "                window_after = driver.window_handles[1]\n",
    "                driver.switch_to_window(window_after)\n",
    "                driver.implicitly_wait(10)\n",
    "                url_list.append(driver.current_url)\n",
    "                driver.close()\n",
    "                driver.switch_to_window(window_before)\n",
    "\n",
    "                if len(url_list) != len(set(url_list)):\n",
    "                    url_list = url_list[:-1]\n",
    "                    check = 0\n",
    "                    break\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    print(\"Category: \",Category,\"\\t블로그 개수: \",len(url_list))\n",
    "\n",
    "    # Get user_id and post_id from url\n",
    "\n",
    "    User_id = []\n",
    "    Post_id = []\n",
    "\n",
    "    for url in tqdm(url_list):\n",
    "\n",
    "        if '?' in url: \n",
    "            User_id.append(re.sub(\"https://blog.naver.com/\",\"\",url).split(\"?\")[0])\n",
    "            Post_id.append(\"\".join(re.findall(\"\\d+\",re.sub(\"https://blog.naver.com/\",\"\",url).split(\"?\")[1])))\n",
    "\n",
    "        elif 'blog.me' in url:\n",
    "            url_temp = re.sub(\"https://\",\"\",url).split(\".\")\n",
    "            temp_Post_id = url\n",
    "            User_id.append(url_temp[0])\n",
    "            Post_id.append(re.sub(\"https://blog.naver.com/\",\"\",temp_Post_id).split(\"/\")[-1])\n",
    "\n",
    "        else:\n",
    "            url_temp = re.sub(\"https://blog.naver.com/\",\"\",url).split(\"/\")\n",
    "            User_id.append(url_temp[0])\n",
    "            Post_id.append(url_temp[1])\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    ## Path 설정\n",
    "    move_path =  dbdbdeep_folder + Category\n",
    "\n",
    "## User_Table Crwaling\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # user_id, post_id zip, remove_duplicated\n",
    "\n",
    "    blog_list = list(set((zip(copy.copy(User_id),copy.copy(Post_id)))))\n",
    "\n",
    "    # source credibility check\n",
    "    Credibility = 0\n",
    "    Source = \"dbdbdeep\"\n",
    "\n",
    "    for user_id, post_id in blog_list:\n",
    "\n",
    "        User_id = user_id\n",
    "        Post_id = post_id\n",
    "        Source = Source \n",
    "        Credibility = Credibility\n",
    "        url = \"http://blog.naver.com/PostView.nhn?blogId=\"+User_id+ \"&logNo=\" + Post_id +\"&redirect=Dlog&widgetTypeCall=true\"\n",
    "        mobile_url = \"http://m.blog.naver.com/PostView.nhn?blogId=\"+ User_id\n",
    "\n",
    "        # get mobile_url\n",
    "        driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "        driver.get(mobile_url)\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        # 존재하지 않는 게시물 클릭\n",
    "        driver.find_element_by_class_name(\"btn_area\").click()\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        # Blog_name, Blog_nickname, Blog_mobile_profile_img, Blog_info_text\n",
    "        Blog_name = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > h2 > a > span').text\n",
    "        Blog_nickname =driver.find_element_by_class_name(\"user_name\").text\n",
    "\n",
    "        try:\n",
    "            post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "            Blog_mobile_profile_img_url = post.get_attribute('ng-href')  \n",
    "        except:\n",
    "            post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "            Blog_mobile_profile_img_url = post.get_attribute('href')\n",
    "        try:\n",
    "            Blog_info_text = driver.find_element_by_class_name(\"text\").text\n",
    "\n",
    "        except:\n",
    "            Blog_info_text = \"\"\n",
    "\n",
    "        # Count_neighbors\n",
    "        neighbors_string = re.sub(\",\",\"\",driver.find_element_by_class_name(\"count_buddy\").text)\n",
    "        Count_neighbors = int(re.findall('\\d+', neighbors_string)[0])\n",
    "\n",
    "        # Count_visitors\n",
    "        visitor_stirng = driver.find_elements_by_class_name('count')[0].text\n",
    "        Count_visitors = re.sub(\",\",\"\",visitor_stirng.split(\"전체\")[1]).strip()\n",
    "\n",
    "        # download_img\n",
    "        Mobile_cover_img_url = driver.find_element_by_class_name(\"cover_img\").get_attribute('bg-lazy-img')\n",
    "\n",
    "        # category 버튼 클릭\n",
    "        driver.find_element_by_css_selector(\"#rego_cover > div.cover_cont > div.btn_area > div > div:nth-child(2) > a > span.txt\").click()\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        # Total_Post, Categories, Count_Categories, \n",
    "\n",
    "        Categories, Count_categories =  find_categories()\n",
    "        Total_post = driver.find_element_by_class_name(\"num\").text\n",
    "        driver.close()\n",
    "\n",
    "        os.chdir(move_path)\n",
    "\n",
    "        # make category_folder\n",
    "        folder_name = User_id\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "\n",
    "        Save_path = dbdbdeep_folder + Category + '\\\\' + folder_name\n",
    "        os.chdir(Save_path)\n",
    "        cover_img = \"Cover_\" + folder_name + \".jpg\"\n",
    "        Blog_mobile_profile_img = Category + \"\\\\\" + cover_img\n",
    "\n",
    "        profile_img = \"Profile_\" + folder_name + \".jpg\"\n",
    "        Blog_mobile_cover_img =  Category + \"\\\\\" + profile_img\n",
    "        #download_img \n",
    "        urllib.request.urlretrieve(Mobile_cover_img_url,cover_img)\n",
    "        urllib.request.urlretrieve(Blog_mobile_profile_img_url,profile_img)\n",
    "\n",
    "        os.chdir(Base_path)\n",
    "\n",
    "        save_content_list = [User_id,Blog_name,Blog_nickname,Blog_info_text,Count_neighbors,Count_visitors,Categories,Count_categories,Total_post,Credibility,Source,Blog_mobile_profile_img,Blog_mobile_cover_img]\n",
    "        save_content = \"\\t\".join(list(map(str,save_content_list)))\n",
    "\n",
    "        with open(csv_name, 'a', encoding='utf-8') as f:\n",
    "            f.write(save_content+\"\\n\")\n",
    "\n",
    "# Post & Tag & Img Table_Crwaling        \n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    for user_id, post_id in blog_list:\n",
    "\n",
    "        User_id = user_id\n",
    "        Post_id = post_id\n",
    "        Category = Category\n",
    "\n",
    "        url = \"http://blog.naver.com/PostView.nhn?blogId=\"+User_id+ \"&logNo=\" + Post_id +\"&redirect=Dlog&widgetTypeCall=true\"\n",
    "        r = requests.get(url)\n",
    "        bs = BeautifulSoup(re.sub('&nbsp;',' ',r.text).encode(\"utf-8\"), \"html.parser\")\n",
    "        if 'u_rmc_btn' in bs or  'ytp-button' in bs:\n",
    "            mdeia_exist = 1\n",
    "        else: \n",
    "            mdeia_exist = 0\n",
    "\n",
    "        #title\n",
    "        Title = bs.find(\"h3\", {\"class\": \"se_textarea\"})\n",
    "        if (Title == None):\n",
    "            Title = bs.find(\"span\", {\"class\": \"pcol1 itemSubjectBoldfont\"})\n",
    "        if (Title != None):\n",
    "            Title = Title.text.strip()\n",
    "        else:\n",
    "            Title = \"TITLE ERROR\"\n",
    "\n",
    "        #date\n",
    "        # Append_value\n",
    "        Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2 fil5\"})\n",
    "        if Date == None:\n",
    "            Date = bs.find(\"p\",{\"class\":\"date fil5 pcol2 _postAddDate\"})\n",
    "\n",
    "        Date_text = re.sub(\"\\n\",\"\",Date.text)\n",
    "        Date = re.sub(\"\\t\",\"\",Date_text)\n",
    "\n",
    "        #Teg, Content_structure, Text\n",
    "\n",
    "        # structure\n",
    "        structure = bs.find(\"div\", {\"id\": \"postViewArea\"})\n",
    "        if structure == None:\n",
    "            structure = bs.find(\"div\",{\"class\",\"se_component_wrap sect_dsc __se_component_area\"})\n",
    "        structure_tag = structure.find_all(['p','img'])\n",
    "\n",
    "\n",
    "        # only tag & texf extract\n",
    "        tag_list = []\n",
    "        structure_list = []\n",
    "        text_list = []\n",
    "\n",
    "        for i in structure_tag:\n",
    "            # p_tag만 불러오기\n",
    "            if \"<p\" in (str(i)):\n",
    "                tag_list.append('<p>')\n",
    "                structure_list.append('<p>')\n",
    "                # img만 있을 때\n",
    "\n",
    "                if '<img' in str(i):\n",
    "                    for j in i:\n",
    "                        try:\n",
    "                            if len(j.text)>1:\n",
    "                                tag_list.append('<br>')\n",
    "                                structure_list.append('<br>')\n",
    "                                structure_list.append(j.text)\n",
    "                                text_list.append(j.text)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                # img가 아닌 경우 span tag가 더 있을 때\n",
    "                elif '<span' in str(i):\n",
    "                    for j in i:\n",
    "                        if '<br' in str(j):\n",
    "                            structure_list.append(j.text)\n",
    "                            text_list.append(j.text)\n",
    "                            # br_tag가 2개 이상 있을 때\n",
    "\n",
    "                            if len(j.findAll('br'))>2:\n",
    "                                for _ in range(0,len(j.findAll('br'))):\n",
    "                                    tag_list.append('<br>')\n",
    "                                    structure_list.append('<br>')\n",
    "\n",
    "                            # br_tag가 1개 있을 때\n",
    "                            else:\n",
    "                                tag_list.append('<br>')\n",
    "                                structure_list.append('<br>')\n",
    "\n",
    "                        # span은 있지만 br tag가 없을 때       \n",
    "                        else:\n",
    "                            try:\n",
    "                                structure_list.append(j.text)\n",
    "                                text_list.append(j.text)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                # 그냥 p_tag만 있을 때 br_tag 추가\n",
    "                else:\n",
    "                    # 글이 있을 때\n",
    "                    if len(i.text) > 1:\n",
    "                        structure_list.append(i.text)\n",
    "                        text_list.append(i.text)\n",
    "\n",
    "                    # 글 없이 br tag만 있을 때\n",
    "                    else:\n",
    "                        tag_list.append('<br>')\n",
    "                        structure_list.append(i.text)\n",
    "                        structure_list.append('<br>')\n",
    "                        text_list.append(i.text)\n",
    "\n",
    "                # P_tag 끝맽음      \n",
    "                tag_list.append('</p>')\n",
    "                structure_list.append('</p>')\n",
    "\n",
    "            else:\n",
    "                tag_list.append('<img>')\n",
    "                structure_list.append('<img>')\n",
    "\n",
    "\n",
    "        structure_list = list(map(remove_odd,structure_list))\n",
    "        text_list = list(map(remove_odd,text_list))\n",
    "        filter_text = list(filter(lambda x: len(x)>1 ,text_list))\n",
    "        \n",
    "        Structure = \"|\".join(list(filter(lambda x: len(x)>1 ,structure_list)))        \n",
    "        Text = \" \".join(list(filter(lambda x: len(x)>1 ,map(lambda x : x.strip(),text_list))))\n",
    "        Space_text = \"\".join(Spacing_text(filter_text))\n",
    "        Count_space_mistake = len(Space_text)-len(Text)\n",
    "\n",
    "        # only tag\n",
    "        Structure_tag = \"|\".join(tag_list)\n",
    "\n",
    "        # image download    \n",
    "        imgs = structure.find_all('img')\n",
    "        Save_path = dbdbdeep_folder + Category + '\\\\' + User_id\n",
    "\n",
    "\n",
    "        Map_exist = 0\n",
    "        Sticker_count = 0\n",
    "        for img in imgs:\n",
    "\n",
    "            if \"스티커 이미지\" in str(img):\n",
    "                img_name = \"Sticker_\" + User_id + \"_\" + random_id() + \".jpg\"\n",
    "                Sticker_count += 1\n",
    "            else:\n",
    "                img_name =  User_id + \"_\" + random_id() + \".jpg\"\n",
    "\n",
    "            img_url = re.sub(\"\\u200b\",\"\",str(img['src']))\n",
    "\n",
    "            try:\n",
    "                urllib.request.urlretrieve(img_url,img_name)\n",
    "                shutil.move(img_name,Save_path)\n",
    "\n",
    "            except UnicodeEncodeError:\n",
    "                try:\n",
    "                    if 'map' not in str(img_url):\n",
    "                        driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "                        driver.get(url)\n",
    "                        driver.implicitly_wait(3)\n",
    "                        img = driver.find_element_by_tag_name('img')\n",
    "                        src = re.sub(\"\\u200b\",\"\",str(img.get_attribute('src')))\n",
    "                        urllib.request.urlretrieve(src, Save_path)\n",
    "                        shutil.move(img_name,move_folder)\n",
    "                        driver.close()\n",
    "                    else:\n",
    "                        Map_exist = 1\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            Img_id = \"dbdbdeep\" + '\\\\'+ Category + '\\\\' + User_id + '\\\\'+ img_name\n",
    "            save_img_content = Img_id + \"\\t\" + Post_id\n",
    "\n",
    "            with open(img_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_img_content + \"\\n\")\n",
    "            post_img = Category + \"\\\\\" + User_id+ '\\\\'+ img_name\n",
    "\n",
    "        # Post_tag, Media_count,Heart_count\n",
    "        driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(10)\n",
    "        tags = driver.find_element_by_class_name('post_footer_contents').text.split(\"#\")[1:]\n",
    "        Heart_count = driver.find_element_by_class_name('postre').text\n",
    "        if Heart_count == '' or Heart_count == 'NaN':\n",
    "            for i in range(0,5):\n",
    "                Heart_count = driver.find_element_by_class_name('postre').text\n",
    "                tags = driver.find_element_by_class_name('post_footer_contents').text.split(\"#\")[1:]\n",
    "        Media_count = 0\n",
    "        Media_check = driver.find_elements_by_tag_name('iframe')\n",
    "\n",
    "        for Media in Media_check:\n",
    "            if 'Player' in str(Media.get_attribute('src')):\n",
    "                Media_count += 1\n",
    "\n",
    "        for Post_tag in tags:\n",
    "            save_tag = Post_id + \"\\t\" + Post_tag\n",
    "            with open(tag_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_tag + \"\\n\")\n",
    "\n",
    "        # make a save list\n",
    "        save_post = \"\\t\".join(list(map(str,[Post_id,User_id,Category,Title,Date,Structure,Structure_tag,Text,Space_text,Count_space_mistake,Map_exist,Media_count,Heart_count,Sticker_count])))\n",
    "\n",
    "        with open(post_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_post + \"\\n\")\n",
    "        driver.close()\n",
    "\n",
    "# Page_Post & Tag & Img Table_Crwaling\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    for user_id, _ in blog_list:\n",
    "\n",
    "        User_id = user_id\n",
    "        pages = 11\n",
    "        check_structure = []\n",
    "\n",
    "        ## 무작위 User_folder 만들기\n",
    "        Base_path = os.getcwd()\n",
    "        Category_path_random = Category_path + '\\\\무작위'\n",
    "        os.chdir(Category_path_random)\n",
    "\n",
    "\n",
    "        if not os.path.exists(User_id):\n",
    "            os.makedirs(User_id)\n",
    "\n",
    "            ## user_id 폴더가 이미 만들어져있으면 똑같은 내용 다시 크롤링할 필요 없음\n",
    "\n",
    "            os.chdir(Base_path)\n",
    "\n",
    "\n",
    "            for page in range(1,pages):\n",
    "\n",
    "                Post_id = User_id + \"_\" + str(page)\n",
    "                Category = '무작위'\n",
    "\n",
    "                url = \"http://blog.naver.com/PostView.nhn?blogId=\"+User_id+ \"&logNo=\" + Post_id +\"&redirect=Dlog&widgetTypeCall=true\"\n",
    "                r = requests.get(url)\n",
    "                bs = BeautifulSoup(re.sub('&nbsp;',' ',r.text).encode(\"utf-8\"), \"html.parser\")\n",
    "                if 'u_rmc_btn' in bs or  'ytp-button' in bs:\n",
    "                    mdeia_exist = 1\n",
    "                else: \n",
    "                    mdeia_exist = 0\n",
    "\n",
    "                #title\n",
    "                Title = bs.find(\"h3\", {\"class\": \"se_textarea\"})\n",
    "                if (Title == None):\n",
    "                    Title = bs.find(\"span\", {\"class\": \"pcol1 itemSubjectBoldfont\"})\n",
    "                if (Title != None):\n",
    "                    Title = Title.text.strip()\n",
    "                else:\n",
    "                    Title = \"TITLE ERROR\"\n",
    "\n",
    "                #date\n",
    "                # Append_value\n",
    "                Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2 fil5\"})\n",
    "                if Date == None:\n",
    "                    Date = bs.find(\"p\",{\"class\":\"date fil5 pcol2 _postAddDate\"})\n",
    "\n",
    "                Date_text = re.sub(\"\\n\",\"\",Date.text)\n",
    "                Date = re.sub(\"\\t\",\"\",Date_text)\n",
    "\n",
    "                #Teg, Content_structure, Text\n",
    "\n",
    "                # structure\n",
    "                structure = bs.find(\"div\", {\"id\": \"postViewArea\"})\n",
    "                if structure == None:\n",
    "                    structure = bs.find(\"div\",{\"class\",\"se_component_wrap sect_dsc __se_component_area\"})\n",
    "                structure_tag = structure.find_all(['p','img'])\n",
    "\n",
    "\n",
    "                # only tag & texf extract\n",
    "                tag_list = []\n",
    "                structure_list = []\n",
    "                text_list = []\n",
    "\n",
    "                for i in structure_tag:\n",
    "                    # p_tag만 불러오기\n",
    "                    if \"<p\" in (str(i)):\n",
    "                        tag_list.append('<p>')\n",
    "                        structure_list.append('<p>')\n",
    "                        # img만 있을 때\n",
    "\n",
    "                        if '<img' in str(i):\n",
    "                            for j in i:\n",
    "                                try:\n",
    "                                    if len(j.text)>1:\n",
    "                                        tag_list.append('<br>')\n",
    "                                        structure_list.append('<br>')\n",
    "                                        structure_list.append(j.text)\n",
    "                                        text_list.append(j.text)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                        # img가 아닌 경우 span tag가 더 있을 때\n",
    "                        elif '<span' in str(i):\n",
    "                            for j in i:\n",
    "                                if '<br' in str(j):\n",
    "                                    structure_list.append(j.text)\n",
    "                                    text_list.append(j.text)\n",
    "                                    # br_tag가 2개 이상 있을 때\n",
    "\n",
    "                                    if len(j.findAll('br'))>2:\n",
    "                                        for _ in range(0,len(j.findAll('br'))):\n",
    "                                            tag_list.append('<br>')\n",
    "                                            structure_list.append('<br>')\n",
    "\n",
    "                                    # br_tag가 1개 있을 때\n",
    "                                    else:\n",
    "                                        tag_list.append('<br>')\n",
    "                                        structure_list.append('<br>')\n",
    "\n",
    "                                # span은 있지만 br tag가 없을 때       \n",
    "                                else:\n",
    "                                    try:\n",
    "                                        structure_list.append(j.text)\n",
    "                                        text_list.append(j.text)\n",
    "                                    except:\n",
    "                                        pass\n",
    "\n",
    "                        # 그냥 p_tag만 있을 때 br_tag 추가\n",
    "                        else:\n",
    "                            # 글이 있을 때\n",
    "                            if len(i.text) > 1:\n",
    "                                structure_list.append(i.text)\n",
    "                                text_list.append(i.text)\n",
    "\n",
    "                            # 글 없이 br tag만 있을 때\n",
    "                            else:\n",
    "                                tag_list.append('<br>')\n",
    "                                structure_list.append(i.text)\n",
    "                                structure_list.append('<br>')\n",
    "                                text_list.append(i.text)\n",
    "\n",
    "                        # P_tag 끝맽음      \n",
    "                        tag_list.append('</p>')\n",
    "                        structure_list.append('</p>')\n",
    "\n",
    "                    else:\n",
    "                        tag_list.append('<img>')\n",
    "                        structure_list.append('<img>')\n",
    "\n",
    "\n",
    "                structure_list = list(map(remove_odd,structure_list))\n",
    "                text_list = list(map(remove_odd,text_list))\n",
    "                filter_text = list(filter(lambda x: len(x)>1 ,text_list))\n",
    "\n",
    "                Structure = \"|\".join(list(filter(lambda x: len(x)>1 ,structure_list)))        \n",
    "                Text = \" \".join(list(filter(lambda x: len(x)>1 ,map(lambda x : x.strip(),text_list))))\n",
    "                Space_text = \"\".join(Spacing_text(filter_text))\n",
    "                Count_space_mistake = len(Space_text)-len(Text)\n",
    "\n",
    "                # only tag\n",
    "                Structure_tag = \"|\".join(tag_list)\n",
    "\n",
    "\n",
    "                # image download    \n",
    "                imgs = structure.find_all('img')\n",
    "                Save_path = dbdbdeep_folder + Category + '\\\\' + User_id\n",
    "\n",
    "                Map_exist = 0\n",
    "                Sticker_count = 0\n",
    "\n",
    "                for img in imgs:\n",
    "\n",
    "                    if \"스티커 이미지\" in str(img):\n",
    "                        img_name = \"Sticker_\" + User_id + \"_\" + random_id() + \".jpg\"\n",
    "                        Sticker_count += 1\n",
    "                    else:\n",
    "                        img_name =  User_id + \"_\" + random_id() + \".jpg\"\n",
    "\n",
    "                    img_url = re.sub(\"\\u200b\",\"\",str(img['src']))\n",
    "\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(img_url,img_name)\n",
    "                        shutil.move(img_name,Save_path)\n",
    "                    except UnicodeEncodeError:\n",
    "                        try:\n",
    "                            if 'map' not in str(img_url):\n",
    "                                driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "                                driver.get(url)\n",
    "                                driver.implicitly_wait(3)\n",
    "                                img = driver.find_element_by_tag_name('img')\n",
    "                                src = re.sub(\"\\u200b\",\"\",str(img.get_attribute('src')))\n",
    "                                urllib.request.urlretrieve(src, Save_path)\n",
    "                                shutil.move(img_name,move_folder)\n",
    "                                driver.close()\n",
    "                            else:\n",
    "                                Map_exist = 1\n",
    "                        except:\n",
    "                            pass\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    Img_id = \"dbdbdeep\" + '\\\\'+ Category + '\\\\' + User_id + '\\\\'+ img_name\n",
    "                    save_img_content = Img_id + \"\\t\" + Post_id\n",
    "\n",
    "                    with open(img_csv_name, 'a', encoding='utf-8') as f:\n",
    "                        f.write(save_img_content + \"\\n\")\n",
    "                    post_img = Category + \"\\\\\" + User_id+ '\\\\'+ img_name\n",
    "\n",
    "                # Post_tag, Media_count, Heart_count\n",
    "                driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "                driver.get(url)\n",
    "                driver.implicitly_wait(10)\n",
    "                tags = driver.find_element_by_class_name('post_footer_contents').text.split(\"#\")[1:]\n",
    "\n",
    "                Heart_count = driver.find_element_by_class_name('postre').text\n",
    "                if Heart_count == '' or Heart_count == 'NaN':\n",
    "                    for i in range(0,5):\n",
    "                        Heart_count = driver.find_element_by_class_name('postre').text\n",
    "                        tags = driver.find_element_by_class_name('post_footer_contents').text.split(\"#\")[1:]\n",
    "                Media_count = 0\n",
    "                Media_check = driver.find_elements_by_tag_name('iframe')\n",
    "\n",
    "                for Media in Media_check:\n",
    "                    if 'Player' in str(Media.get_attribute('src')):\n",
    "                        Media_count += 1\n",
    "\n",
    "                for Post_tag in tags:\n",
    "                    save_tag = Post_id + \"\\t\" + Post_tag\n",
    "                    with open(tag_csv_name, 'a', encoding='utf-8') as f:\n",
    "                        f.write(save_tag + \"\\n\")\n",
    "\n",
    "                # make a save list\n",
    "                save_post = \"\\t\".join(list(map(str,[Post_id,User_id,Category,Title,Date,Structure,Structure_tag,Text,Space_text,Count_space_mistake,Map_exist,Media_count,Heart_count,Sticker_count])))\n",
    "\n",
    "                with open(post_csv_name, 'a', encoding='utf-8') as f:\n",
    "                        f.write(save_post + \"\\n\")\n",
    "                driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
