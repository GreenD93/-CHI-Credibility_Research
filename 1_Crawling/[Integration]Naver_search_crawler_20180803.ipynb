{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6dbd4c8062f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import urllib\n",
    "import requests\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pykospacing import spacing\n",
    "import pandas as pd\n",
    "import copy\n",
    "import string, random ## generate random str package\n",
    "from collections import OrderedDict ## repetition removal package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hangul(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글과 띄어쓰기를 제외한 모든 글자\n",
    "    # hangul = re.compile('[^ \\u3131-\\u3163\\uac00-\\ud7a3]+')  # 위와 동일\n",
    "    result = hangul.sub('', text) # 한글과 띄어쓰기를 제외한 모든 부분을 제거\n",
    "    return str(result)\n",
    "\n",
    "def find_categories():\n",
    "    test = driver.find_elements_by_css_selector(\"body > div.lyr_category_lst1 > ul > li:nth-child(1) > ul > li > a\")\n",
    "    Categories = []\n",
    "    for i in test:\n",
    "        Categories.append(i.text.split(\"\\n\")[:2])\n",
    "    Count_Categories = len(Categories)\n",
    "    return Categories, Count_Categories\n",
    "\n",
    "def find_post_id():\n",
    "    post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "    r = re.compile('logNo=.*')\n",
    "    string = r.findall(post.get_attribute('ng-href'))\n",
    "    return re.sub(\"logNo=\",'',\"\".join(string))\n",
    "\n",
    "def random_id():\n",
    "    passkey='' # an empty str key\n",
    "    for x in range(10): # length of the random passkeys\n",
    "\n",
    "        if random.choice([1,2]) == 1:\n",
    "            passkey += passkey.join(random.choice(string.ascii_letters)) # upper & lower cased letter\n",
    "        else:\n",
    "            passkey += passkey.join(random.choice(string.digits)) # numbers\n",
    "    return passkey\n",
    "\n",
    "def Spacing_text(text_list):\n",
    "    spacing_list = []\n",
    "    for i in text_list:\n",
    "        if len(i) < 197:\n",
    "            spacing_list.append(spacing(i))\n",
    "        else:\n",
    "            iteration = int(len(i) / 197)\n",
    "            mod = len(i) % 197\n",
    "            start = 0\n",
    "            end = 197\n",
    "            check = 0\n",
    "            while True:\n",
    "                # 시행횟수 < 몫\n",
    "                if check < iteration:\n",
    "                    spacing_list.append(spacing(i[start:end]))\n",
    "                    start+=197\n",
    "                    end+=197\n",
    "                    check +=1\n",
    "                else:\n",
    "                    # 마지막 횟수 + 나머지 더 slice \n",
    "                    spacing_list.append(spacing(i[iteration*197:(iteration*197)+mod]))\n",
    "                    break\n",
    "    return spacing_list\n",
    "\n",
    "def remove_odd(x):\n",
    "    x = re.sub(\"nbsp\",\" \",x)\n",
    "    x = re.sub(\"\\xa0\",\"\",x)\n",
    "    x = re.sub(\"\\u200b\",\"\",x)\n",
    "    x = re.sub(\"\\n\",\"\",x)\n",
    "    x = re.sub(\"\\t\",\"\",x)\n",
    "    x = re.sub('   ',' ',x)\n",
    "    return x.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Post_Id_Get_1():\n",
    "    foot_info = driver.find_element_by_class_name('wrap_postcomment').get_attribute('innerHTML')\n",
    "    p = re.compile('id=\"area_sympathy.*\" ')\n",
    "    post_id_string = p.findall(foot_info)\n",
    "    if post_id_string == []:\n",
    "        p = re.compile('id=\"Comi.*\" ')\n",
    "        post_id_string = p.findall(foot_info)\n",
    "    remove_quotes = re.sub('\"','',str(post_id_string[0]))\n",
    "    post_no = \"\".join(list(filter(str.isdigit,remove_quotes)))\n",
    "    return post_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Post_Id_Get_2():\n",
    "    #게시글 번호 따오기\n",
    "\n",
    "    foot_info = driver.find_element_by_id('postViewArea').get_attribute('innerHTML')\n",
    "    p = re.compile('postViewArea.*\"')\n",
    "    post_id_string = \"\".join(p.findall(foot_info))\n",
    "\n",
    "    post_id_string = re.sub('postViewArea','',post_id_string)\n",
    "    post_id_string = re.sub('\"','',post_id_string)\n",
    "    return post_id_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comment_Sympath_Count():\n",
    "    p = re.compile('[0-9]')\n",
    "    sympathy_count = ''\n",
    "    comment_count = ''\n",
    "    footer_list = driver.find_elements_by_class_name('wrap_postcomment')[0].text.split('\\n')\n",
    "    for foot in footer_list:\n",
    "        if '공감' in foot:\n",
    "            sympathy_count = \"\".join(p.findall(foot))      \n",
    "        if '댓글' in foot:\n",
    "            comment_count = \"\".join(p.findall(foot))\n",
    "\n",
    "    if sympathy_count == '':\n",
    "        sympathy_count = 0\n",
    "    if comment_count == '':\n",
    "        comment_count = 0\n",
    "    return sympathy_count, comment_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_csv 작성\n",
    "csv_name = 'New_Naver_user_table.csv'\n",
    "col_name = \"\\t\".join([\"User_id\",\"Blog_name\",\"Blog_nickname\",\"Blog_info_text\",\"Count_neighbors\",\"Count_visitors\",\"Categories\",\"Count_categories\",\"Total_post\",\"Credibility\",\"Source\",\"Blog_mobile_profile_img\",\"Blog_mobile_cover_img\"])\n",
    "\n",
    "if not os.path.exists(csv_name):\n",
    "    with open(csv_name, 'w') as f:\n",
    "        f.write(col_name+'\\n')\n",
    "        \n",
    "# post_csv 작성\n",
    "post_csv_name = 'New_Naver_post_table.csv'\n",
    "post_col_name = \"\\t\".join([\"Post_id\",\"User_id\",\"Category\",\"Title\",\"Date\",\"Structure\",\"Structure_tag\",\"Text\",\"Space_text\",\"Count_space_mistake\",\"Map_exist\",\"Media_count\",\"Heart_count\",\"Sticker_count\",\"Comment_count\"])\n",
    "if not os.path.exists(post_csv_name):\n",
    "    with open(post_csv_name, 'w') as f:\n",
    "        f.write(post_col_name +'\\n')\n",
    "\n",
    "# img_csv 작성\n",
    "img_csv_name = 'New_Naver_img_table.csv'\n",
    "img_col_name = \"\\t\".join([\"Img_id\",\"Post_id\"])\n",
    "if not os.path.exists(img_csv_name):\n",
    "    with open(img_csv_name, 'w') as f:\n",
    "        f.write(img_col_name +'\\n')\n",
    "\n",
    "# tag_csv 작성\n",
    "tag_csv_name = 'New_Naver_tag_table.csv'\n",
    "tag_col_name = \"\\t\".join([\"Post_id\",\"Post_tag\"])\n",
    "if not os.path.exists(tag_csv_name):\n",
    "    with open(tag_csv_name, 'w') as f:\n",
    "        f.write(tag_col_name +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"new_missed_Naver_blog.csv\",encoding='utf-8',names=['Year','Parent','Child','ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Category 폴더 만들기\n",
    "Category_list = [\"와인·술\",\"육아·결혼\",\"등산·낚시·레저\",\"드라마·방송\",\"교육·학문\",\"건강·의학\",\"차·커피·디저트\",\\\n",
    "\"국내여행\",\"어학·외국어\",\"만화·애니\",\"IT·컴퓨터\",\"자동차\",\"시사·인문·경제\",\"패션·뷰티\",\"공연·전시\",\"스포츠\",\"맛집\",\"사진\",'무작위']\n",
    "\n",
    "Base_path = os.getcwd()\n",
    "Category_path = \"C:\\\\Users\\\\AjouHCI\\\\Desktop\\\\Archive\\\\New_Naver\"\n",
    "os.chdir(Category_path)\n",
    "    \n",
    "for directory in Category_list:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "os.chdir(Base_path)\n",
    "\n",
    "# 기본 path설정\n",
    "Naver_folder = \"C:\\\\Users\\\\AjouHCI\\\\Desktop\\\\Archive\\\\New_Naver\\\\\" \n",
    "Base_path = 'C:\\\\workspace\\\\Credibility_Research'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post_count_number 입력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_number = 89\n",
    "end_number = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  89\n",
      "User_id:  doublej0128 Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                              | 1/61 [03:39<3:39:32, 219.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  90\n",
      "User_id:  ctofj Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                             | 2/61 [07:18<3:35:41, 219.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  91\n",
      "User_id:  coolps8 Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▉                                                                            | 3/61 [10:48<3:28:48, 216.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  92\n",
      "User_id:  pingu422 Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▏                                                                          | 4/61 [15:24<3:39:30, 231.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  93\n",
      "User_id:  iamchocolat Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▌                                                                         | 5/61 [18:56<3:32:10, 227.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  94\n",
      "User_id:  damsluv Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▊                                                                        | 6/61 [24:18<3:42:48, 243.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  95\n",
      "User_id:  goflvotus Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▏                                                                      | 7/61 [28:43<3:41:36, 246.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  96\n",
      "User_id:  sol_2love Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▍                                                                     | 8/61 [32:05<3:32:39, 240.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  97\n",
      "User_id:  yujingoon Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▊                                                                    | 9/61 [36:18<3:29:44, 242.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  98\n",
      "User_id:  cuckoonest Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                  | 10/61 [39:44<3:22:40, 238.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  99\n",
      "User_id:  25___8 Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▏                                                                | 11/61 [44:35<3:22:41, 243.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  100\n",
      "User_id:  minipin04 Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▏                                                             | 12/61 [1:21:38<5:33:23, 408.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  101\n",
      "User_id:  aura_m Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▍                                                            | 13/61 [1:39:57<6:09:06, 461.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  102\n",
      "User_id:  csjcsj20 Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████▋                                                           | 14/61 [1:45:09<5:53:02, 450.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  103\n",
      "User_id:  istyleamy Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████████████▉                                                          | 15/61 [1:57:22<5:59:55, 469.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  104\n",
      "User_id:  jboy23 Category:  패션·뷰티\n",
      "Category 게시판을 선택해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▏                                                        | 16/61 [2:05:54<5:54:07, 472.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_number:  105\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e73d7edb3678>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnumber\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_number\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"User_number: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mUser_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mCategory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Child'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\study\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\study\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1830\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1832\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\study\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1711\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1713\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1714\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Post_urls_of_user_crawling\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for number in tqdm(range(start_number,end_number)):\n",
    "    print(\"User_number: \",number)\n",
    "    User_id = df['ID'].iloc[number]\n",
    "    Category = df['Child'].iloc[number]\n",
    "\n",
    "    mobile_url = \"http://m.blog.naver.com/PostView.nhn?blogId=\" + User_id\n",
    "    print('User_id: ',User_id,'Category: ',Category)\n",
    "\n",
    "    driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "    driver.get(mobile_url)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    # 존재하지 않는 게시물 클릭 (for pass)\n",
    "    driver.find_element_by_class_name(\"btn_area\").click()\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    # Category\n",
    "    temp_variable = input('Category 게시판을 선택해주세요.')\n",
    "\n",
    "    # Post_id 10개 append\n",
    "    Post_id_list = []\n",
    "    # card_section\n",
    "    for i in driver.find_elements_by_class_name(\"card_section\"):\n",
    "        Post_id_list.append(i.get_attribute('id')[3:])\n",
    "\n",
    "    # list_section\n",
    "    if  Post_id_list == []:\n",
    "        for i in driver.find_elements_by_class_name(\"list\"):\n",
    "            Post_id_list.append(i.get_attribute('id')[3:])\n",
    "\n",
    "    # image_section\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    ## Path 설정\n",
    "    move_path =  Naver_folder + Category\n",
    "\n",
    "# User_table_crawling\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # source credibility check\n",
    "    Post_id = Post_id_list[0]\n",
    "    Source = \"Naver\"\n",
    "    Credibility = 1\n",
    "    mobile_url = \"http://m.blog.naver.com/PostView.nhn?blogId=\"+ User_id\n",
    "\n",
    "    # get mobile_url\n",
    "    driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "    driver.get(mobile_url)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    # 존재하지 않는 게시물 클릭\n",
    "    driver.find_element_by_class_name(\"btn_area\").click()\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    # Blog_name, Blog_nickname, Blog_mobile_profile_img, Blog_info_text\n",
    "    Blog_name = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > h2 > a > span').text\n",
    "    Blog_nickname =driver.find_element_by_class_name(\"user_name\").text\n",
    "\n",
    "    try:\n",
    "        post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "        Blog_mobile_profile_img_url = post.get_attribute('ng-href')  \n",
    "    except:\n",
    "        post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "        Blog_mobile_profile_img_url = post.get_attribute('href')\n",
    "    try:\n",
    "        Blog_info_text = driver.find_element_by_class_name(\"text\").text\n",
    "\n",
    "    except:\n",
    "        Blog_info_text = \"\"\n",
    "\n",
    "    # Count_neighbors\n",
    "    neighbors_string = re.sub(\",\",\"\",driver.find_element_by_class_name(\"count_buddy\").text)\n",
    "    Count_neighbors = int(re.findall('\\d+', neighbors_string)[0])\n",
    "\n",
    "    # Count_visitors\n",
    "    visitor_stirng = driver.find_elements_by_class_name('count')[0].text\n",
    "    Count_visitors = re.sub(\",\",\"\",visitor_stirng.split(\"전체\")[1]).strip()\n",
    "\n",
    "    # download_img\n",
    "    Mobile_cover_img_url = driver.find_element_by_class_name(\"cover_img\").get_attribute('bg-lazy-img')\n",
    "\n",
    "    # category 버튼 클릭\n",
    "    driver.find_element_by_css_selector(\"#rego_cover > div.cover_cont > div.btn_area > div > div:nth-child(2) > a > span.txt\").click()\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    # Total_Post, Categories, Count_Categories, \n",
    "\n",
    "    Categories, Count_categories =  find_categories()\n",
    "    Total_post = driver.find_element_by_class_name(\"num\").text\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    os.chdir(move_path)\n",
    "\n",
    "    # make category_folder\n",
    "    folder_name = User_id\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # download img\n",
    "    Save_path = Naver_folder + Category + '\\\\' + folder_name\n",
    "    os.chdir(Save_path)\n",
    "    cover_img = \"Cover_\" + folder_name + \".jpg\"\n",
    "    Blog_mobile_profile_img = Category + \"\\\\\" + cover_img\n",
    "\n",
    "    profile_img = \"Profile_\" + folder_name + \".jpg\"\n",
    "    Blog_mobile_cover_img =  Category + \"\\\\\" + profile_img\n",
    "\n",
    "    urllib.request.urlretrieve(Mobile_cover_img_url,cover_img)\n",
    "    urllib.request.urlretrieve(Blog_mobile_profile_img_url,profile_img)\n",
    "    os.chdir(Base_path)\n",
    "\n",
    "    save_content_list = [User_id,Blog_name,Blog_nickname,Blog_info_text,Count_neighbors,Count_visitors,Categories,Count_categories,Total_post,Credibility,Source,Blog_mobile_profile_img,Blog_mobile_cover_img]\n",
    "    save_content = \"\\t\".join(list(map(str,save_content_list)))\n",
    "\n",
    "    with open(csv_name, 'a', encoding='utf-8') as f:\n",
    "        f.write(save_content+\"\\n\")\n",
    "        \n",
    "# Post & Tag & Img Table_Crwaling\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    User_id_list = [User_id] * 10\n",
    "    blog_list = list(zip(copy.copy(User_id_list),copy.copy(Post_id_list)))\n",
    "\n",
    "    for user_id, post_id in blog_list:\n",
    "        User_id = user_id\n",
    "        Post_id = post_id\n",
    "        Category = Category\n",
    "\n",
    "        url = \"http://blog.naver.com/PostView.nhn?blogId=\"+User_id+ \"&logNo=\" + Post_id +\"&redirect=Dlog&widgetTypeCall=true\"\n",
    "        r = requests.get(url)\n",
    "        bs = BeautifulSoup(re.sub('&nbsp;',' ',r.text).encode(\"utf-8\"), \"html.parser\")\n",
    "        if 'u_rmc_btn' in bs or  'ytp-button' in bs:\n",
    "            mdeia_exist = 1\n",
    "        else: \n",
    "            mdeia_exist = 0\n",
    "\n",
    "        #title\n",
    "        Title = bs.find(\"h3\", {\"class\": \"se_textarea\"})\n",
    "        if (Title == None):\n",
    "            Title = bs.find(\"span\", {\"class\": \"pcol1 itemSubjectBoldfont\"})\n",
    "        if (Title != None):\n",
    "            Title = Title.text.strip()\n",
    "        else:\n",
    "            Title = \"TITLE ERROR\"\n",
    "\n",
    "        #date\n",
    "        # Append_value\n",
    "        Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2 fil5\"})\n",
    "\n",
    "        if Date == None:\n",
    "            Date = bs.find(\"p\",{\"class\":\"date fil5 pcol2 _postAddDate\"})\n",
    "        if Date == None:\n",
    "            Date = bs.find(\"span\",{\"class\":\"se_publishDate pcol2\"})\n",
    "\n",
    "        Date_text = re.sub(\"\\n\",\"\",Date.text)\n",
    "        Date = re.sub(\"\\t\",\"\",Date_text)\n",
    "\n",
    "        #Tag, Content_structure, Text\n",
    "\n",
    "        # structure\n",
    "        structure = bs.find(\"div\", {\"id\": \"postViewArea\"})\n",
    "        if structure == None:\n",
    "            structure = bs.find(\"div\",{\"class\",\"se_component_wrap sect_dsc __se_component_area\"})\n",
    "        structure_tag = structure.find_all(['p','img'])\n",
    "\n",
    "\n",
    "        # only tag & texf extract\n",
    "        tag_list = []\n",
    "        structure_list = []\n",
    "        text_list = []\n",
    "\n",
    "        for i in structure_tag:\n",
    "            # p_tag만 불러오기\n",
    "            if \"<p\" in (str(i)):\n",
    "                tag_list.append('<p>')\n",
    "                structure_list.append('<p>')\n",
    "                # img만 있을 때\n",
    "\n",
    "                if '<img' in str(i):\n",
    "                    for j in i:\n",
    "                        try:\n",
    "                            if len(j.text)>1:\n",
    "                                tag_list.append('<br>')\n",
    "                                structure_list.append('<br>')\n",
    "                                structure_list.append(j.text)\n",
    "                                text_list.append(j.text)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                # img가 아닌 경우 span tag가 더 있을 때\n",
    "                elif '<span' in str(i):\n",
    "                    for j in i:\n",
    "                        if '<br' in str(j):\n",
    "                            structure_list.append(j.text)\n",
    "                            text_list.append(j.text)\n",
    "                            # br_tag가 2개 이상 있을 때\n",
    "\n",
    "                            if len(j.findAll('br'))>2:\n",
    "                                for _ in range(0,len(j.findAll('br'))):\n",
    "                                    tag_list.append('<br>')\n",
    "                                    structure_list.append('<br>')\n",
    "\n",
    "                            # br_tag가 1개 있을 때\n",
    "                            else:\n",
    "                                tag_list.append('<br>')\n",
    "                                structure_list.append('<br>')\n",
    "\n",
    "                        # span은 있지만 br tag가 없을 때       \n",
    "                        else:\n",
    "                            try:\n",
    "                                structure_list.append(j.text)\n",
    "                                text_list.append(j.text)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                # 그냥 p_tag만 있을 때 br_tag 추가\n",
    "                else:\n",
    "                    # 글이 있을 때\n",
    "                    if len(i.text) > 1:\n",
    "                        structure_list.append(i.text)\n",
    "                        text_list.append(i.text)\n",
    "\n",
    "                    # 글 없이 br tag만 있을 때\n",
    "                    else:\n",
    "                        tag_list.append('<br>')\n",
    "                        structure_list.append(i.text)\n",
    "                        structure_list.append('<br>')\n",
    "                        text_list.append(i.text)\n",
    "\n",
    "                # P_tag 끝맽음      \n",
    "                tag_list.append('</p>')\n",
    "                structure_list.append('</p>')\n",
    "\n",
    "            else:\n",
    "                tag_list.append('<img>')\n",
    "                structure_list.append('<img>')\n",
    "\n",
    "\n",
    "        structure_list = list(map(remove_odd,structure_list))\n",
    "        text_list = list(map(remove_odd,text_list))\n",
    "        filter_text = list(filter(lambda x: len(x)>1 ,text_list))\n",
    "\n",
    "        Structure = \"|\".join(list(filter(lambda x: len(x)>1 ,structure_list)))        \n",
    "        Text = \" \".join(list(filter(lambda x: len(x)>1 ,map(lambda x : x.strip(),text_list))))\n",
    "        Text = re.sub('\\n','',Text)\n",
    "        Text = re.sub('\\t','',Text)\n",
    "        Space_text = \" \".join(Spacing_text(filter_text))\n",
    "        Count_space_mistake = len(Space_text)-len(Text)\n",
    "\n",
    "        # only tag\n",
    "        Structure_tag = \"|\".join(tag_list)\n",
    "\n",
    "        # image download    \n",
    "        imgs = structure.find_all('img')\n",
    "        Save_path = Naver_folder + Category + '\\\\' + User_id\n",
    "\n",
    "        Map_exist = 0\n",
    "        Sticker_count = 0\n",
    "        # Sticker_count로 수정\n",
    "        sticker_img = structure.find_all('a')\n",
    "        for i in sticker_img:\n",
    "            if 'sticker' in str(i):\n",
    "                Sticker_count += 1\n",
    "        \n",
    "        # image download    \n",
    "        imgs = structure.find_all('img')\n",
    "        \n",
    "        for img in imgs:\n",
    "\n",
    "            if \"스티커 이미지\" in str(img):\n",
    "                img_name = \"Sticker_\" + User_id + \"_\" + random_id() + \".jpg\"\n",
    "            else:\n",
    "                img_name =  User_id + \"_\" + random_id() + \".jpg\"\n",
    "\n",
    "            img_url = re.sub(\"\\u200b\",\"\",str(img['src']))\n",
    "\n",
    "            try:\n",
    "                urllib.request.urlretrieve(img_url,img_name)\n",
    "                shutil.move(img_name,Save_path)\n",
    "\n",
    "            except UnicodeEncodeError:\n",
    "                try:\n",
    "                    if 'map' not in str(img_url):\n",
    "                        driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "                        driver.get(url)\n",
    "                        driver.implicitly_wait(3)\n",
    "                        img = driver.find_element_by_tag_name('img')\n",
    "                        src = re.sub(\"\\u200b\",\"\",str(img.get_attribute('src')))\n",
    "                        urllib.request.urlretrieve(src, Save_path)\n",
    "                        shutil.move(img_name,move_folder)\n",
    "                        driver.close()\n",
    "                    else:\n",
    "                        Map_exist = 1\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "            Img_id = \"Naver\" + '\\\\'+ Category + '\\\\' + User_id + '\\\\'+ img_name\n",
    "            save_img_content = Img_id + \"\\t\" + Post_id\n",
    "\n",
    "            with open(img_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_img_content + \"\\n\")\n",
    "            post_img = Category + \"\\\\\" + User_id+ '\\\\'+ img_name\n",
    "\n",
    "        # Post_tag, Media_count\n",
    "        driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(10)\n",
    "        \n",
    "        #extract comment_count\n",
    "        Heart_count, Comment_count = Comment_Sympath_Count()\n",
    "        Media_count = 0\n",
    "        Media_check = driver.find_elements_by_tag_name('iframe')\n",
    "\n",
    "        for Media in Media_check:\n",
    "            if 'Player' in str(Media.get_attribute('src')):\n",
    "                Media_count += 1\n",
    "        \n",
    "        tag_list = re.sub('\\n','',driver.find_element_by_class_name('wrap_tag').text).strip().split('#')[1:]\n",
    "        \n",
    "        for Post_tag in tag_list:\n",
    "            save_tag = Post_id + \"\\t\" + Post_tag\n",
    "            with open(tag_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_tag + \"\\n\")\n",
    "\n",
    "        # make a save list\n",
    "        save_post = \"\\t\".join(list(map(str,[Post_id,User_id,Category,Title,Date,Structure,Structure_tag,Text,Space_text,Count_space_mistake,Map_exist,Media_count,Heart_count,Sticker_count,Comment_count])))\n",
    "        with open(post_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_post + \"\\n\")\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "# Page_Post & Tag & Img Table_Crwaling        \n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "#     pages = 11\n",
    "#     check_structure = []\n",
    "\n",
    "#     ## 무작위 User_folder 만들기\n",
    "#     Base_path = os.getcwd()\n",
    "#     Category_path_random = Category_path + \"\\\\무작위\"\n",
    "#     os.chdir(Category_path_random)\n",
    "\n",
    "#     if not os.path.exists(User_id):\n",
    "#         os.makedirs(User_id)\n",
    "\n",
    "#     os.chdir(Base_path)\n",
    "\n",
    "#     for page in range(1, pages):\n",
    "\n",
    "#         Category = '무작위'\n",
    "\n",
    "#         url = \"http://blog.naver.com/PostList.nhn?blogId=\" + User_id + \"&currentPage=\" + str(page)\n",
    "#         r = requests.get(url)\n",
    "#         bs = BeautifulSoup(re.sub('&nbsp;', ' ', r.text).encode(\"utf-8\"), \"html.parser\")\n",
    "#         try:\n",
    "#             if '아직 작성된 글이 없습니다.' in bs.find('div', {'class': \"new_blog_inner2\"}).text:\n",
    "#                 break\n",
    "#         except:\n",
    "#             pass\n",
    "#         # title\n",
    "#         Title = bs.find(\"h3\", {\"class\": \"se_textarea\"})\n",
    "#         if (Title == None):\n",
    "#             Title = bs.find(\"span\", {\"class\": \"pcol1 itemSubjectBoldfont\"})\n",
    "#         if (Title != None):\n",
    "#             Title = Title.text.strip()\n",
    "#         else:\n",
    "#             Title = \"TITLE ERROR\"\n",
    "\n",
    "#         # date\n",
    "\n",
    "#         # date\n",
    "#         # Append_value\n",
    "#         Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2 fil5\"})\n",
    "\n",
    "#         if Date == None:\n",
    "#             Date = bs.find(\"p\", {\"class\": \"date fil5 pcol2 _postAddDate\"})\n",
    "#         if Date == None:\n",
    "#             Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2\"})\n",
    "\n",
    "#         Date_text = re.sub(\"\\n\", \"\", Date.text)\n",
    "#         Date = re.sub(\"\\t\", \"\", Date_text)\n",
    "\n",
    "#         # Teg, Content_structure, Text\n",
    "\n",
    "#         # structure\n",
    "#         structure = bs.find(\"div\", {\"id\": \"postViewArea\"})\n",
    "#         if structure == None:\n",
    "#             structure = bs.find(\"div\", {\"class\", \"se_component_wrap sect_dsc __se_component_area\"})\n",
    "#         structure_tag = structure.find_all(['p', 'img'])\n",
    "\n",
    "#         if structure in check_structure:\n",
    "#             break\n",
    "#         else:\n",
    "#             check_structure.append(structure)\n",
    "\n",
    "#         # only tag & texf extract\n",
    "#         tag_list = []\n",
    "#         structure_list = []\n",
    "#         text_list = []\n",
    "\n",
    "#         for i in structure_tag:\n",
    "#             # p_tag만 불러오기\n",
    "#             if \"<p\" in (str(i)):\n",
    "#                 tag_list.append('<p>')\n",
    "#                 structure_list.append('<p>')\n",
    "#                 # img만 있을 때\n",
    "\n",
    "#                 if '<img' in str(i):\n",
    "#                     for j in i:\n",
    "#                         try:\n",
    "#                             if len(j.text) > 1:\n",
    "#                                 tag_list.append('<br>')\n",
    "#                                 structure_list.append('<br>')\n",
    "#                                 structure_list.append(j.text)\n",
    "#                                 text_list.append(j.text)\n",
    "#                         except:\n",
    "#                             pass\n",
    "\n",
    "#                 # img가 아닌 경우 span tag가 더 있을 때\n",
    "#                 elif '<span' in str(i):\n",
    "#                     for j in i:\n",
    "#                         if '<br' in str(j):\n",
    "#                             structure_list.append(j.text)\n",
    "#                             text_list.append(j.text)\n",
    "#                             # br_tag가 2개 이상 있을 때\n",
    "\n",
    "#                             if len(j.findAll('br')) > 2:\n",
    "#                                 for _ in range(0, len(j.findAll('br'))):\n",
    "#                                     tag_list.append('<br>')\n",
    "#                                     structure_list.append('<br>')\n",
    "\n",
    "#                             # br_tag가 1개 있을 때\n",
    "#                             else:\n",
    "#                                 tag_list.append('<br>')\n",
    "#                                 structure_list.append('<br>')\n",
    "\n",
    "#                         # span은 있지만 br tag가 없을 때\n",
    "#                         else:\n",
    "#                             try:\n",
    "#                                 structure_list.append(j.text)\n",
    "#                                 text_list.append(j.text)\n",
    "#                             except:\n",
    "#                                 pass\n",
    "\n",
    "#                 # 그냥 p_tag만 있을 때 br_tag 추가\n",
    "#                 else:\n",
    "#                     # 글이 있을 때\n",
    "#                     if len(i.text) > 1:\n",
    "#                         structure_list.append(i.text)\n",
    "#                         text_list.append(i.text)\n",
    "\n",
    "#                     # 글 없이 br tag만 있을 때\n",
    "#                     else:\n",
    "#                         tag_list.append('<br>')\n",
    "#                         structure_list.append(i.text)\n",
    "#                         structure_list.append('<br>')\n",
    "#                         text_list.append(i.text)\n",
    "\n",
    "#                 # P_tag 끝맽음\n",
    "#                 tag_list.append('</p>')\n",
    "#                 structure_list.append('</p>')\n",
    "\n",
    "#             else:\n",
    "#                 tag_list.append('<img>')\n",
    "#                 structure_list.append('<img>')\n",
    "\n",
    "#         structure_list = list(map(remove_odd, structure_list))\n",
    "#         text_list = list(map(remove_odd, text_list))\n",
    "#         filter_text = list(filter(lambda x: len(x) > 1, text_list))\n",
    "\n",
    "#         Structure = \"|\".join(list(filter(lambda x: len(x) > 1, structure_list)))\n",
    "#         Text = re.sub('\\n', '', Text)\n",
    "#         Text = re.sub('\\t', '', Text)\n",
    "#         Text = \" \".join(list(filter(lambda x: len(x) > 1, map(lambda x: x.strip(), text_list))))\n",
    "#         Space_text = \" \".join(Spacing_text(filter_text))\n",
    "#         Count_space_mistake = len(Space_text) - len(Text)\n",
    "\n",
    "#         # only tag\n",
    "#         Structure_tag = \"|\".join(tag_list)\n",
    "\n",
    "#         # image download\n",
    "#         imgs = structure.find_all('img')\n",
    "#         Save_path = Naver_folder + Category + '\\\\' + User_id\n",
    "\n",
    "#         Map_exist = 0\n",
    "#         Sticker_count = 0\n",
    "#         # Sticker_count로 수정\n",
    "#         sticker_img = structure.find_all('a')\n",
    "#         for i in sticker_img:\n",
    "#             if 'sticker' in str(i):\n",
    "#                 Sticker_count += 1\n",
    "\n",
    "#         for img in imgs:\n",
    "\n",
    "#             if \"스티커 이미지\" in str(img):\n",
    "#                 img_name = \"Sticker_\" + User_id + \"_\" + random_id() + \".jpg\"\n",
    "#             else:\n",
    "#                 img_name = User_id + \"_\" + random_id() + \".jpg\"\n",
    "\n",
    "#             img_url = re.sub(\"\\u200b\", \"\", str(img['src']))\n",
    "\n",
    "#             try:\n",
    "#                 urllib.request.urlretrieve(img_url, img_name)\n",
    "#                 shutil.move(img_name, Save_path)\n",
    "\n",
    "#             except UnicodeEncodeError:\n",
    "#                 try:\n",
    "#                     if 'map' not in str(img_url):\n",
    "#                         driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "#                         driver.get(url)\n",
    "#                         driver.implicitly_wait(3)\n",
    "#                         img = driver.find_element_by_tag_name('img')\n",
    "#                         src = re.sub(\"\\u200b\", \"\", str(img.get_attribute('src')))\n",
    "#                         urllib.request.urlretrieve(src, Save_path)\n",
    "#                         shutil.move(img_name, move_folder)\n",
    "#                         driver.close()\n",
    "#                     else:\n",
    "#                         Map_exist = 1\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#             Img_id = \"Naver\" + '\\\\' + Category + '\\\\' + User_id + '\\\\' + img_name\n",
    "#             save_img_content = Img_id + \"\\t\" + Post_id\n",
    "\n",
    "#             with open(img_csv_name, 'a', encoding='utf-8') as f:\n",
    "#                 f.write(save_img_content + \"\\n\")\n",
    "#             post_img = Category + \"\\\\\" + User_id + '\\\\' + img_name\n",
    "\n",
    "#         # Post_tag, Media_count\n",
    "#         driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "#         driver.get(url)\n",
    "#         driver.implicitly_wait(10)\n",
    "#         try:\n",
    "#             Post_id = Post_Id_Get_1()\n",
    "#         except:\n",
    "#             Post_id = Post_Id_Get_2()\n",
    "#         # extract comment_count\n",
    "#         Heart_count, Comment_count = Comment_Sympath_Count()\n",
    "#         Media_count = 0\n",
    "#         Media_check = driver.find_elements_by_tag_name('iframe')\n",
    "\n",
    "#         for Media in Media_check:\n",
    "#             if 'Player' in str(Media.get_attribute('src')):\n",
    "#                 Media_count += 1\n",
    "#         tag_list = re.sub('\\n', '', driver.find_element_by_class_name('wrap_tag').text).strip().split('#')[1:]\n",
    "\n",
    "#         for Post_tag in tag_list:\n",
    "#             save_tag = Post_id + \"\\t\" + Post_tag\n",
    "#             with open(tag_csv_name, 'a', encoding='utf-8') as f:\n",
    "#                 f.write(save_tag + \"\\n\")\n",
    "\n",
    "#         # make a save list\n",
    "#         save_post = \"\\t\".join(list(map(str, [Post_id, User_id, Category, Title, Date, Structure, Structure_tag, Text,\n",
    "#                                              Space_text, Count_space_mistake, Map_exist, Media_count, Heart_count,\n",
    "#                                              Sticker_count, Comment_count])))\n",
    "#         with open(post_csv_name, 'a', encoding='utf-8') as f:\n",
    "#             f.write(save_post + \"\\n\")\n",
    "\n",
    "#         driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page_Post & Tag & Img Table_Crwaling        \n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "#     pages = 11\n",
    "#     check_structure = []\n",
    "\n",
    "#     ## 무작위 User_folder 만들기\n",
    "#     Base_path = os.getcwd()\n",
    "#     Category_path_random = Category_path + \"\\\\무작위\"\n",
    "#     os.chdir(Category_path_random)\n",
    "\n",
    "#     if not os.path.exists(User_id):\n",
    "#         os.makedirs(User_id)\n",
    "\n",
    "#     os.chdir(Base_path)\n",
    "\n",
    "#     for page in range(1, pages):\n",
    "\n",
    "#         Category = '무작위'\n",
    "\n",
    "#         url = \"http://blog.naver.com/PostList.nhn?blogId=\" + User_id + \"&currentPage=\" + str(page)\n",
    "#         r = requests.get(url)\n",
    "#         bs = BeautifulSoup(re.sub('&nbsp;', ' ', r.text).encode(\"utf-8\"), \"html.parser\")\n",
    "#         try:\n",
    "#             if '아직 작성된 글이 없습니다.' in bs.find('div', {'class': \"new_blog_inner2\"}).text:\n",
    "#                 break\n",
    "#         except:\n",
    "#             pass\n",
    "#         # title\n",
    "#         Title = bs.find(\"h3\", {\"class\": \"se_textarea\"})\n",
    "#         if (Title == None):\n",
    "#             Title = bs.find(\"span\", {\"class\": \"pcol1 itemSubjectBoldfont\"})\n",
    "#         if (Title != None):\n",
    "#             Title = Title.text.strip()\n",
    "#         else:\n",
    "#             Title = \"TITLE ERROR\"\n",
    "\n",
    "#         # date\n",
    "\n",
    "#         # date\n",
    "#         # Append_value\n",
    "#         Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2 fil5\"})\n",
    "\n",
    "#         if Date == None:\n",
    "#             Date = bs.find(\"p\", {\"class\": \"date fil5 pcol2 _postAddDate\"})\n",
    "#         if Date == None:\n",
    "#             Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2\"})\n",
    "\n",
    "#         Date_text = re.sub(\"\\n\", \"\", Date.text)\n",
    "#         Date = re.sub(\"\\t\", \"\", Date_text)\n",
    "\n",
    "#         # Teg, Content_structure, Text\n",
    "\n",
    "#         # structure\n",
    "#         structure = bs.find(\"div\", {\"id\": \"postViewArea\"})\n",
    "#         if structure == None:\n",
    "#             structure = bs.find(\"div\", {\"class\", \"se_component_wrap sect_dsc __se_component_area\"})\n",
    "#         structure_tag = structure.find_all(['p', 'img'])\n",
    "\n",
    "#         if structure in check_structure:\n",
    "#             break\n",
    "#         else:\n",
    "#             check_structure.append(structure)\n",
    "\n",
    "#         # only tag & texf extract\n",
    "#         tag_list = []\n",
    "#         structure_list = []\n",
    "#         text_list = []\n",
    "\n",
    "#         for i in structure_tag:\n",
    "#             # p_tag만 불러오기\n",
    "#             if \"<p\" in (str(i)):\n",
    "#                 tag_list.append('<p>')\n",
    "#                 structure_list.append('<p>')\n",
    "#                 # img만 있을 때\n",
    "\n",
    "#                 if '<img' in str(i):\n",
    "#                     for j in i:\n",
    "#                         try:\n",
    "#                             if len(j.text) > 1:\n",
    "#                                 tag_list.append('<br>')\n",
    "#                                 structure_list.append('<br>')\n",
    "#                                 structure_list.append(j.text)\n",
    "#                                 text_list.append(j.text)\n",
    "#                         except:\n",
    "#                             pass\n",
    "\n",
    "#                 # img가 아닌 경우 span tag가 더 있을 때\n",
    "#                 elif '<span' in str(i):\n",
    "#                     for j in i:\n",
    "#                         if '<br' in str(j):\n",
    "#                             structure_list.append(j.text)\n",
    "#                             text_list.append(j.text)\n",
    "#                             # br_tag가 2개 이상 있을 때\n",
    "\n",
    "#                             if len(j.findAll('br')) > 2:\n",
    "#                                 for _ in range(0, len(j.findAll('br'))):\n",
    "#                                     tag_list.append('<br>')\n",
    "#                                     structure_list.append('<br>')\n",
    "\n",
    "#                             # br_tag가 1개 있을 때\n",
    "#                             else:\n",
    "#                                 tag_list.append('<br>')\n",
    "#                                 structure_list.append('<br>')\n",
    "\n",
    "#                         # span은 있지만 br tag가 없을 때\n",
    "#                         else:\n",
    "#                             try:\n",
    "#                                 structure_list.append(j.text)\n",
    "#                                 text_list.append(j.text)\n",
    "#                             except:\n",
    "#                                 pass\n",
    "\n",
    "#                 # 그냥 p_tag만 있을 때 br_tag 추가\n",
    "#                 else:\n",
    "#                     # 글이 있을 때\n",
    "#                     if len(i.text) > 1:\n",
    "#                         structure_list.append(i.text)\n",
    "#                         text_list.append(i.text)\n",
    "\n",
    "#                     # 글 없이 br tag만 있을 때\n",
    "#                     else:\n",
    "#                         tag_list.append('<br>')\n",
    "#                         structure_list.append(i.text)\n",
    "#                         structure_list.append('<br>')\n",
    "#                         text_list.append(i.text)\n",
    "\n",
    "#                 # P_tag 끝맽음\n",
    "#                 tag_list.append('</p>')\n",
    "#                 structure_list.append('</p>')\n",
    "\n",
    "#             else:\n",
    "#                 tag_list.append('<img>')\n",
    "#                 structure_list.append('<img>')\n",
    "\n",
    "#         structure_list = list(map(remove_odd, structure_list))\n",
    "#         text_list = list(map(remove_odd, text_list))\n",
    "#         filter_text = list(filter(lambda x: len(x) > 1, text_list))\n",
    "\n",
    "#         Structure = \"|\".join(list(filter(lambda x: len(x) > 1, structure_list)))\n",
    "#         Text = re.sub('\\n', '', Text)\n",
    "#         Text = re.sub('\\t', '', Text)\n",
    "#         Text = \" \".join(list(filter(lambda x: len(x) > 1, map(lambda x: x.strip(), text_list))))\n",
    "#         Space_text = \" \".join(Spacing_text(filter_text))\n",
    "#         Count_space_mistake = len(Space_text) - len(Text)\n",
    "\n",
    "#         # only tag\n",
    "#         Structure_tag = \"|\".join(tag_list)\n",
    "\n",
    "#         # image download\n",
    "#         imgs = structure.find_all('img')\n",
    "#         Save_path = Naver_folder + Category + '\\\\' + User_id\n",
    "\n",
    "#         Map_exist = 0\n",
    "#         Sticker_count = 0\n",
    "#         # Sticker_count로 수정\n",
    "#         sticker_img = structure.find_all('a')\n",
    "#         for i in sticker_img:\n",
    "#             if 'sticker' in str(i):\n",
    "#                 Sticker_count += 1\n",
    "\n",
    "#         for img in imgs:\n",
    "\n",
    "#             if \"스티커 이미지\" in str(img):\n",
    "#                 img_name = \"Sticker_\" + User_id + \"_\" + random_id() + \".jpg\"\n",
    "#             else:\n",
    "#                 img_name = User_id + \"_\" + random_id() + \".jpg\"\n",
    "\n",
    "#             img_url = re.sub(\"\\u200b\", \"\", str(img['src']))\n",
    "\n",
    "#             try:\n",
    "#                 urllib.request.urlretrieve(img_url, img_name)\n",
    "#                 shutil.move(img_name, Save_path)\n",
    "\n",
    "#             except UnicodeEncodeError:\n",
    "#                 try:\n",
    "#                     if 'map' not in str(img_url):\n",
    "#                         driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "#                         driver.get(url)\n",
    "#                         driver.implicitly_wait(3)\n",
    "#                         img = driver.find_element_by_tag_name('img')\n",
    "#                         src = re.sub(\"\\u200b\", \"\", str(img.get_attribute('src')))\n",
    "#                         urllib.request.urlretrieve(src, Save_path)\n",
    "#                         shutil.move(img_name, move_folder)\n",
    "#                         driver.close()\n",
    "#                     else:\n",
    "#                         Map_exist = 1\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#             Img_id = \"Naver\" + '\\\\' + Category + '\\\\' + User_id + '\\\\' + img_name\n",
    "#             save_img_content = Img_id + \"\\t\" + Post_id\n",
    "\n",
    "#             with open(img_csv_name, 'a', encoding='utf-8') as f:\n",
    "#                 f.write(save_img_content + \"\\n\")\n",
    "#             post_img = Category + \"\\\\\" + User_id + '\\\\' + img_name\n",
    "\n",
    "#         # Post_tag, Media_count\n",
    "#         driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "#         driver.get(url)\n",
    "#         driver.implicitly_wait(10)\n",
    "#         try:\n",
    "#             Post_id = Post_Id_Get_1()\n",
    "#         except:\n",
    "#             Post_id = Post_Id_Get_2()\n",
    "#         # extract comment_count\n",
    "#         Heart_count, Comment_count = Comment_Sympath_Count()\n",
    "#         Media_count = 0\n",
    "#         Media_check = driver.find_elements_by_tag_name('iframe')\n",
    "\n",
    "#         for Media in Media_check:\n",
    "#             if 'Player' in str(Media.get_attribute('src')):\n",
    "#                 Media_count += 1\n",
    "#         tag_list = re.sub('\\n', '', driver.find_element_by_class_name('wrap_tag').text).strip().split('#')[1:]\n",
    "\n",
    "#         for Post_tag in tag_list:\n",
    "#             save_tag = Post_id + \"\\t\" + Post_tag\n",
    "#             with open(tag_csv_name, 'a', encoding='utf-8') as f:\n",
    "#                 f.write(save_tag + \"\\n\")\n",
    "\n",
    "#         # make a save list\n",
    "#         save_post = \"\\t\".join(list(map(str, [Post_id, User_id, Category, Title, Date, Structure, Structure_tag, Text,\n",
    "#                                              Space_text, Count_space_mistake, Map_exist, Media_count, Heart_count,\n",
    "#                                              Sticker_count, Comment_count])))\n",
    "#         with open(post_csv_name, 'a', encoding='utf-8') as f:\n",
    "#             f.write(save_post + \"\\n\")\n",
    "\n",
    "#         driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
