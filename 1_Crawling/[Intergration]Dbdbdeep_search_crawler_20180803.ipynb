{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import urllib\n",
    "import requests\n",
    "import shutil \n",
    "from selenium import webdriver\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pykospacing import spacing\n",
    "import pandas as pd\n",
    "import copy\n",
    "import string, random ## generate random str package\n",
    "from collections import OrderedDict ## repetition removal package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-44bf44956935>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-44bf44956935>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    re.sub(,test)\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def hangul(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글과 띄어쓰기를 제외한 모든 글자\n",
    "    # hangul = re.compile('[^ \\u3131-\\u3163\\uac00-\\ud7a3]+')  # 위와 동일\n",
    "    result = hangul.sub('', text) # 한글과 띄어쓰기를 제외한 모든 부분을 제거\n",
    "    return str(result)\n",
    "\n",
    "def find_categories():\n",
    "    test = driver.find_elements_by_css_selector(\"body > div.lyr_category_lst1 > ul > li:nth-child(1) > ul > li > a\")\n",
    "    Categories = []\n",
    "    re.sub(,test)\n",
    "    for i in test:\n",
    "        Categories.append(i.text.split(\"\\n\")[:2])\n",
    "    Count_Categories = len(Categories)\n",
    "    Categories\n",
    "    return Categories, Count_Categories\n",
    "\n",
    "def find_post_id():\n",
    "    post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "    r = re.compile('logNo=.*')\n",
    "    string = r.findall(post.get_attribute('ng-href'))\n",
    "    return re.sub(\"logNo=\",'',\"\".join(string))\n",
    "\n",
    "def random_id():\n",
    "    passkey='' # an empty str key\n",
    "    for x in range(10): # length of the random passkeys\n",
    "\n",
    "        if random.choice([1,2]) == 1:\n",
    "            passkey += passkey.join(random.choice(string.ascii_letters)) # upper & lower cased letter\n",
    "        else:\n",
    "            passkey += passkey.join(random.choice(string.digits)) # numbers\n",
    "    return passkey\n",
    "\n",
    "def Spacing_text(text_list):\n",
    "    spacing_list = []\n",
    "    for i in text_list:\n",
    "        if len(i) < 197:\n",
    "            spacing_list.append(spacing(i))\n",
    "        else:\n",
    "            iteration = int(len(i) / 197)\n",
    "            mod = len(i) % 197\n",
    "            start = 0\n",
    "            end = 197\n",
    "            check = 0\n",
    "            while True:\n",
    "                # 시행횟수 < 몫\n",
    "                if check < iteration:\n",
    "                    spacing_list.append(spacing(i[start:end]))\n",
    "                    start+=197\n",
    "                    end+=197\n",
    "                    check +=1\n",
    "                else:\n",
    "                    # 마지막 횟수 + 나머지 더 slice \n",
    "                    spacing_list.append(spacing(i[iteration*197:(iteration*197)+mod]))\n",
    "                    break\n",
    "    return spacing_list\n",
    "\n",
    "def remove_odd(x):\n",
    "    x = re.sub(\"&nbsp\",\" \",x)\n",
    "    x = re.sub(\"nbsp\",\" \",x)\n",
    "    x = re.sub(\"\\xa0\",\"\",x)\n",
    "    x = re.sub(\"\\u200b\",\"\",x)\n",
    "    x = re.sub(\"\\n\",\"\",x)\n",
    "    x = re.sub(\"\\t\",\"\",x)\n",
    "    x = re.sub(\"\\r\",\"\",x)\n",
    "    x = re.sub('   ',' ',x)\n",
    "    return x.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Post_Id_Get_1():\n",
    "    foot_info = driver.find_element_by_class_name('wrap_postcomment').get_attribute('innerHTML')\n",
    "    p = re.compile('id=\"area_sympathy.*\" ')\n",
    "    post_id_string = p.findall(foot_info)\n",
    "    if post_id_string == []:\n",
    "        p = re.compile('id=\"Comi.*\" ')\n",
    "        post_id_string = p.findall(foot_info)\n",
    "    remove_quotes = re.sub('\"','',str(post_id_string[0]))\n",
    "    post_no = \"\".join(list(filter(str.isdigit,remove_quotes)))\n",
    "    return post_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Post_Id_Get_2():\n",
    "    #게시글 번호 따오기\n",
    "\n",
    "    foot_info = driver.find_element_by_id('postViewArea').get_attribute('innerHTML')\n",
    "    p = re.compile('postViewArea.*\"')\n",
    "    post_id_string = \"\".join(p.findall(foot_info))\n",
    "\n",
    "    post_id_string = re.sub('postViewArea','',post_id_string)\n",
    "    post_id_string = re.sub('\"','',post_id_string)\n",
    "    return post_id_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comment_Sympath_Count():\n",
    "    p = re.compile('[0-9]')\n",
    "    sympathy_count = ''\n",
    "    comment_count = ''\n",
    "    footer_list = driver.find_elements_by_class_name('wrap_postcomment')[0].text.split('\\n')\n",
    "    for foot in footer_list:\n",
    "        if '공감' in foot:\n",
    "            sympathy_count = \"\".join(p.findall(foot))      \n",
    "        if '댓글' in foot:\n",
    "            comment_count = \"\".join(p.findall(foot))\n",
    "\n",
    "    if sympathy_count == '':\n",
    "        sympathy_count = 0\n",
    "    if comment_count == '':\n",
    "        comment_count = 0\n",
    "    return sympathy_count, comment_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_csv 작성\n",
    "csv_name = 'test_table.csv'\n",
    "col_name = \"\\t\".join([\"User_id\",\"Blog_name\",\"Blog_nickname\",\"Blog_info_text\",\"Count_neighbors\",\"Count_visitors\",\"Categories\",\"Count_categories\",\"Total_post\",\"Credibility\",\"Source\",\"Blog_mobile_profile_img\",\"Blog_mobile_cover_img\",'Opening_date'])\n",
    "\n",
    "if not os.path.exists(csv_name):\n",
    "    with open(csv_name, 'w') as f:\n",
    "        f.write(col_name+'\\n')\n",
    "        \n",
    "# post_csv 작성\n",
    "post_csv_name = 'test_post_table.csv'\n",
    "post_col_name = \"\\t\".join([\"Post_id\",\"User_id\",\"Category\",\"Title\",\"Date\",\"Structure\",\"Structure_tag\",\"Text\",\"Space_text\",\"Count_space_mistake\",\"Map_exist\",\"Media_count\",\"Heart_count\",\"Sticker_count\",\"Comment_count\"])\n",
    "if not os.path.exists(post_csv_name):\n",
    "    with open(post_csv_name, 'w') as f:\n",
    "        f.write(post_col_name +'\\n')\n",
    "\n",
    "# img_csv 작성\n",
    "img_csv_name = 'test_img_table.csv'\n",
    "img_col_name = \"\\t\".join([\"Img_id\",\"Post_id\"])\n",
    "if not os.path.exists(img_csv_name):\n",
    "    with open(img_csv_name, 'w') as f:\n",
    "        f.write(img_col_name +'\\n')\n",
    "\n",
    "# tag_csv 작성\n",
    "tag_csv_name = 'test_tag_table.csv'\n",
    "tag_col_name = \"\\t\".join([\"Post_id\",\"Post_tag\"])\n",
    "if not os.path.exists(tag_csv_name):\n",
    "    with open(tag_csv_name, 'w') as f:\n",
    "        f.write(tag_col_name +'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Category 폴더 만들기\n",
    "\n",
    "Category_list = [\"와인·술\",\"육아·결혼\",\"등산·낚시·레저\",\"드라마·방송\",\"교육·학문\",\"건강·의학\",\"차·커피·디저트\",\\\n",
    "\"국내여행\",\"어학·외국어\",\"만화·애니\",\"IT·컴퓨터\",\"자동차\",\"시사·인문·경제\",\"패션·뷰티\",\"공연·전시\",\"스포츠\",\"맛집\",\"사진\",'무작위']\n",
    "\n",
    "Base_path = os.getcwd()\n",
    "Category_path = \"C:\\\\Users\\\\AjouHCI\\\\Desktop\\\\test\\\\dbdbdeep\"\n",
    "os.chdir(Category_path)\n",
    "    \n",
    "for directory in Category_list:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "os.chdir(Base_path)\n",
    "\n",
    "# 기본 path설정\n",
    "dbdbdeep_folder = \"C:\\\\Users\\\\AjouHCI\\\\Desktop\\\\test\\\\dbdbdeep\\\\\" \n",
    "Base_path = 'C:\\\\workspace\\\\Credibility_Research'\n",
    "Chrome_path = './/exe_file//chromedriver.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post_count_number 입력\n",
    "- sample \n",
    "- \"http://www.netcury.com\" \"넷큐리로부터 지원받아 작성하였습니다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_number = 0\n",
    "end_number = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post number: 0\n",
      "0 \t 와인·술\n",
      "1 \t 육아·결혼\n",
      "2 \t 등산·낚시·레저\n",
      "3 \t 드라마·방송\n",
      "4 \t 교육·학문\n",
      "5 \t 건강·의학\n",
      "6 \t 차·커피·디저트\n",
      "7 \t 국내여행\n",
      "8 \t 어학·외국어\n",
      "9 \t 만화·애니\n",
      "10 \t IT·컴퓨터\n",
      "11 \t 자동차\n",
      "12 \t 시사·인문·경제\n",
      "13 \t 패션·뷰티\n",
      "14 \t 공연·전시\n",
      "15 \t 스포츠\n",
      "16 \t 맛집\n",
      "17 \t 사진\n",
      "18 \t 무작위\n",
      "Category를 입력하세요: 드라마·방송\n",
      "Category : 드라마·방송\n",
      "Category:  드라마·방송 \t블로그 개수:  51\n"
     ]
    }
   ],
   "source": [
    "for post_count_number in tqdm(range(start_number,end_number)):\n",
    "    print(\"post number:\",post_count_number)\n",
    "# Extract User_id and Post_id\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "     # Web blog 검색\n",
    "    driver = webdriver.Chrome(Chrome_path)\n",
    "    driver.get(\"https://search.naver.com/search.naver?where=post&sm=tab_jum\")\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    url_list = []\n",
    "\n",
    "    # Category List 나열\n",
    "\n",
    "    for num,category in enumerate(Category_list):\n",
    "        print(num,'\\t',category)\n",
    "\n",
    "    Category = input(\"Category를 입력하세요: \")\n",
    "    check = 1\n",
    "\n",
    "    while check:\n",
    "        if Category not in Category_list:\n",
    "            Category = input(\"Category를 다시 입력하세요: \")\n",
    "        else:\n",
    "            print(\"Category :\",Category)\n",
    "            check = 0\n",
    "\n",
    "    # click blog in current page and save to list\n",
    "\n",
    "    first_page = 1\n",
    "    check = 1\n",
    "    while check:\n",
    "        if first_page == 1:\n",
    "            first_page = 0\n",
    "            urls = driver.find_elements_by_class_name(\"url\")\n",
    "            for num, url in enumerate(urls):\n",
    "                url.click()   \n",
    "                window_before = driver.window_handles[0]\n",
    "                window_after = driver.window_handles[1]\n",
    "                driver.switch_to_window(window_after)\n",
    "                driver.implicitly_wait(10)\n",
    "                url_list.append(driver.current_url)\n",
    "                driver.close()\n",
    "                driver.switch_to_window(window_before)\n",
    "\n",
    "        # next_button click\n",
    "        try:\n",
    "            driver.find_element_by_class_name(\"next\").click()\n",
    "            driver.implicitly_wait(3)\n",
    "            urls = driver.find_elements_by_class_name(\"url\")\n",
    "\n",
    "            for num, url in enumerate(urls):\n",
    "                url.click()\n",
    "                window_before = driver.window_handles[0]\n",
    "                window_after = driver.window_handles[1]\n",
    "                driver.switch_to_window(window_after)\n",
    "                driver.implicitly_wait(10)\n",
    "                url_list.append(driver.current_url)\n",
    "                driver.close()\n",
    "                driver.switch_to_window(window_before)\n",
    "\n",
    "                if len(url_list) != len(set(url_list)):\n",
    "                    url_list = url_list[:-1]\n",
    "                    check = 0\n",
    "                    break\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    print(\"Category: \",Category,\"\\t블로그 개수: \",len(url_list))\n",
    "\n",
    "    # Get user_id and post_id from url\n",
    "\n",
    "    User_id = []\n",
    "    Post_id = []\n",
    "\n",
    "    for url in url_list:\n",
    "\n",
    "        if '?' in url: \n",
    "            User_id.append(re.sub(\"https://blog.naver.com/\",\"\",url).split(\"?\")[0])\n",
    "            Post_id.append(\"\".join(re.findall(\"\\d+\",re.sub(\"https://blog.naver.com/\",\"\",url).split(\"?\")[1])))\n",
    "\n",
    "        elif 'blog.me' in url:\n",
    "            url_temp = re.sub(\"https://\",\"\",url).split(\".\")\n",
    "            temp_Post_id = url\n",
    "            User_id.append(url_temp[0])\n",
    "            Post_id.append(re.sub(\"https://blog.naver.com/\",\"\",temp_Post_id).split(\"/\")[-1])\n",
    "\n",
    "        else:\n",
    "            url_temp = re.sub(\"https://blog.naver.com/\",\"\",url).split(\"/\")\n",
    "            User_id.append(url_temp[0])\n",
    "            Post_id.append(url_temp[1])\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    ## Path 설정\n",
    "    move_path =  dbdbdeep_folde\n",
    "\n",
    "## User_Table Crwaling\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # user_id, post_id zip, remove_duplicated\n",
    "\n",
    "    blog_list = list(set((zip(copy.copy(User_id),copy.copy(Post_id)))))\n",
    "    blog_list = list(filter(lambda x : len(x[1]) > 0,blog_list))\n",
    "    \n",
    "    User_id = []\n",
    "    Post_id = []\n",
    "    \n",
    "    # verifying blog_list\n",
    "    for user_id, post_id in blog_list:\n",
    "        url = \"http://blog.naver.com/PostView.nhn?blogId=\"+user_id+ \"&logNo=\" + post_id +\"&redirect=Dlog&widgetTypeCall=true\"\n",
    "        r = requests.get(url)\n",
    "        if '접근하고자하는 블로그 아이디가 없습니다.' not in r.text or '해당 블로그가 없습니다.' not in r.text:\n",
    "            User_id.append(user_id)\n",
    "            Post_id.append(post_id)\n",
    "    # blog_list _ verification        \n",
    "    blog_list = list(set((zip(copy.copy(User_id),copy.copy(Post_id)))))\n",
    "    blog_list = list(filter(lambda x : len(x[1]) > 0,blog_list))\n",
    "\n",
    "    # source credibility\n",
    "    Credibility = 0\n",
    "    Source = \"dbdbdeep\"\n",
    "        \n",
    "    for user_id, post_id in blog_list:\n",
    "        User_id = user_id\n",
    "        Post_id = post_id\n",
    "        Source = Source \n",
    "        Credibility = Credibility\n",
    "        url = \"http://blog.naver.com/PostView.nhn?blogId=\"+User_id+ \"&logNo=\" + Post_id +\"&redirect=Dlog&widgetTypeCall=true\"\n",
    "        mobile_url = \"http://m.blog.naver.com/PostView.nhn?blogId=\"+ User_id\n",
    "\n",
    "        # get mobile_url\n",
    "        driver = webdriver.Chrome(Chrome_path)\n",
    "        driver.get(mobile_url)\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        # 존재하지 않는 게시물 클릭\n",
    "        driver.find_element_by_class_name(\"btn_area\").click()\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(1)\n",
    "        # Blog_name, Blog_nickname, Blog_mobile_profile_img, Blog_info_text\n",
    "        Blog_name = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > h2 > a > span').text\n",
    "        Blog_nickname =driver.find_element_by_class_name(\"user_name\").text\n",
    "\n",
    "        try:\n",
    "            post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "            Blog_mobile_profile_img_url = post.get_attribute('ng-href')  \n",
    "        except:\n",
    "            post = driver.find_element_by_css_selector('#rego_cover > div.cover_cont > div.tit_area > div.bloger > span.thumb > a')\n",
    "            Blog_mobile_profile_img_url = post.get_attribute('href')\n",
    "            \n",
    "        try:\n",
    "            Blog_info_text = driver.find_element_by_class_name(\"text\").text\n",
    "\n",
    "        except:\n",
    "            Blog_info_text = \"\"\n",
    "        Blog_info_text = remove_odd(Blog_info_text)    \n",
    "\n",
    "        # Count_neighbors\n",
    "        neighbors_string = re.sub(\",\",\"\",driver.find_element_by_class_name(\"count_buddy\").text)\n",
    "        Count_neighbors = int(re.findall('\\d+', neighbors_string)[0])\n",
    "\n",
    "        # Count_visitors\n",
    "        visitor_stirng = driver.find_elements_by_class_name('count')[0].text\n",
    "        Count_visitors = re.sub(\",\",\"\",visitor_stirng.split(\"전체\")[1]).strip()\n",
    "\n",
    "        # download_img\n",
    "        Mobile_cover_img_url = driver.find_element_by_class_name(\"cover_img\").get_attribute('bg-lazy-img')\n",
    "\n",
    "        # category 버튼 클릭\n",
    "        driver.find_element_by_css_selector(\"#rego_cover > div.cover_cont > div.btn_area > div > div:nth-child(2) > a > span.txt\").click()\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        # Total_Post, Categories, Count_Categories, \n",
    "\n",
    "        Categories, Count_categories =  find_categories()\n",
    "        Total_post = driver.find_element_by_class_name(\"num\").text\n",
    "        driver.close()\n",
    "        \n",
    "        Opening_date = Opening_Date_Get(user_id)\n",
    "        \n",
    "\n",
    "        os.chdir(move_path)\n",
    "\n",
    "        # make category_folder\n",
    "        folder_name = User_id\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "        \n",
    "        os.chdir(os.join(move_path,User_id))\n",
    "\n",
    "        Save_path = dbdbdeep_folder '\\\\' + folder_name\n",
    "        os.chdir(Save_path)\n",
    "        cover_img = \"Cover_\" + User_id + \".jpg\"\n",
    "        Blog_mobile_profile_img = User_id + \"\\\\\" + cover_img\n",
    "\n",
    "        profile_img = \"Profile_\" + User_id + \".jpg\"\n",
    "        Blog_mobile_cover_img =  User_id +  \"\\\\\" + profile_img\n",
    "        \n",
    "        #download_img\n",
    "        profile_cover_image_check = os.listdir(os.join(move_path,User_id))\n",
    "        print(profile_cover_image_check)\n",
    "        if \"Profile_\" or \"Cover_\" not in profile_cover_image_check: \n",
    "            urllib.request.urlretrieve(Mobile_cover_img_url,cover_img)\n",
    "            urllib.request.urlretrieve(Blog_mobile_profile_img_url,profile_img)\n",
    "\n",
    "        os.chdir(Base_path)\n",
    "\n",
    "        save_content_list = [User_id,Blog_name,Blog_nickname,Blog_info_text,Count_neighbors,Count_visitors,Categories,Count_categories,Total_post,Credibility,Source,Blog_mobile_profile_img,Blog_mobile_cover_img,Opening_date]\n",
    "        save_content = \"\\t\".join(list(map(str,save_content_list)))\n",
    "\n",
    "        with open(csv_name, 'a', encoding='utf-8') as f:\n",
    "            f.write(save_content+\"\\n\")\n",
    "\n",
    "# Post & Tag & Img Table_Crwaling        \n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    for user_id, post_id in blog_list:\n",
    "        User_id = user_id\n",
    "        Post_id = post_id\n",
    "        Category = Category\n",
    "\n",
    "        url = \"http://blog.naver.com/PostView.nhn?blogId=\"+User_id+ \"&logNo=\" + Post_id +\"&redirect=Dlog&widgetTypeCall=true\"\n",
    "        r = requests.get(url)\n",
    "        bs = BeautifulSoup(re.sub('&nbsp;',' ',r.text).encode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "        #title\n",
    "        Title = bs.find(\"h3\", {\"class\": \"se_textarea\"})\n",
    "        if (Title == None):\n",
    "            Title = bs.find(\"span\", {\"class\": \"pcol1 itemSubjectBoldfont\"})\n",
    "        if (Title != None):\n",
    "            Title = Title.text.strip()\n",
    "        else:\n",
    "            Title = \"TITLE ERROR\"\n",
    "\n",
    "        #date\n",
    "        # Append_value\n",
    "        Date = bs.find(\"span\", {\"class\": \"se_publishDate pcol2 fil5\"})\n",
    "\n",
    "        if Date == None:\n",
    "            Date = bs.find(\"p\",{\"class\":\"date fil5 pcol2 _postAddDate\"})\n",
    "        if Date == None:\n",
    "            Date = bs.find(\"span\",{\"class\":\"se_publishDate pcol2\"})\n",
    "\n",
    "        Date_text = re.sub(\"\\n\",\"\",Date.text)\n",
    "        Date = re.sub(\"\\t\",\"\",Date_text)\n",
    "\n",
    "        #Tag, Content_structure, Text\n",
    "\n",
    "        # structure\n",
    "        structure = bs.find(\"div\", {\"id\": \"postViewArea\"})\n",
    "        if structure == None:\n",
    "            structure = bs.find(\"div\",{\"class\",\"se_component_wrap sect_dsc __se_component_area\"})\n",
    "        structure_tag = structure.find_all(['p','img'])\n",
    "\n",
    "\n",
    "        # only tag & texf extract\n",
    "        tag_list = []\n",
    "        structure_list = []\n",
    "        text_list = []\n",
    "\n",
    "        for i in structure_tag:\n",
    "            # p_tag만 불러오기\n",
    "            if \"<p\" in (str(i)):\n",
    "                tag_list.append('<p>')\n",
    "                structure_list.append('<p>')\n",
    "                # img만 있을 때\n",
    "\n",
    "                if '<img' in str(i):\n",
    "                    for j in i:\n",
    "                        try:\n",
    "                            if len(j.text)>1:\n",
    "                                tag_list.append('<br>')\n",
    "                                structure_list.append('<br>')\n",
    "                                structure_list.append(j.text)\n",
    "                                text_list.append(j.text)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                # img가 아닌 경우 span tag가 더 있을 때\n",
    "                elif '<span' in str(i):\n",
    "                    for j in i:\n",
    "                        if '<br' in str(j):\n",
    "                            structure_list.append(j.text)\n",
    "                            text_list.append(j.text)\n",
    "                            # br_tag가 2개 이상 있을 때\n",
    "\n",
    "                            if len(j.findAll('br'))>2:\n",
    "                                for _ in range(0,len(j.findAll('br'))):\n",
    "                                    tag_list.append('<br>')\n",
    "                                    structure_list.append('<br>')\n",
    "\n",
    "                            # br_tag가 1개 있을 때\n",
    "                            else:\n",
    "                                tag_list.append('<br>')\n",
    "                                structure_list.append('<br>')\n",
    "\n",
    "                        # span은 있지만 br tag가 없을 때       \n",
    "                        else:\n",
    "                            try:\n",
    "                                structure_list.append(j.text)\n",
    "                                text_list.append(j.text)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                # 그냥 p_tag만 있을 때 br_tag 추가\n",
    "                else:\n",
    "                    # 글이 있을 때\n",
    "                    if len(i.text) > 1:\n",
    "                        structure_list.append(i.text)\n",
    "                        text_list.append(i.text)\n",
    "\n",
    "                    # 글 없이 br tag만 있을 때\n",
    "                    else:\n",
    "                        tag_list.append('<br>')\n",
    "                        structure_list.append(i.text)\n",
    "                        structure_list.append('<br>')\n",
    "                        text_list.append(i.text)\n",
    "\n",
    "                # P_tag 끝맽음      \n",
    "                tag_list.append('</p>')\n",
    "                structure_list.append('</p>')\n",
    "\n",
    "            else:\n",
    "                tag_list.append('<img>')\n",
    "                structure_list.append('<img>')\n",
    "\n",
    "\n",
    "        structure_list = list(map(remove_odd,structure_list))\n",
    "        text_list = list(map(remove_odd,text_list))\n",
    "        filter_text = list(filter(lambda x: len(x)>1 ,text_list))\n",
    "\n",
    "        Structure = \"|\".join(list(filter(lambda x: len(x)>1 ,structure_list)))        \n",
    "        Text = \" \".join(list(filter(lambda x: len(x)>1 ,map(lambda x : x.strip(),text_list))))\n",
    "        Text = re.sub('\\n','',Text)\n",
    "        Text = re.sub('\\t','',Text)\n",
    "        Space_text = \" \".join(Spacing_text(filter_text))\n",
    "        Count_space_mistake = len(Space_text)-len(Text)\n",
    "\n",
    "\n",
    "        # only tag\n",
    "        Structure_tag = \"|\".join(tag_list)\n",
    "\n",
    "        # image download    \n",
    "        imgs = structure.find_all('img')\n",
    "        Save_path = dbdbdeep_folder + Category + '\\\\' + User_id\n",
    "\n",
    "\n",
    "        Map_exist = 0\n",
    "        Sticker_count = 0\n",
    "        # Sticker_count로 수정\n",
    "        sticker_img = structure.find_all('a')\n",
    "        for i in sticker_img:\n",
    "            if 'sticker' in str(i):\n",
    "                Sticker_count += 1\n",
    "        \n",
    "        # image download    \n",
    "        imgs = structure.find_all('img')\n",
    "        \n",
    "        for img in imgs:\n",
    "\n",
    "            if \"스티커 이미지\" in str(img):\n",
    "                img_name = \"Sticker_\" + User_id + \"_\" + random_id() + \".jpg\"\n",
    "            else:\n",
    "                img_name =  User_id + \"_\" + random_id() + \".jpg\"\n",
    "            try:\n",
    "                img_url = re.sub(\"\\u200b\",\"\",str(img['src']))\n",
    "\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(img_url,img_name)\n",
    "                    shutil.move(img_name,Save_path)\n",
    "\n",
    "                except UnicodeEncodeError:\n",
    "                    try:\n",
    "                        if 'map' not in str(img_url):\n",
    "                            driver = webdriver.Chrome(Chrome_path)\n",
    "                            driver.get(url)\n",
    "                            driver.implicitly_wait(3)\n",
    "                            img = driver.find_element_by_tag_name('img')\n",
    "                            src = re.sub(\"\\u200b\",\"\",str(img.get_attribute('src')))\n",
    "                            urllib.request.urlretrieve(src, Save_path)\n",
    "                            shutil.move(img_name,move_folder)\n",
    "                            driver.close()\n",
    "                        else:\n",
    "                            Map_exist = 1\n",
    "                    except:\n",
    "                        pass\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                Img_id = \"dbdbdeep\" + '\\\\'+ Category + '\\\\' + User_id + '\\\\'+ img_name\n",
    "                save_img_content = Img_id + \"\\t\" + Post_id\n",
    "\n",
    "                with open(img_csv_name, 'a', encoding='utf-8') as f:\n",
    "                    f.write(save_img_content + \"\\n\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Post_tag, Media_count\n",
    "        driver = webdriver.Chrome('.//exe_file//chromedriver.exe')\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(10)\n",
    "        \n",
    "        #extract comment_count\n",
    "        Heart_count, Comment_count = Comment_Sympath_Count()\n",
    "        Media_count = 0\n",
    "        Media_check = driver.find_elements_by_tag_name('iframe')\n",
    "\n",
    "        for Media in Media_check:\n",
    "            if 'Player' in str(Media.get_attribute('src')):\n",
    "                Media_count += 1\n",
    "        tag_list = re.sub('\\n','',driver.find_element_by_class_name('wrap_tag').text).strip().split('#')[1:]\n",
    "        \n",
    "        for Post_tag in tag_list:\n",
    "            save_tag = Post_id + \"\\t\" + Post_tag\n",
    "            with open(tag_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_tag + \"\\n\")\n",
    "                \n",
    "        for Media in Media_check:\n",
    "            if 'Player' in str(Media.get_attribute('src')):\n",
    "                Media_count += 1\n",
    "        # make a save list\n",
    "        save_post = \"\\t\".join(list(map(str,[Post_id,User_id,Category,Title,Date,Structure,Structure_tag,Text,Space_text,Count_space_mistake,Map_exist,Media_count,Heart_count,Sticker_count,Comment_count])))\n",
    "\n",
    "        with open(post_csv_name, 'a', encoding='utf-8') as f:\n",
    "                f.write(save_post + \"\\n\")\n",
    "        driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
