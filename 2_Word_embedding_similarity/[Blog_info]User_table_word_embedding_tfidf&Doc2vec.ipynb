{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_user = pd.read_csv('[Final]naver_user_table.csv',sep='\\t',encoding='utf-8')\n",
    "dbdbdeep_user = pd.read_csv('[Final]dbdbdeep_user_table.csv',sep='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refined_category(category):\n",
    "    refined_list = []\n",
    "    for i in category.split('], '):\n",
    "        try:\n",
    "            category_count = int(i.split(', ')[0].replace('[','').replace(\"'\",''))\n",
    "            categoty_title = i.split(', ')[1]\n",
    "            categoty_title = i.split(', ')[1].replace(']]','')\n",
    "            categoty_title = categoty_title.replace(')]','')\n",
    "            refined_list.append((category_count,categoty_title))\n",
    "        except:\n",
    "            pass\n",
    "    return refined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refined_category_title(category):\n",
    "    refined_list = []\n",
    "    for i in category.split('], '):\n",
    "        try:\n",
    "            categoty_title = i.split(', ')[1]\n",
    "            categoty_title = i.split(', ')[1].replace(']]','')\n",
    "            categoty_title = categoty_title.replace(')]','')\n",
    "            refined_list.append((categoty_title))\n",
    "        except:\n",
    "            pass\n",
    "    return refined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_stopword = pd.read_csv('Korean_stopwords.txt',encoding='utf-8',header=None)\n",
    "korean_stopword_list = korean_stopword[0].tolist()\n",
    "stopwords = ['하다', ',', '들', '이', '..', '.', '것', '다', '이다', '~', '그', '그녀', '저', '...', '\"', '~~',\"'\",':','&','[',']','{','}','(',')','-'] \n",
    "sum_stopwords = stopwords + korean_stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Korean_tagger(Text):\n",
    "\n",
    "    twitter = Twitter()\n",
    "\n",
    "    try:\n",
    "        malist = twitter.pos(Text, norm=True, stem=True)\n",
    "        r = []\n",
    "        remove_tag =['Eomi','PreEomi','Josa','Determiner','Foreign','Alpha','Number','Punctuation','Suffix','Unknown','Hashtag','KoreanParticle','ScreenName']\n",
    "\n",
    "        stopwords = sum_stopwords\n",
    "\n",
    "\n",
    "        for word in malist:\n",
    "            # 어미/조사/구두점/ㅋㅋ^^ㅎㅎ/음표살림/Alphabet/부사는 대상에서 제외\n",
    "            if not word[1] in remove_tag:\n",
    "                if not word[0] in r:\n",
    "                    if not word[0] in stopwords:\n",
    "                       # 숫자, 특수문자 제거.\n",
    "                        r.append(word[0])\n",
    "        return ' '.join(r)\n",
    "    except Exception as e:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "naver_user['Blog_info_text_embedding'] = naver_user['Blog_info_text'].apply(lambda x : Korean_tagger(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "dbdbdeep_user['Blog_info_text_embedding'] = dbdbdeep_user['Blog_info_text'].apply(lambda x : Korean_tagger(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_user = pd.concat([naver_user,dbdbdeep_user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_test = Total_user[['Blog_info_text_embedding','Credibility']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Info_text = Total_test['Blog_info_text_embedding'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(max_features=161)\n",
    "x = v.fit_transform(Info_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Total_test['Credibility'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x , y , test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : 0.712450592885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "result = LinearSVC(random_state=0).fit(x_train, y_train)\n",
    "result.predict(x_test)\n",
    "print(\"SVM :\",accuracy_score(result.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.90      0.81       672\n",
      "          1       0.64      0.34      0.44       340\n",
      "\n",
      "avg / total       0.70      0.71      0.68      1012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71498371,  0.72638436,  0.67536705,  0.68627451,  0.74836601])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(result, x, y, cv=5)\n",
    "scores                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_test = Total_user[['Blog_info_text_embedding','Credibility']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Total_test['Blog_info_text_embedding'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer = Doc2Vec(\n",
    "    dm=0,            # PV-DBOW / default 1\n",
    "    dbow_words=1,    # w2v simultaneous with DBOW d2v / default 0\n",
    "    window=8,        # distance between the predicted word and context words\n",
    "    size=92,        # vector size\n",
    "    alpha=0.025,     # learning-rate\n",
    "    seed=1234,\n",
    "    min_count=20,    # ignore with freq lower\n",
    "    min_alpha=0.025, # min learning-rate\n",
    "    workers=cores,   # multi cpu\n",
    "    hs = 1,          # hierarchical softmax / default 0\n",
    "    negative = 10,   # negative sampling / default 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 11:35:20,275 : INFO : collecting all words and their counts\n",
      "2018-09-02 11:35:20,277 : WARNING : Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.\n",
      "2018-09-02 11:35:20,278 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-09-02 11:35:20,315 : INFO : collected 1076 word types and 3065 unique tags from a corpus of 3065 examples and 70462 words\n",
      "2018-09-02 11:35:20,316 : INFO : Loading a fresh vocabulary\n",
      "2018-09-02 11:35:20,319 : INFO : min_count=20 retains 377 unique words (35% of original 1076, drops 699)\n",
      "2018-09-02 11:35:20,320 : INFO : min_count=20 leaves 66888 word corpus (94% of original 70462, drops 3574)\n",
      "2018-09-02 11:35:20,321 : INFO : deleting the raw counts dictionary of 1076 items\n",
      "2018-09-02 11:35:20,326 : INFO : sample=0.001 downsamples 67 most-common words\n",
      "2018-09-02 11:35:20,328 : INFO : downsampling leaves estimated 36255 word corpus (54.2% of prior 66888)\n",
      "2018-09-02 11:35:20,330 : INFO : constructing a huffman tree from 377 words\n",
      "2018-09-02 11:35:20,340 : INFO : built huffman tree with maximum node depth 12\n",
      "2018-09-02 11:35:20,345 : INFO : estimated required memory for 377 words and 92 dimensions: 2421028 bytes\n",
      "2018-09-02 11:35:20,346 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d92,n10,hs,w8,mc20,s0.001,t4)\n"
     ]
    }
   ],
   "source": [
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.95"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.corpus_count*0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  after removing the cwd from sys.path.\n",
      "2018-09-02 11:35:24,516 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:24,712 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:24,838 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:24,844 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:24,846 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:24,847 : INFO : EPOCH - 1 : training on 70462 raw words (39317 effective words) took 0.3s, 121884 effective words/s\n",
      "2018-09-02 11:35:25,044 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:25,160 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:25,170 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:25,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:25,173 : INFO : EPOCH - 2 : training on 70462 raw words (39221 effective words) took 0.3s, 122656 effective words/s\n",
      "2018-09-02 11:35:25,367 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:25,468 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:25,494 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:25,494 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:25,495 : INFO : EPOCH - 3 : training on 70462 raw words (39294 effective words) took 0.3s, 125232 effective words/s\n",
      "2018-09-02 11:35:25,689 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:25,802 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:25,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:25,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:25,809 : INFO : EPOCH - 4 : training on 70462 raw words (39254 effective words) took 0.3s, 128717 effective words/s\n",
      "2018-09-02 11:35:26,031 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:26,138 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:26,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:26,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:26,148 : INFO : EPOCH - 5 : training on 70462 raw words (39297 effective words) took 0.3s, 118618 effective words/s\n",
      "2018-09-02 11:35:26,148 : INFO : training on a 352310 raw words (196383 effective words) took 1.6s, 120445 effective words/s\n",
      "2018-09-02 11:35:26,149 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:26,359 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:26,474 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:26,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:26,485 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:26,486 : INFO : EPOCH - 1 : training on 70462 raw words (39449 effective words) took 0.3s, 121334 effective words/s\n",
      "2018-09-02 11:35:26,672 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:26,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:26,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:26,797 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:26,797 : INFO : EPOCH - 2 : training on 70462 raw words (39275 effective words) took 0.3s, 128908 effective words/s\n",
      "2018-09-02 11:35:26,990 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:27,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:27,117 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:27,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:27,126 : INFO : EPOCH - 3 : training on 70462 raw words (39196 effective words) took 0.3s, 122174 effective words/s\n",
      "2018-09-02 11:35:27,337 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:27,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:27,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:27,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:27,475 : INFO : EPOCH - 4 : training on 70462 raw words (39279 effective words) took 0.3s, 115112 effective words/s\n",
      "2018-09-02 11:35:27,669 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:27,788 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:27,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:27,792 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:27,793 : INFO : EPOCH - 5 : training on 70462 raw words (39222 effective words) took 0.3s, 127750 effective words/s\n",
      "2018-09-02 11:35:27,794 : INFO : training on a 352310 raw words (196421 effective words) took 1.6s, 119599 effective words/s\n",
      "2018-09-02 11:35:27,795 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:27,988 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:28,105 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:28,111 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:28,114 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:28,116 : INFO : EPOCH - 1 : training on 70462 raw words (39297 effective words) took 0.3s, 124990 effective words/s\n",
      "2018-09-02 11:35:28,338 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:28,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:28,456 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:28,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:28,481 : INFO : EPOCH - 2 : training on 70462 raw words (39344 effective words) took 0.4s, 111189 effective words/s\n",
      "2018-09-02 11:35:28,665 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:28,783 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:28,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:28,788 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:28,788 : INFO : EPOCH - 3 : training on 70462 raw words (39371 effective words) took 0.3s, 131534 effective words/s\n",
      "2018-09-02 11:35:28,982 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:29,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:29,101 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:29,106 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:29,107 : INFO : EPOCH - 4 : training on 70462 raw words (39381 effective words) took 0.3s, 126715 effective words/s\n",
      "2018-09-02 11:35:29,303 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:29,411 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:29,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:29,425 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 11:35:29,426 : INFO : EPOCH - 5 : training on 70462 raw words (39415 effective words) took 0.3s, 126458 effective words/s\n",
      "2018-09-02 11:35:29,426 : INFO : training on a 352310 raw words (196808 effective words) took 1.6s, 120659 effective words/s\n",
      "2018-09-02 11:35:29,427 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:29,634 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:29,748 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:29,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:29,755 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:29,756 : INFO : EPOCH - 1 : training on 70462 raw words (39279 effective words) took 0.3s, 123430 effective words/s\n",
      "2018-09-02 11:35:29,946 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:30,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:30,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:30,070 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:30,071 : INFO : EPOCH - 2 : training on 70462 raw words (39275 effective words) took 0.3s, 128648 effective words/s\n",
      "2018-09-02 11:35:30,262 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:30,367 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:30,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:30,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:30,387 : INFO : EPOCH - 3 : training on 70462 raw words (39187 effective words) took 0.3s, 127476 effective words/s\n",
      "2018-09-02 11:35:30,585 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:30,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:30,701 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:30,710 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:30,711 : INFO : EPOCH - 4 : training on 70462 raw words (39375 effective words) took 0.3s, 124950 effective words/s\n",
      "2018-09-02 11:35:30,943 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:31,021 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:31,041 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:31,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:31,054 : INFO : EPOCH - 5 : training on 70462 raw words (39221 effective words) took 0.3s, 117264 effective words/s\n",
      "2018-09-02 11:35:31,055 : INFO : training on a 352310 raw words (196337 effective words) took 1.6s, 120652 effective words/s\n",
      "2018-09-02 11:35:31,056 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:31,261 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:31,375 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:31,387 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:31,404 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:31,405 : INFO : EPOCH - 1 : training on 70462 raw words (39248 effective words) took 0.3s, 116292 effective words/s\n",
      "2018-09-02 11:35:31,597 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:31,706 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:31,717 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:31,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:31,720 : INFO : EPOCH - 2 : training on 70462 raw words (39332 effective words) took 0.3s, 128555 effective words/s\n",
      "2018-09-02 11:35:31,921 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:32,025 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:32,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:32,047 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:32,047 : INFO : EPOCH - 3 : training on 70462 raw words (39322 effective words) took 0.3s, 123888 effective words/s\n",
      "2018-09-02 11:35:32,245 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:32,346 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:32,352 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:32,354 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:32,355 : INFO : EPOCH - 4 : training on 70462 raw words (39240 effective words) took 0.3s, 130994 effective words/s\n",
      "2018-09-02 11:35:32,547 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:32,655 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:32,669 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:32,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:32,672 : INFO : EPOCH - 5 : training on 70462 raw words (39288 effective words) took 0.3s, 128137 effective words/s\n",
      "2018-09-02 11:35:32,673 : INFO : training on a 352310 raw words (196430 effective words) took 1.6s, 121675 effective words/s\n",
      "2018-09-02 11:35:32,674 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:32,873 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:32,978 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:32,989 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:32,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:32,996 : INFO : EPOCH - 1 : training on 70462 raw words (39374 effective words) took 0.3s, 128271 effective words/s\n",
      "2018-09-02 11:35:33,186 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:33,299 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:33,307 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:33,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:33,316 : INFO : EPOCH - 2 : training on 70462 raw words (39321 effective words) took 0.3s, 126751 effective words/s\n",
      "2018-09-02 11:35:33,547 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:33,612 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:33,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:33,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:33,663 : INFO : EPOCH - 3 : training on 70462 raw words (39322 effective words) took 0.3s, 116770 effective words/s\n",
      "2018-09-02 11:35:33,852 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:33,960 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:33,962 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:33,967 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:33,967 : INFO : EPOCH - 4 : training on 70462 raw words (39331 effective words) took 0.3s, 131925 effective words/s\n",
      "2018-09-02 11:35:34,171 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:34,280 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:34,292 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:34,302 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 11:35:34,302 : INFO : EPOCH - 5 : training on 70462 raw words (39333 effective words) took 0.3s, 120455 effective words/s\n",
      "2018-09-02 11:35:34,303 : INFO : training on a 352310 raw words (196681 effective words) took 1.6s, 120917 effective words/s\n",
      "2018-09-02 11:35:34,304 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:34,501 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:34,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:34,623 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:34,629 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:34,630 : INFO : EPOCH - 1 : training on 70462 raw words (39355 effective words) took 0.3s, 124823 effective words/s\n",
      "2018-09-02 11:35:34,826 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:34,938 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:34,943 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:34,948 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:34,949 : INFO : EPOCH - 2 : training on 70462 raw words (39321 effective words) took 0.3s, 128133 effective words/s\n",
      "2018-09-02 11:35:35,156 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:35,270 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:35,278 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:35,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:35,296 : INFO : EPOCH - 3 : training on 70462 raw words (39283 effective words) took 0.3s, 116686 effective words/s\n",
      "2018-09-02 11:35:35,492 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:35,613 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:35,625 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:35,630 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:35,631 : INFO : EPOCH - 4 : training on 70462 raw words (39330 effective words) took 0.3s, 120599 effective words/s\n",
      "2018-09-02 11:35:35,831 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:35,948 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:35,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:35,978 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:35,979 : INFO : EPOCH - 5 : training on 70462 raw words (39315 effective words) took 0.3s, 115311 effective words/s\n",
      "2018-09-02 11:35:35,980 : INFO : training on a 352310 raw words (196604 effective words) took 1.7s, 117341 effective words/s\n",
      "2018-09-02 11:35:35,981 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:36,183 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:36,294 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:36,305 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:36,306 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:36,308 : INFO : EPOCH - 1 : training on 70462 raw words (39442 effective words) took 0.3s, 123893 effective words/s\n",
      "2018-09-02 11:35:36,514 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:36,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:36,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:36,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:36,640 : INFO : EPOCH - 2 : training on 70462 raw words (39344 effective words) took 0.3s, 122755 effective words/s\n",
      "2018-09-02 11:35:36,845 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:36,962 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:36,970 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:36,975 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:36,976 : INFO : EPOCH - 3 : training on 70462 raw words (39209 effective words) took 0.3s, 119432 effective words/s\n",
      "2018-09-02 11:35:37,210 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:37,321 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:37,337 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:37,349 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:37,350 : INFO : EPOCH - 4 : training on 70462 raw words (39379 effective words) took 0.4s, 107747 effective words/s\n",
      "2018-09-02 11:35:37,571 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:37,707 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:37,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:37,729 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:37,730 : INFO : EPOCH - 5 : training on 70462 raw words (39346 effective words) took 0.4s, 106796 effective words/s\n",
      "2018-09-02 11:35:37,731 : INFO : training on a 352310 raw words (196720 effective words) took 1.7s, 112470 effective words/s\n",
      "2018-09-02 11:35:37,732 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:37,974 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:38,057 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:38,075 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:38,112 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:38,113 : INFO : EPOCH - 1 : training on 70462 raw words (39410 effective words) took 0.4s, 106650 effective words/s\n",
      "2018-09-02 11:35:38,317 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:38,425 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:38,434 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:38,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:38,440 : INFO : EPOCH - 2 : training on 70462 raw words (39299 effective words) took 0.3s, 123609 effective words/s\n",
      "2018-09-02 11:35:38,713 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:38,759 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:38,782 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:38,784 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:38,786 : INFO : EPOCH - 3 : training on 70462 raw words (39294 effective words) took 0.3s, 116917 effective words/s\n",
      "2018-09-02 11:35:39,069 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:39,102 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:39,105 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:39,141 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:39,142 : INFO : EPOCH - 4 : training on 70462 raw words (39378 effective words) took 0.3s, 113342 effective words/s\n",
      "2018-09-02 11:35:39,337 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:39,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:39,463 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:39,464 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 11:35:39,464 : INFO : EPOCH - 5 : training on 70462 raw words (39328 effective words) took 0.3s, 125138 effective words/s\n",
      "2018-09-02 11:35:39,465 : INFO : training on a 352310 raw words (196709 effective words) took 1.7s, 113522 effective words/s\n",
      "2018-09-02 11:35:39,466 : INFO : training model with 4 workers on 377 vocabulary and 92 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:35:39,669 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:39,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:39,794 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:39,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:39,804 : INFO : EPOCH - 1 : training on 70462 raw words (39291 effective words) took 0.3s, 120512 effective words/s\n",
      "2018-09-02 11:35:39,996 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:40,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:40,122 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:40,126 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:40,127 : INFO : EPOCH - 2 : training on 70462 raw words (39356 effective words) took 0.3s, 125769 effective words/s\n",
      "2018-09-02 11:35:40,365 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:40,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:40,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:40,479 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:40,479 : INFO : EPOCH - 3 : training on 70462 raw words (39441 effective words) took 0.3s, 115403 effective words/s\n",
      "2018-09-02 11:35:40,668 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:40,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:40,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:40,806 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:40,808 : INFO : EPOCH - 4 : training on 70462 raw words (39275 effective words) took 0.3s, 122185 effective words/s\n",
      "2018-09-02 11:35:41,003 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:35:41,111 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:35:41,134 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:35:41,138 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:35:41,138 : INFO : EPOCH - 5 : training on 70462 raw words (39394 effective words) took 0.3s, 122535 effective words/s\n",
      "2018-09-02 11:35:41,139 : INFO : training on a 352310 raw words (196757 effective words) took 1.7s, 117657 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During Time: 16.624151945114136\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(sentences, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "end = time.time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [doc_vectorizer.infer_vector(doc.words) for doc in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train , y , test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : 0.728260869565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "result = LinearSVC(random_state=0).fit(x_train, y_train)\n",
    "result.predict(x_test)\n",
    "print(\"SVM :\",accuracy_score(result.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(50,),\n",
    "    max_iter=10,\n",
    "    alpha=1e-4,\n",
    "    solver='sgd',\n",
    "    verbose=10,\n",
    "    tol=1e-4,\n",
    "    random_state=1,\n",
    "    learning_rate_init=.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.63657523\n",
      "Iteration 2, loss = 0.57108310\n",
      "Iteration 3, loss = 0.53959295\n",
      "Iteration 4, loss = 0.52346447\n",
      "Iteration 5, loss = 0.51377926\n",
      "Iteration 6, loss = 0.50754608\n",
      "Iteration 7, loss = 0.49968620\n",
      "Iteration 8, loss = 0.49422984\n",
      "Iteration 9, loss = 0.48718201\n",
      "Iteration 10, loss = 0.48103360\n",
      "Time: 0.112207s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp_clf.fit(X_train, y)\n",
    "end = time.time()\n",
    "print('Time: {:f}s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 0.771\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp_clf.predict(x_test)\n",
    "print(\"테스트 정확도: {:.3f}\".format(accuracy_score(y_pred, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
