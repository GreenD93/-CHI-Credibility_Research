{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_user = pd.read_csv('[Final]naver_user_table.csv',sep='\\t',encoding='utf-8')\n",
    "dbdbdeep_user = pd.read_csv('[Final]dbdbdeep_user_table.csv',sep='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refined_category(category):\n",
    "    refined_list = []\n",
    "    for i in category.split('], '):\n",
    "        try:\n",
    "            category_count = int(i.split(', ')[0].replace('[','').replace(\"'\",''))\n",
    "            categoty_title = i.split(', ')[1]\n",
    "            categoty_title = i.split(', ')[1].replace(']]','')\n",
    "            categoty_title = categoty_title.replace(')]','')\n",
    "            refined_list.append((category_count,categoty_title))\n",
    "        except:\n",
    "            pass\n",
    "    return refined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refined_category_title(category):\n",
    "    refined_list = []\n",
    "    for i in category.split('], '):\n",
    "        try:\n",
    "            categoty_title = i.split(', ')[1]\n",
    "            categoty_title = i.split(', ')[1].replace(']]','')\n",
    "            categoty_title = categoty_title.replace(')]','')\n",
    "            refined_list.append((categoty_title))\n",
    "        except:\n",
    "            pass\n",
    "    return refined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_stopword = pd.read_csv('Korean_stopwords.txt',encoding='utf-8',header=None)\n",
    "korean_stopword_list = korean_stopword[0].tolist()\n",
    "stopwords = ['하다', ',', '들', '이', '..', '.', '것', '다', '이다', '~', '그', '그녀', '저', '...', '\"', '~~',\"'\",':','&','[',']','{','}','(',')','-'] \n",
    "sum_stopwords = stopwords + korean_stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Korean_tagger(Text):\n",
    "\n",
    "    twitter = Twitter()\n",
    "\n",
    "    try:\n",
    "        \n",
    "        \n",
    "        malist = twitter.pos(Text, norm=True, stem=True)\n",
    "        r = []\n",
    "        remove_tag =['Eomi','PreEomi','Josa','Determiner','Foreign','Alpha','Number','Punctuation','Suffix','Unknown','Hashtag','KoreanParticle','ScreenName']\n",
    "\n",
    "        stopwords = sum_stopwords\n",
    "\n",
    "\n",
    "        for word in malist:\n",
    "            # 어미/조사/구두점/ㅋㅋ^^ㅎㅎ/음표살림/Alphabet/부사는 대상에서 제외\n",
    "            if not word[1] in remove_tag:\n",
    "                if not word[0] in r:\n",
    "                    if not word[0] in stopwords:\n",
    "                       # 숫자, 특수문자 제거.\n",
    "                        r.append(word[0])\n",
    "        return ' '.join(r)\n",
    "    except Exception as e:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "naver_user['Categories_embedding'] = naver_user['Categories'].apply(lambda x : \"\".join(refined_category_title(x)))\n",
    "naver_user['Categories_embedding'] = naver_user['Categories_embedding'].apply(lambda x : Korean_tagger(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "dbdbdeep_user['Categories_embedding'] = dbdbdeep_user['Categories'].apply(lambda x : \"\".join(refined_category_title(x)))\n",
    "dbdbdeep_user['Categories_embedding'] = dbdbdeep_user['Categories_embedding'].apply(lambda x : Korean_tagger(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_user = pd.concat([naver_user,dbdbdeep_user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_test = Total_user[['Categories_embedding','Credibility']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categories_text = Total_test['Categories_embedding'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(max_features=391)\n",
    "x = v.fit_transform(Categories_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Total_test['Credibility'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x , y , test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : 0.830039525692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "result = LinearSVC(random_state=0).fit(x_train, y_train)\n",
    "result.predict(x_test)\n",
    "print(\"SVM :\",accuracy_score(result.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.91      0.88       672\n",
      "          1       0.79      0.67      0.73       340\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85504886,  0.84201954,  0.72430669,  0.8120915 ,  0.81372549])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(result, x, y, cv=5)\n",
    "scores                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_test = Total_user[['Categories_embedding','Credibility']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Total_test['Categories_embedding'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "2018-09-02 11:46:54,549 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer = Doc2Vec(\n",
    "    dm=0,            # PV-DBOW / default 1\n",
    "    dbow_words=1,    # w2v simultaneous with DBOW d2v / default 0\n",
    "    window=8,        # distance between the predicted word and context words\n",
    "    size=391,        # vector size\n",
    "    alpha=0.025,     # learning-rate\n",
    "    seed=1234,\n",
    "    min_count=20,    # ignore with freq lower\n",
    "    min_alpha=0.025, # min learning-rate\n",
    "    workers=cores,   # multi cpu\n",
    "    hs = 1,          # hierarchical softmax / default 0\n",
    "    negative = 10,   # negative sampling / default 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 11:46:56,973 : INFO : collecting all words and their counts\n",
      "2018-09-02 11:46:56,975 : WARNING : Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.\n",
      "2018-09-02 11:46:56,977 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-09-02 11:46:57,063 : INFO : collected 1337 word types and 3065 unique tags from a corpus of 3065 examples and 229662 words\n",
      "2018-09-02 11:46:57,063 : INFO : Loading a fresh vocabulary\n",
      "2018-09-02 11:46:57,067 : INFO : min_count=20 retains 613 unique words (45% of original 1337, drops 724)\n",
      "2018-09-02 11:46:57,069 : INFO : min_count=20 leaves 225765 word corpus (98% of original 229662, drops 3897)\n",
      "2018-09-02 11:46:57,072 : INFO : deleting the raw counts dictionary of 1337 items\n",
      "2018-09-02 11:46:57,074 : INFO : sample=0.001 downsamples 78 most-common words\n",
      "2018-09-02 11:46:57,074 : INFO : downsampling leaves estimated 126697 word corpus (56.1% of prior 225765)\n",
      "2018-09-02 11:46:57,078 : INFO : constructing a huffman tree from 613 words\n",
      "2018-09-02 11:46:57,097 : INFO : built huffman tree with maximum node depth 13\n",
      "2018-09-02 11:46:57,099 : INFO : estimated required memory for 613 words and 391 dimensions: 8711956 bytes\n",
      "2018-09-02 11:46:57,102 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d391,n10,hs,w8,mc20,s0.001,t4)\n"
     ]
    }
   ],
   "source": [
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.95"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.corpus_count*0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  after removing the cwd from sys.path.\n",
      "2018-09-02 11:47:29,274 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:47:30,405 : INFO : EPOCH 1 - PROGRESS: at 21.17% examples, 44661 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:47:31,277 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:31,462 : INFO : EPOCH 1 - PROGRESS: at 83.16% examples, 54242 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:47:31,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:31,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:31,477 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:31,478 : INFO : EPOCH - 1 : training on 229662 raw words (129661 effective words) took 2.2s, 59001 effective words/s\n",
      "2018-09-02 11:47:32,597 : INFO : EPOCH 2 - PROGRESS: at 21.17% examples, 45322 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:47:33,485 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:33,614 : INFO : EPOCH 2 - PROGRESS: at 81.89% examples, 55623 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:47:33,616 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:33,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:33,658 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:33,659 : INFO : EPOCH - 2 : training on 229662 raw words (129652 effective words) took 2.2s, 59666 effective words/s\n",
      "2018-09-02 11:47:34,826 : INFO : EPOCH 3 - PROGRESS: at 21.17% examples, 43767 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:47:35,793 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:35,920 : INFO : EPOCH 3 - PROGRESS: at 83.16% examples, 52860 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:47:35,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:35,927 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:35,934 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:35,935 : INFO : EPOCH - 3 : training on 229662 raw words (129947 effective words) took 2.3s, 57489 effective words/s\n",
      "2018-09-02 11:47:37,128 : INFO : EPOCH 4 - PROGRESS: at 21.17% examples, 42214 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:47:38,050 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:38,155 : INFO : EPOCH 4 - PROGRESS: at 81.89% examples, 53419 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:47:38,156 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:38,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:38,207 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:38,208 : INFO : EPOCH - 4 : training on 229662 raw words (129662 effective words) took 2.3s, 57159 effective words/s\n",
      "2018-09-02 11:47:39,398 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 42334 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:47:40,440 : INFO : EPOCH 5 - PROGRESS: at 70.05% examples, 47422 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-02 11:47:40,649 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:40,724 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:40,770 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:40,796 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:40,796 : INFO : EPOCH - 5 : training on 229662 raw words (129745 effective words) took 2.6s, 50183 effective words/s\n",
      "2018-09-02 11:47:40,798 : INFO : training on a 1148310 raw words (648667 effective words) took 11.5s, 56299 effective words/s\n",
      "2018-09-02 11:47:40,799 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:47:42,067 : INFO : EPOCH 1 - PROGRESS: at 21.66% examples, 39699 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:47:43,136 : INFO : EPOCH 1 - PROGRESS: at 75.69% examples, 48296 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:47:43,137 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:43,158 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:43,218 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:43,294 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:43,295 : INFO : EPOCH - 1 : training on 229662 raw words (129607 effective words) took 2.5s, 52036 effective words/s\n",
      "2018-09-02 11:47:44,470 : INFO : EPOCH 2 - PROGRESS: at 21.17% examples, 42954 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:47:45,461 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:45,615 : INFO : EPOCH 2 - PROGRESS: at 81.89% examples, 51112 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:47:45,616 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:45,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:45,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:45,632 : INFO : EPOCH - 2 : training on 229662 raw words (129608 effective words) took 2.3s, 55573 effective words/s\n",
      "2018-09-02 11:47:46,849 : INFO : EPOCH 3 - PROGRESS: at 21.17% examples, 41663 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:47:47,753 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:47,909 : INFO : EPOCH 3 - PROGRESS: at 81.89% examples, 52214 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:47:47,910 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:47,968 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:47,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:47,975 : INFO : EPOCH - 3 : training on 229662 raw words (129814 effective words) took 2.3s, 55569 effective words/s\n",
      "2018-09-02 11:47:49,181 : INFO : EPOCH 4 - PROGRESS: at 21.17% examples, 41945 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:47:50,119 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:50,265 : INFO : EPOCH 4 - PROGRESS: at 81.89% examples, 51826 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:47:50,266 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:50,303 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:50,333 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:50,334 : INFO : EPOCH - 4 : training on 229662 raw words (129818 effective words) took 2.4s, 55130 effective words/s\n",
      "2018-09-02 11:47:51,528 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 42661 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:47:52,570 : INFO : EPOCH 5 - PROGRESS: at 75.69% examples, 50802 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:47:52,571 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:52,660 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:52,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:52,736 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:52,737 : INFO : EPOCH - 5 : training on 229662 raw words (129595 effective words) took 2.4s, 54290 effective words/s\n",
      "2018-09-02 11:47:52,738 : INFO : training on a 1148310 raw words (648442 effective words) took 11.9s, 54320 effective words/s\n",
      "2018-09-02 11:47:52,740 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:47:54,002 : INFO : EPOCH 1 - PROGRESS: at 21.66% examples, 39974 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 11:47:55,073 : INFO : EPOCH 1 - PROGRESS: at 75.69% examples, 48395 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:47:55,075 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:55,246 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:55,252 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:55,311 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:55,312 : INFO : EPOCH - 1 : training on 229662 raw words (129655 effective words) took 2.6s, 50500 effective words/s\n",
      "2018-09-02 11:47:56,688 : INFO : EPOCH 2 - PROGRESS: at 21.92% examples, 36658 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:47:57,648 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:47:57,734 : INFO : EPOCH 2 - PROGRESS: at 81.89% examples, 48959 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:47:57,735 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:47:57,767 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:47:57,831 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:47:57,832 : INFO : EPOCH - 2 : training on 229662 raw words (129795 effective words) took 2.5s, 51610 effective words/s\n",
      "2018-09-02 11:47:59,015 : INFO : EPOCH 3 - PROGRESS: at 21.66% examples, 42517 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:47:59,960 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:00,134 : INFO : EPOCH 3 - PROGRESS: at 81.89% examples, 51516 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:00,135 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:00,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:00,196 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:00,197 : INFO : EPOCH - 3 : training on 229662 raw words (129679 effective words) took 2.4s, 54960 effective words/s\n",
      "2018-09-02 11:48:01,442 : INFO : EPOCH 4 - PROGRESS: at 21.17% examples, 40596 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:02,444 : INFO : EPOCH 4 - PROGRESS: at 72.53% examples, 49600 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-02 11:48:02,555 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:02,660 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:02,670 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:02,712 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:02,713 : INFO : EPOCH - 4 : training on 229662 raw words (129699 effective words) took 2.5s, 51666 effective words/s\n",
      "2018-09-02 11:48:03,923 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 41795 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:04,921 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:05,029 : INFO : EPOCH 5 - PROGRESS: at 83.16% examples, 51314 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:05,030 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:05,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:05,085 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:05,086 : INFO : EPOCH - 5 : training on 229662 raw words (129871 effective words) took 2.4s, 54890 effective words/s\n",
      "2018-09-02 11:48:05,086 : INFO : training on a 1148310 raw words (648699 effective words) took 12.3s, 52544 effective words/s\n",
      "2018-09-02 11:48:05,087 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:48:06,230 : INFO : EPOCH 1 - PROGRESS: at 21.17% examples, 44177 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:07,250 : INFO : EPOCH 1 - PROGRESS: at 75.69% examples, 52402 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:48:07,250 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:07,353 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:07,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:07,441 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:07,442 : INFO : EPOCH - 1 : training on 229662 raw words (129909 effective words) took 2.3s, 55336 effective words/s\n",
      "2018-09-02 11:48:08,610 : INFO : EPOCH 2 - PROGRESS: at 21.17% examples, 43205 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:09,615 : INFO : EPOCH 2 - PROGRESS: at 75.69% examples, 52051 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:48:09,616 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:09,760 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:09,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:09,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:09,799 : INFO : EPOCH - 2 : training on 229662 raw words (129818 effective words) took 2.4s, 55205 effective words/s\n",
      "2018-09-02 11:48:11,070 : INFO : EPOCH 3 - PROGRESS: at 21.17% examples, 39741 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:12,151 : INFO : EPOCH 3 - PROGRESS: at 75.69% examples, 48041 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:48:12,153 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:12,236 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:12,272 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:12,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:12,326 : INFO : EPOCH - 3 : training on 229662 raw words (129732 effective words) took 2.5s, 51429 effective words/s\n",
      "2018-09-02 11:48:13,568 : INFO : EPOCH 4 - PROGRESS: at 21.17% examples, 40668 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:14,576 : INFO : EPOCH 4 - PROGRESS: at 75.69% examples, 50168 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:48:14,578 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:14,759 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:14,770 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:14,779 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:14,780 : INFO : EPOCH - 4 : training on 229662 raw words (129653 effective words) took 2.4s, 52926 effective words/s\n",
      "2018-09-02 11:48:16,017 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 40767 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:17,066 : INFO : EPOCH 5 - PROGRESS: at 70.05% examples, 46319 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-02 11:48:17,258 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:17,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:17,462 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:17,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:17,469 : INFO : EPOCH - 5 : training on 229662 raw words (129661 effective words) took 2.7s, 48307 effective words/s\n",
      "2018-09-02 11:48:17,469 : INFO : training on a 1148310 raw words (648773 effective words) took 12.4s, 52407 effective words/s\n",
      "2018-09-02 11:48:17,471 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:48:18,719 : INFO : EPOCH 1 - PROGRESS: at 21.17% examples, 40334 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:19,691 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:19,804 : INFO : EPOCH 1 - PROGRESS: at 83.16% examples, 50856 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:19,806 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:19,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:19,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 11:48:19,851 : INFO : EPOCH - 1 : training on 229662 raw words (129702 effective words) took 2.4s, 54611 effective words/s\n",
      "2018-09-02 11:48:20,993 : INFO : EPOCH 2 - PROGRESS: at 21.17% examples, 44204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:21,871 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:22,096 : INFO : EPOCH 2 - PROGRESS: at 86.33% examples, 52872 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:22,097 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:22,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:22,099 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:22,100 : INFO : EPOCH - 2 : training on 229662 raw words (129693 effective words) took 2.2s, 57810 effective words/s\n",
      "2018-09-02 11:48:23,304 : INFO : EPOCH 3 - PROGRESS: at 21.92% examples, 41840 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:24,185 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:24,359 : INFO : EPOCH 3 - PROGRESS: at 81.89% examples, 52525 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:24,360 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:24,365 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:24,377 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:24,378 : INFO : EPOCH - 3 : training on 229662 raw words (129763 effective words) took 2.3s, 57092 effective words/s\n",
      "2018-09-02 11:48:25,534 : INFO : EPOCH 4 - PROGRESS: at 21.66% examples, 43591 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:26,417 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:26,557 : INFO : EPOCH 4 - PROGRESS: at 81.89% examples, 54433 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:26,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:26,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:26,601 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:26,601 : INFO : EPOCH - 4 : training on 229662 raw words (129772 effective words) took 2.2s, 58484 effective words/s\n",
      "2018-09-02 11:48:27,764 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 43354 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:28,674 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:28,863 : INFO : EPOCH 5 - PROGRESS: at 81.89% examples, 52515 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:28,864 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:28,899 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:28,914 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:28,915 : INFO : EPOCH - 5 : training on 229662 raw words (129856 effective words) took 2.3s, 56238 effective words/s\n",
      "2018-09-02 11:48:28,916 : INFO : training on a 1148310 raw words (648786 effective words) took 11.4s, 56689 effective words/s\n",
      "2018-09-02 11:48:28,917 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:48:30,148 : INFO : EPOCH 1 - PROGRESS: at 21.66% examples, 40875 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:31,050 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:31,229 : INFO : EPOCH 1 - PROGRESS: at 81.89% examples, 51263 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:31,236 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:31,270 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:31,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:31,272 : INFO : EPOCH - 1 : training on 229662 raw words (129579 effective words) took 2.3s, 55164 effective words/s\n",
      "2018-09-02 11:48:32,498 : INFO : EPOCH 2 - PROGRESS: at 21.17% examples, 41142 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:33,442 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:33,620 : INFO : EPOCH 2 - PROGRESS: at 83.16% examples, 50599 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:33,621 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:33,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:33,667 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:33,668 : INFO : EPOCH - 2 : training on 229662 raw words (129853 effective words) took 2.4s, 54309 effective words/s\n",
      "2018-09-02 11:48:34,902 : INFO : EPOCH 3 - PROGRESS: at 21.17% examples, 40912 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:35,903 : INFO : EPOCH 3 - PROGRESS: at 75.69% examples, 50545 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:48:35,904 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:36,044 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:36,053 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:36,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:36,085 : INFO : EPOCH - 3 : training on 229662 raw words (129617 effective words) took 2.4s, 53781 effective words/s\n",
      "2018-09-02 11:48:37,200 : INFO : EPOCH 4 - PROGRESS: at 21.17% examples, 45368 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:38,082 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:38,244 : INFO : EPOCH 4 - PROGRESS: at 81.89% examples, 55033 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:38,245 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:38,259 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:38,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:38,280 : INFO : EPOCH - 4 : training on 229662 raw words (129838 effective words) took 2.2s, 59260 effective words/s\n",
      "2018-09-02 11:48:39,446 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 43689 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:40,526 : INFO : EPOCH 5 - PROGRESS: at 63.72% examples, 44767 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-02 11:48:40,699 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:40,903 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:40,967 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:40,975 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:40,976 : INFO : EPOCH - 5 : training on 229662 raw words (129863 effective words) took 2.7s, 48400 effective words/s\n",
      "2018-09-02 11:48:40,977 : INFO : training on a 1148310 raw words (648750 effective words) took 12.1s, 53800 effective words/s\n",
      "2018-09-02 11:48:40,979 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:48:42,277 : INFO : EPOCH 1 - PROGRESS: at 21.17% examples, 39021 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:43,241 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:43,376 : INFO : EPOCH 1 - PROGRESS: at 81.89% examples, 49625 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:43,377 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:43,421 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:43,424 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:43,425 : INFO : EPOCH - 1 : training on 229662 raw words (130040 effective words) took 2.4s, 53292 effective words/s\n",
      "2018-09-02 11:48:44,588 : INFO : EPOCH 2 - PROGRESS: at 21.17% examples, 43270 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:45,629 : INFO : EPOCH 2 - PROGRESS: at 75.69% examples, 51250 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:48:45,631 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 11:48:45,726 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:45,757 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:45,823 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:45,824 : INFO : EPOCH - 2 : training on 229662 raw words (129751 effective words) took 2.4s, 54178 effective words/s\n",
      "2018-09-02 11:48:46,942 : INFO : EPOCH 3 - PROGRESS: at 13.15% examples, 24907 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:47,943 : INFO : EPOCH 3 - PROGRESS: at 34.88% examples, 34222 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:48,545 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:48,710 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:48,750 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:48,756 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:48,757 : INFO : EPOCH - 3 : training on 229662 raw words (129603 effective words) took 2.9s, 44261 effective words/s\n",
      "2018-09-02 11:48:49,765 : INFO : EPOCH 4 - PROGRESS: at 15.60% examples, 33355 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:50,906 : INFO : EPOCH 4 - PROGRESS: at 60.29% examples, 44437 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:51,147 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:51,267 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:51,275 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:51,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:51,319 : INFO : EPOCH - 4 : training on 229662 raw words (130104 effective words) took 2.6s, 50895 effective words/s\n",
      "2018-09-02 11:48:52,520 : INFO : EPOCH 5 - PROGRESS: at 21.66% examples, 42112 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:53,475 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:53,658 : INFO : EPOCH 5 - PROGRESS: at 81.89% examples, 50891 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:48:53,659 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:53,670 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:53,689 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:53,690 : INFO : EPOCH - 5 : training on 229662 raw words (130133 effective words) took 2.4s, 54997 effective words/s\n",
      "2018-09-02 11:48:53,691 : INFO : training on a 1148310 raw words (649631 effective words) took 12.7s, 51112 effective words/s\n",
      "2018-09-02 11:48:53,691 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:48:54,968 : INFO : EPOCH 1 - PROGRESS: at 21.66% examples, 39531 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:48:56,024 : INFO : EPOCH 1 - PROGRESS: at 75.69% examples, 48484 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-02 11:48:56,025 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:56,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:56,143 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:56,210 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:56,211 : INFO : EPOCH - 1 : training on 229662 raw words (129761 effective words) took 2.5s, 51612 effective words/s\n",
      "2018-09-02 11:48:57,408 : INFO : EPOCH 2 - PROGRESS: at 21.17% examples, 42126 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:48:58,456 : INFO : EPOCH 2 - PROGRESS: at 72.53% examples, 49614 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-02 11:48:58,558 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:48:58,686 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:48:58,729 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:48:58,773 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:48:58,774 : INFO : EPOCH - 2 : training on 229662 raw words (129607 effective words) took 2.6s, 50660 effective words/s\n",
      "2018-09-02 11:49:00,037 : INFO : EPOCH 3 - PROGRESS: at 21.17% examples, 39868 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:49:00,920 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:01,067 : INFO : EPOCH 3 - PROGRESS: at 81.89% examples, 51615 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:01,068 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:01,078 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:01,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:01,108 : INFO : EPOCH - 3 : training on 229662 raw words (129443 effective words) took 2.3s, 55584 effective words/s\n",
      "2018-09-02 11:49:02,243 : INFO : EPOCH 4 - PROGRESS: at 21.17% examples, 44471 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:49:03,128 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:03,310 : INFO : EPOCH 4 - PROGRESS: at 81.89% examples, 53930 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:03,311 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:03,316 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:03,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:03,336 : INFO : EPOCH - 4 : training on 229662 raw words (129853 effective words) took 2.2s, 58378 effective words/s\n",
      "2018-09-02 11:49:04,485 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 43912 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:49:05,410 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:05,537 : INFO : EPOCH 5 - PROGRESS: at 81.89% examples, 53862 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:05,538 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:05,593 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:05,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:05,620 : INFO : EPOCH - 5 : training on 229662 raw words (129586 effective words) took 2.3s, 56862 effective words/s\n",
      "2018-09-02 11:49:05,621 : INFO : training on a 1148310 raw words (648250 effective words) took 11.9s, 54346 effective words/s\n",
      "2018-09-02 11:49:05,622 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:49:06,837 : INFO : EPOCH 1 - PROGRESS: at 21.17% examples, 41461 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:49:07,760 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:07,980 : INFO : EPOCH 1 - PROGRESS: at 81.89% examples, 50188 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:07,981 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:07,990 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:07,995 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:07,996 : INFO : EPOCH - 1 : training on 229662 raw words (129309 effective words) took 2.4s, 54620 effective words/s\n",
      "2018-09-02 11:49:09,263 : INFO : EPOCH 2 - PROGRESS: at 21.66% examples, 39735 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:49:10,171 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:10,330 : INFO : EPOCH 2 - PROGRESS: at 81.89% examples, 50769 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:10,332 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:10,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:10,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:10,370 : INFO : EPOCH - 2 : training on 229662 raw words (129604 effective words) took 2.4s, 54697 effective words/s\n",
      "2018-09-02 11:49:11,578 : INFO : EPOCH 3 - PROGRESS: at 21.17% examples, 41932 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 11:49:12,491 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:12,659 : INFO : EPOCH 3 - PROGRESS: at 81.89% examples, 51860 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:12,660 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:12,683 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:12,709 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:12,710 : INFO : EPOCH - 3 : training on 229662 raw words (129747 effective words) took 2.3s, 55628 effective words/s\n",
      "2018-09-02 11:49:13,854 : INFO : EPOCH 4 - PROGRESS: at 21.17% examples, 44134 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:49:14,739 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:14,881 : INFO : EPOCH 4 - PROGRESS: at 81.89% examples, 54727 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:14,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:14,897 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:14,933 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:14,933 : INFO : EPOCH - 4 : training on 229662 raw words (129956 effective words) took 2.2s, 58556 effective words/s\n",
      "2018-09-02 11:49:16,080 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 44020 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:49:17,018 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:17,142 : INFO : EPOCH 5 - PROGRESS: at 81.89% examples, 53697 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:17,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:17,175 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:17,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:17,213 : INFO : EPOCH - 5 : training on 229662 raw words (129725 effective words) took 2.3s, 57021 effective words/s\n",
      "2018-09-02 11:49:17,213 : INFO : training on a 1148310 raw words (648341 effective words) took 11.6s, 55938 effective words/s\n",
      "2018-09-02 11:49:17,214 : INFO : training model with 4 workers on 613 vocabulary and 391 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2018-09-02 11:49:18,362 : INFO : EPOCH 1 - PROGRESS: at 21.17% examples, 43933 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:49:19,264 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:19,419 : INFO : EPOCH 1 - PROGRESS: at 83.16% examples, 53818 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:19,420 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:19,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:19,471 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:19,472 : INFO : EPOCH - 1 : training on 229662 raw words (129641 effective words) took 2.3s, 57562 effective words/s\n",
      "2018-09-02 11:49:20,620 : INFO : EPOCH 2 - PROGRESS: at 21.17% examples, 44008 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:49:21,543 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:21,706 : INFO : EPOCH 2 - PROGRESS: at 81.89% examples, 53115 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:21,707 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:21,718 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:21,739 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:21,740 : INFO : EPOCH - 2 : training on 229662 raw words (129769 effective words) took 2.3s, 57324 effective words/s\n",
      "2018-09-02 11:49:22,921 : INFO : EPOCH 3 - PROGRESS: at 22.35% examples, 42803 words/s, in_qsize 8, out_qsize 0\n",
      "2018-09-02 11:49:23,806 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:23,993 : INFO : EPOCH 3 - PROGRESS: at 81.89% examples, 52722 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:23,994 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:23,997 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:24,024 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:24,025 : INFO : EPOCH - 3 : training on 229662 raw words (129900 effective words) took 2.3s, 56955 effective words/s\n",
      "2018-09-02 11:49:25,167 : INFO : EPOCH 4 - PROGRESS: at 21.17% examples, 44243 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:49:26,054 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:26,188 : INFO : EPOCH 4 - PROGRESS: at 81.89% examples, 54800 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:26,189 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:26,228 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:26,246 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:26,247 : INFO : EPOCH - 4 : training on 229662 raw words (129547 effective words) took 2.2s, 58425 effective words/s\n",
      "2018-09-02 11:49:27,431 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 42643 words/s, in_qsize 7, out_qsize 0\n",
      "2018-09-02 11:49:28,281 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-02 11:49:28,457 : INFO : EPOCH 5 - PROGRESS: at 81.89% examples, 53710 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-02 11:49:28,459 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-02 11:49:28,499 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-02 11:49:28,504 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-02 11:49:28,504 : INFO : EPOCH - 5 : training on 229662 raw words (129759 effective words) took 2.3s, 57590 effective words/s\n",
      "2018-09-02 11:49:28,505 : INFO : training on a 1148310 raw words (648616 effective words) took 11.3s, 57450 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During Time: 119.23198103904724\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(sentences, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "end = time.time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [doc_vectorizer.infer_vector(doc.words) for doc in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train , y , test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : 0.807312252964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "result = LinearSVC(random_state=0).fit(x_train, y_train)\n",
    "result.predict(x_test)\n",
    "print(\"SVM :\",accuracy_score(result.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(50,),\n",
    "    max_iter=10,\n",
    "    alpha=1e-4,\n",
    "    solver='sgd',\n",
    "    verbose=10,\n",
    "    tol=1e-4,\n",
    "    random_state=1,\n",
    "    learning_rate_init=.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.58986401\n",
      "Iteration 2, loss = 0.39349004\n",
      "Iteration 3, loss = 0.34249328\n",
      "Iteration 4, loss = 0.31402776\n",
      "Iteration 5, loss = 0.29559513\n",
      "Iteration 6, loss = 0.28058410\n",
      "Iteration 7, loss = 0.26707563\n",
      "Iteration 8, loss = 0.25575315\n",
      "Iteration 9, loss = 0.24410927\n",
      "Iteration 10, loss = 0.23320133\n",
      "Time: 0.169047s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonggeol/anaconda3/envs/py/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp_clf.fit(X_train, y)\n",
    "end = time.time()\n",
    "print('Time: {:f}s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 0.916\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp_clf.predict(x_test)\n",
    "print(\"테스트 정확도: {:.3f}\".format(accuracy_score(y_pred, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
