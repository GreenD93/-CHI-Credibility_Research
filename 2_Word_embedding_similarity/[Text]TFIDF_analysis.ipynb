{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사진 제외 : 87%\n",
    "# 사진 포함 : 88%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naver = pd.read_csv('A_V_Adj_C_df_naver_post_table.csv',sep='\\t',encoding='utf-8')\n",
    "df_dbdbdeep = pd.read_csv('A_V_Adj_C_df_dbdbdeep_post_table.csv',sep='\\t',encoding='utf-8')\n",
    "df_naver_page = pd.read_csv('A_V_Adj_C_df_naver_page_table.csv',sep='\\t',encoding='utf-8')\n",
    "df_dbdbdeep_page = pd.read_csv('A_V_Adj_C_df_dbdbdeep_page_table.csv',sep='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "IT·컴퓨터       514\n",
       "건강·의학        917\n",
       "공연·전시        378\n",
       "교육·학문        732\n",
       "국내여행          80\n",
       "드라마·방송       383\n",
       "등산·낚시·레저      39\n",
       "만화·애니         30\n",
       "맛집           662\n",
       "사진            31\n",
       "스포츠           64\n",
       "시사·인문·경제      95\n",
       "어학·외국어       179\n",
       "와인·술          68\n",
       "육아·결혼         55\n",
       "자동차          330\n",
       "차·커피·디저트     569\n",
       "패션·뷰티       1238\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dbdbdeep.groupby(by='Category')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "IT·컴퓨터       476\n",
       "건강·의학        565\n",
       "공연·전시        532\n",
       "교육·학문        492\n",
       "국내여행         475\n",
       "드라마·방송       258\n",
       "등산·낚시·레저     232\n",
       "만화·애니        653\n",
       "맛집          1033\n",
       "사진          1682\n",
       "스포츠          841\n",
       "시사·인문·경제     565\n",
       "어학·외국어       162\n",
       "와인·술          80\n",
       "육아·결혼        257\n",
       "자동차          643\n",
       "차·커피·디저트     254\n",
       "패션·뷰티        742\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naver.groupby(by='Category')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naver = df_naver.dropna(subset=['Embedding_text'])\n",
    "df_dbdbdeep = df_dbdbdeep.dropna(subset=['Embedding_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Embedding_text_reduction(Embedding_text):\n",
    "    if len(Embedding_text.split(' '))> 55:\n",
    "        return \" \".join(Embedding_text.split(' ')[:-28])\n",
    "    elif len(Embedding_text.split(' '))>45:\n",
    "        return \" \".join(Embedding_text.split(' ')[:-12])\n",
    "    elif len(Embedding_text.split(' '))>35:\n",
    "        return \" \".join(Embedding_text.split(' ')[:-5])\n",
    "    else:\n",
    "        return \" \".join(Embedding_text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naver['Embedding_text'] = df_naver['Embedding_text'].apply(lambda x : Embedding_text_reduction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_naver = df_naver[df_naver['Category'] != '사진']\n",
    "# df_dbdbdeep = df_dbdbdeep[df_dbdbdeep['Category'] != '사진']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_naver = shuffle(df_naver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dbdbdeep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_naver = df_naver.iloc[:6178]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjouHCI\\Anaconda3\\envs\\py\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Total = pd.concat([df_naver,df_dbdbdeep,df_naver_page,df_dbdbdeep_page])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total = Total.dropna(subset=['Embedding_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = Total['Embedding_text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(max_features=100)\n",
    "x = v.fit_transform(Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "#Save vectorizer.vocabulary_\n",
    "pickle.dump(v.vocabulary_,open(\"Text_features_100.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vec = TfidfVectorizer(decode_error=\"replace\",vocabulary=pickle.load(open(\"Text_features_100.pkl\", \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Total['Embedding_text'].apply(lambda x : transformer.fit_transform(loaded_vec.fit_transform(np.array([x]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Array = list(map(lambda x : x.toarray(),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = Total['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'Array':Array,'label':Label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "test_df = shuffle(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_df['Array'].apply(lambda x: x.flatten())\n",
    "x = x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "# test = shuffle(test)\n",
    "# test = test.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x , y , test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : 0.8617085427135679\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "result = LinearSVC(random_state=0).fit(x_train, y_train)\n",
    "result.predict(x_test)\n",
    "print(\"SVM :\",accuracy_score(result.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.81      0.83      2036\n",
      "        1.0       0.87      0.90      0.88      2939\n",
      "\n",
      "avg / total       0.86      0.86      0.86      4975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86898839, 0.87396352, 0.86401327, 0.86197744, 0.8715992 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(result, x, y, cv=5)\n",
    "\n",
    "scores                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB : 0.820502512562814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.predict(x_test)\n",
    "print(\"NB :\",accuracy_score(clf.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.83      0.79      2036\n",
      "        1.0       0.87      0.81      0.84      2939\n",
      "\n",
      "avg / total       0.83      0.82      0.82      4975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82354892, 0.82321725, 0.81890547, 0.81353683, 0.83244857])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, x, y, cv=5)\n",
    "scores                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjouHCI\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF : 0.7762814070351759\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"RF :\",accuracy_score(clf.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.54      0.66      2036\n",
      "        1.0       0.75      0.94      0.83      2939\n",
      "\n",
      "avg / total       0.80      0.78      0.76      4975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77910448, 0.79104478, 0.77147595, 0.78201725, 0.79595222])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, x, y, cv=5)\n",
    "scores                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logsitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=42, solver='sag',\n",
       "          tol=0.0001, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn  import  linear_model\n",
    "logreg = linear_model.LogisticRegression(C=2.0,random_state=42,solver='sag',multi_class='multinomial',warm_start=True)\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF : 0.862713567839196\n"
     ]
    }
   ],
   "source": [
    "print(\"RF :\",accuracy_score(logreg.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.81      0.83      2036\n",
      "        1.0       0.87      0.90      0.89      2939\n",
      "\n",
      "avg / total       0.86      0.86      0.86      4975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, logreg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86865672, 0.87495854, 0.86368159, 0.86297279, 0.86960849])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(logreg, x, y, cv=5)\n",
    "scores                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT : 0.7841206030150754\n"
     ]
    }
   ],
   "source": [
    "print(\"DT :\",accuracy_score(clf.predict(x_test),y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.73      0.73      2036\n",
      "        1.0       0.81      0.82      0.82      2939\n",
      "\n",
      "avg / total       0.78      0.78      0.78      4975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79004975, 0.79402985, 0.77313433, 0.7743862 , 0.79727936])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, x, y, cv=5)\n",
    "scores                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(50,),\n",
    "    max_iter=35,\n",
    "    alpha=1e-4,\n",
    "    solver='sgd',\n",
    "    verbose=10,\n",
    "    tol=1e-4,\n",
    "    random_state=1,\n",
    "    learning_rate_init=.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.57983937\n",
      "Iteration 2, loss = 0.35908439\n",
      "Iteration 3, loss = 0.32573120\n",
      "Iteration 4, loss = 0.32007679\n",
      "Iteration 5, loss = 0.31807734\n",
      "Iteration 6, loss = 0.31715078\n",
      "Iteration 7, loss = 0.31592271\n",
      "Iteration 8, loss = 0.31582633\n",
      "Iteration 9, loss = 0.31383355\n",
      "Iteration 10, loss = 0.31384717\n",
      "Iteration 11, loss = 0.31238460\n",
      "Iteration 12, loss = 0.31146634\n",
      "Iteration 13, loss = 0.30877022\n",
      "Iteration 14, loss = 0.30842177\n",
      "Iteration 15, loss = 0.30693345\n",
      "Iteration 16, loss = 0.30514031\n",
      "Iteration 17, loss = 0.30302447\n",
      "Iteration 18, loss = 0.30198294\n",
      "Iteration 19, loss = 0.30031109\n",
      "Iteration 20, loss = 0.29770017\n",
      "Iteration 21, loss = 0.29748683\n",
      "Iteration 22, loss = 0.29451736\n",
      "Iteration 23, loss = 0.29369916\n",
      "Iteration 24, loss = 0.29059317\n",
      "Iteration 25, loss = 0.28980086\n",
      "Iteration 26, loss = 0.28730343\n",
      "Iteration 27, loss = 0.28509838\n",
      "Iteration 28, loss = 0.28271123\n",
      "Iteration 29, loss = 0.28011185\n",
      "Iteration 30, loss = 0.27855619\n",
      "Iteration 31, loss = 0.27615241\n",
      "Iteration 32, loss = 0.27376923\n",
      "Iteration 33, loss = 0.27051776\n",
      "Iteration 34, loss = 0.26942327\n",
      "Iteration 35, loss = 0.26705980\n",
      "Time: 14.626311s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjouHCI\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (35) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp_clf.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print('Time: {:f}s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 0.873\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp_clf.predict(x_test)\n",
    "print(\"테스트 정확도: {:.3f}\".format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import random\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyper Parameter\n",
    "# learning_rate = 0.001\n",
    "# training_epochs = 15\n",
    "# batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input layer\n",
    "# X = tf.placeholder(tf.float32, [None, 134])\n",
    "# Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# # dropout\n",
    "# keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# # Xavier_Initializer\n",
    "# xavier_init = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hidden layers and Output layer\n",
    "# W1 = tf.get_variable(\"W1\", shape=[134, 67], initializer=xavier_init)\n",
    "# b1 = tf.Variable(tf.random_normal([67]))\n",
    "# L1 = tf.nn.relu(tf.matmul(X, W1)+b1)\n",
    "# dropout1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "# W2 = tf.get_variable(\"W2\", shape=[67, 30], initializer=xavier_init)\n",
    "# b2 = tf.Variable(tf.random_normal([30]))\n",
    "# L2 = tf.nn.relu(tf.matmul(dropout1, W2)+b2)\n",
    "# dropout2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "# W3 = tf.get_variable(\"W3\", shape=[30, 1], initializer=xavier_init)\n",
    "# b3 = tf.Variable(tf.random_normal([1]))\n",
    "# hypothesis = tf.matmul(dropout2, W3)+b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define cost/loss & optimizer\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# # Initialize\n",
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.array(x_train)\n",
    "# x_test = np.array(x_test)\n",
    "# y_train = np.array(y_train)\n",
    "# y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[0].reshape(1,134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Model\n",
    "# for epoch in range(training_epochs):\n",
    "#     feed_dict = {X:x_train, Y: y_train, keep_prob:0.7}\n",
    "#     c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "#     avg_cost += c / total_batch\n",
    "\n",
    "#     print('Epoch:', '{:04d}'.format(epoch +1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "# print('Training Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_x = [0,0,1,0]\n",
    "# np.transpose(text_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
